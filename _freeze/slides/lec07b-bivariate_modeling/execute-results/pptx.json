{
  "hash": "1b18bcd838660f5fc661b8c27173fe29",
  "result": {
    "markdown": "---\ntitle: \"Modeling Bivariate Relationships\"\ndate: \"2023-10-11\"\ndescription: \"8-10\"\nformat: pptx\n---\n\n\n\n\n## Advisory note\n\n-   This set of slides is really long.\n-   I recommend using the navigation menu (hamburger menu in the bottom\n    left) to skip to the relevant section.\n-   You can also download these slides as PDF in that same side menu\n-   Similar/more details on coding for this section found in ASCN Ch 5\n\n## A unifying model framework\n\nA good way to think about all statistical models is that the observed\ndata comes from some true model with some random error.\n\n> DATA = MODEL + RESIDUAL\n\nThe `MODEL` is a mathematical formula like $y = f(x)$. The formulation\nof the `MODEL` will change depending on the number of, and data types of\nexplanatory variables. One goal of inferential analysis is to explain\nthe variation in our data, using information contained in other\nmeasures.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-2-1.png)\n:::\n:::\n\n\n# Quantitative Outcome \\~ Binary Covariate {background-image=\"images/plot2norm.png\" background-opacity=\"0.3\"}\n\n-   Does knowing what group an observation is in tell you about the\n    location of the data?\n-   Are the means of **two** groups are *statistically* different from\n    each other?\n\n## Model\n\n$$\ny_{ij} = \\mu_{j} + \\epsilon_{ij} \\qquad \\qquad\n\\epsilon_{ij} \\overset{iid}{\\sim} \\mathcal{N}(0,\\sigma^{2})\n$$\n\n-   Response data $y_{ij}$ from observation $i=1\\ldots n$ belonging to\n    group $j=1,2$\n-   The random error terms $\\epsilon_{ij}$ are independently and\n    identically distributed (iid) as normal with mean zero and common\n    variance.\n\n## T-test for difference in means between two groups {.smaller}\n\n-   Parameter: $\\mu_{1} - \\mu_{2}$\n-   Estimate: $\\bar{x}_{1} - \\bar{x}_{2}$\n-   Assumptions:\n    -   Group 1 & 2 are mutually exclusive and independent\n    -   Difference $\\bar{x}_{1} - \\bar{x}_{2}$ is normally distributed\n    -   Variance within each group are approximately the same ($\\sigma$)\n\n$H_{0}: \\mu_{1} - \\mu_{2} = 0$: There is no difference in the averages\nbetween groups.\n\n$H_{A}: \\mu_{1} - \\mu_{2} \\neq 0$: There is a difference in the averages\nbetween groups.\n\n## Example: BMI vs smoking\n\nWe would like to know, is there convincing evidence that the average BMI\ndiffers between those who have ever smoked a cigarette in their life\ncompared to those who have never smoked?\n\n::: callout-important\n## Nitty gritty detail\n\nFor the purposes of learning, you will be writing out each step in the\nanalysis in depth. As you begin to master these analyses, it is natural\nto slowly start to blend and some steps. However it is important for you\nto have a baseline reference.\n:::\n\n## 1. Identify response and explanatory variables\n\n-   Ever smoker = binary explanatory variable (variable `eversmoke_c`)\n-   BMI = quantitative response variable (variable `BMI`)\n\n## 2. Visualize and summarise bivariate relationship {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot.bmi.smoke <- addhealth %>% select(eversmoke_c, BMI) %>% na.omit()\n\nggplot(plot.bmi.smoke, aes(x=eversmoke_c, y=BMI, fill=eversmoke_c)) + \n      geom_boxplot(width=.3) + geom_violin(alpha=.4) + theme_bw() + \n      labs(x=\"Smoking status\") + \n      scale_fill_manual(values=c(\"skyblue\", \"orange\"), guide = \"none\") + \n      stat_summary(fun=\"mean\", geom=\"point\", size=3, pch=17, \n      position=position_dodge(width=0.75))\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-3-1.png)\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot.bmi.smoke %>% \n  tbl_summary(\n    by=\"eversmoke_c\",\n    digits = all_continuous() ~ 1,     \n    statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"\n    ))\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"wzagoyucrg\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#wzagoyucrg .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#wzagoyucrg .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#wzagoyucrg .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#wzagoyucrg .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#wzagoyucrg .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#wzagoyucrg .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#wzagoyucrg .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#wzagoyucrg .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wzagoyucrg .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wzagoyucrg .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#wzagoyucrg .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#wzagoyucrg .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#wzagoyucrg .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzagoyucrg .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#wzagoyucrg .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#wzagoyucrg .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzagoyucrg .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#wzagoyucrg .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzagoyucrg .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#wzagoyucrg .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzagoyucrg .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wzagoyucrg .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzagoyucrg .gt_left {\n  text-align: left;\n}\n\n#wzagoyucrg .gt_center {\n  text-align: center;\n}\n\n#wzagoyucrg .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#wzagoyucrg .gt_font_normal {\n  font-weight: normal;\n}\n\n#wzagoyucrg .gt_font_bold {\n  font-weight: bold;\n}\n\n#wzagoyucrg .gt_font_italic {\n  font-style: italic;\n}\n\n#wzagoyucrg .gt_super {\n  font-size: 65%;\n}\n\n#wzagoyucrg .gt_two_val_uncert {\n  display: inline-block;\n  line-height: 1em;\n  text-align: right;\n  font-size: 60%;\n  vertical-align: -0.25em;\n  margin-left: 0.1em;\n}\n\n#wzagoyucrg .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#wzagoyucrg .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#wzagoyucrg .gt_slash_mark {\n  font-size: 0.7em;\n  line-height: 0.7em;\n  vertical-align: 0.15em;\n}\n\n#wzagoyucrg .gt_fraction_numerator {\n  font-size: 0.6em;\n  line-height: 0.6em;\n  vertical-align: 0.45em;\n}\n\n#wzagoyucrg .gt_fraction_denominator {\n  font-size: 0.6em;\n  line-height: 0.6em;\n  vertical-align: -0.05em;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\"><strong>Characteristic</strong></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\"><strong>Never Smoked</strong>, N = 1,750<sup class=\"gt_footnote_marks\">1</sup></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\"><strong>Smoked at least once</strong>, N = 3,276<sup class=\"gt_footnote_marks\">1</sup></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td class=\"gt_row gt_left\">BMI</td>\n<td class=\"gt_row gt_center\">29.7 (7.8)</td>\n<td class=\"gt_row gt_center\">28.8 (7.3)</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"3\"><sup class=\"gt_footnote_marks\">1</sup> Mean (SD)</td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n:::\n:::\n\n:::\n:::\n\nSmokers have on average BMI of 28.8, smaller than the average BMI of\nnon-smokers at 29.7. Non-smokers have more variation in their weights\n(7.8 vs 7.3lbs), but the distributions both look normal, if slightly\nskewed right.\n\n## 3. Write the relationship you want to examine in the form of a research question.\n\n-   Null Hypothesis: There is no difference in the average BMI between\n    smokers and non-smokers.\n-   Alternate Hypothesis: There is a difference in the average BMI\n    between smokers and non-smokers.\n\n## 4. Perform an appropriate statistical analysis using Dr D's 4 step method.\n\n**a. Define parameters**\n\nLet $\\mu_{1}$ be the average BMI for smokers, and $\\mu_{2}$ be the\naverage BMI for non-smokers\n\n**b. State the null and alternative hypothesis as symbols**\n\n$H_{0}: \\mu_{1} - \\mu_{2} = 0$\\\n$H_{A}: \\mu_{1} - \\mu_{2} \\neq 0$\n\n## \n\n**c. State and justify the analysis model. Check assumptions.**\n\nWe are comparing the means between two independent samples. A Two-Sample\nT-Test for a difference in means will be conducted. The assumptions that\nthe groups are independent is upheld because each individual can only be\neither a smoker or non smoker. The difference in sample means\n$\\bar{x}_{1}-\\bar{x}_{2}$ is normally distributed - this is a valid\nassumption due to the large sample size and that differences typically\nare normally distributed. The observations are independent, and the\nvariances are roughly equal (67/44 = 1.5 is smaller than 2).\n\n## \n\n**d. Conduct the test and make a decision about the plausibility of the\nalternative hypothesis.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(BMI ~ eversmoke_c, data=addhealth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  BMI by eversmoke_c\nt = 3.6937, df = 3395.3, p-value = 0.0002245\nalternative hypothesis: true difference in means between group Never Smoked and group Smoked at least once is not equal to 0\n95 percent confidence interval:\n 0.3906204 1.2744780\nsample estimates:\n        mean in group Never Smoked mean in group Smoked at least once \n                          29.67977                           28.84722 \n```\n:::\n:::\n\n\nThere is strong evidence in favor of the alternative hypothesis. The\ninterval for the differences (0.4, 1.3) does not contain zero and the\np-value = .0002.\n\n## 5. Write a conclusion in context of the problem. Include the point estimates, confidence interval for the difference and p-value.\n\nOn average, non-smokers have a significantly higher 0.82 (0.39, 1.27)\nBMI compared to smokers (p=.0002).\n\n## Assumption: Samples come from the same population\n\n![Credit: Allison Horst\nhttps://allisonhorst.com/](https://cdn.myportfolio.com/45214904-6a61-4e23-98d6-b140f8654a40/fa7b5022-e604-44d4-8659-985f427a673f_rw_1920.png?h=bd0561fd403aa4d7607c5609ea1ea292)\n\n## But we could be wrong\n\n![Credit: Allison Horst\nhttps://allisonhorst.com/](https://cdn.myportfolio.com/45214904-6a61-4e23-98d6-b140f8654a40/d37eedc5-e0f9-43f4-88da-e81d97f00540_rw_1920.png?h=db424d8a00f8e515824ddaf0aceee46c)\n\n## But we could be wrong\n\n![Credit: Allison Horst\nhttps://allisonhorst.com/](https://cdn.myportfolio.com/45214904-6a61-4e23-98d6-b140f8654a40/49e0e9dd-63c5-435c-9e94-38ee61c5224b_rw_1920.png?h=938bf875e8e6456341336019290469ad)\n\n## Type I and Type II Error {.incremental}\n\n-   AKA False positive or false negative.\n    [Wikipedia](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)\n-   The significance level, $\\alpha$, is what we use to define the\n    amount of \"risk\" we are willing to take to falsely reject $H_{0}$\n    (false positive).\n-   We talk more about false positive & false negative, [specificity and\n    sensitivity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n    in Math 456.\n-   We will see shortly however how to conduct multiple comparisons\n    while maintaining our \"family-wise\" error rate at $\\alpha$\n\n\n\n\n\n\n# Quant ~ Cat {background-image=\"images/plot3norm.png\" background-opacity=\"0.3\"}\n\n-   Does knowing what group an observation is in tell you about the\n    location of the data?\n-   Are the means of **two or more** groups are *statistically*\n    different from each other?\n\n## Analysis of Variance (ANOVA) Model\n\n$$\ny_{ij} = \\mu_{j} + \\epsilon_{ij} \\qquad \\qquad\n\\epsilon_{ij} \\overset{iid}{\\sim} \\mathcal{N}(0,\\sigma^{2})\n$$\n\n-   Response data $y_{ij}$ from observation $i=1\\ldots n$ belonging to\n    group $j=1,2$\n-   The random error terms $\\epsilon_{ij}$ are independently and\n    identically distributed (iid) as normal with mean zero and common\n    variance.\n-   Look familiar? T-test is a special case of ANOVA.\n\n## Hypothesis specification\n\nThe null hypothesis is that there is no difference in the mean of the\nquantitative variable across groups (categorical variable), while the\nalternative is that there is a difference.\n\n-   $H_0$: The mean outcome is the same across all groups.\n    $\\mu_1 = \\mu_2 = \\cdots = \\mu_j$\n-   $H_A$: At least one mean is different.\n\n##  {background-image=\"https://imgs.xkcd.com/comics/significant.png\" background-size=\"300px\" background-position=\"85% 50%\"}\n\n::: columns\n::: {.column width=\"60%\"}\n**Why not multiple T-tests between all pairs of groups?**\n\n\\\n\nEach time you conduct a test, you risk coming to the wrong conclusion.\n\nRepeated tests compound that chance of being wrong.\n\n\\\n\nImg Ref: <https://xkcd.com/882>\n:::\n\n::: {.column width=\"40%\"}\n:::\n:::\n\n## Analysis of Variance\n\nBy comparing the portion of the variance in the outcome that is\nexplained by the groups, to the portion that's leftover due to\nunexplained randomness. Essentially we're comparing the ratio of `MODEL`\nto `RESIDUAL`.\n\n> Total Variation = Between Group Variation + Within Group Variation\n\n## Sum of Squares {.smaller}\n\nVariation is measured using the Sum of Squares (SS): The sum of the\nsquares within a group (SSE), the sum of squares between groups (SSG),\nand the total sum of squares (SST).\n\n\n$$\nSST =  \\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}(y_{ij}-\\bar{y}..)^{2} = (N-1)Var(Y)\n$$\n\n**SST (Total)**: Measures the variation of the $N$ data points around\nthe overall mean. \n\n## Sum of Squares {.smaller}\n\n\n$$\nSSG = \\sum_{i=1}^{I}n_{i}(\\bar{y}_{i.}-\\bar{y}..)^{2} = n_{1}(\\bar{y}_{1.}-\\bar{y}..)^{2} + n_{2}(\\bar{y}_{2.}-\\bar{y}..)^{2} + \\ldots + n_{I}(\\bar{y}_{I.}-\\bar{y}..)^{2}\n$$\n\n**SSG (Between groups)**: Measures the variation of the $I$ group means\naround the overall mean. \n\n\n$$\nSSE = \\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}(y_{ij}-\\bar{y}_{i.})^{2} = \\sum_{i=1}^{I}(n_{i}-1)Var(Y_{i})\n$$\n\n**SSE (Within group)**: Measures the variation of each observation\naround its group mean. \n\n## Analysis of Variance Table\n\nThe results are typically summarized in an ANOVA table.\n\n| Source    | SS      | df    | MS                      | F                  |\n|-----------|---------|-------|-------------------------|--------------------|\n| Groups    | SSG     | $I-1$ | MSG = $\\frac{SSG}{I-1}$ | $\\frac{MSG}{MSE}$  |\n| Error     | SSE     | $N-I$ | MSE = $\\frac{MSE}{N-I}$ |                    |\n| **Total** | **SST** | $N-1$ |                         |                    |\n\n\nThe value in the **F** column is the test statistic, and has a F\ndistribution with degrees of freedom (df) dependent on the number of\ngroups (I-1), and the number of observations (N-I).\n\n## The F-distribution\n\nThe $p$-value is the **area to the right** of the F statistic density\ncurve. This is always to the right because the F-distribution is\ntruncated at 0 and skewed right. This is true regardless of the $df$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf1 <- c(3, 5, 8)\ndf2 <- c(4, 6, 10)\n\nplot(NULL, xlim = c(0, 5), ylim = c(0, 1), xlab = expression(F), ylab=\"\", main = \"F Distribution\", axes=FALSE)\naxis(2, labels = FALSE, tick = FALSE)\naxis(1); box()\nfor (i in 1:3) {\n  curve(df(x, df1[i], df2[i]), from = 0, to = 5, col = i, add = TRUE, lty = i, lwd=2)\n}\nlegend(\"topright\", legend = paste(\"df1 =\", df1, \", df2 =\", df2), col = 1:3, lty = 1:3)\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-7-1.png){fig-align='center'}\n:::\n:::\n\n\n## Assumptions\n\nGenerally we must check three conditions on the data before performing\nANOVA:\n\n-   The observations are independent within and across groups\n-   The data within each group are nearly normal\n-   The variability across the groups is about equal.\n\n## Example: March of the Penguins\n\n\n::: {.cell}\n\n```{.r .cell-code}\npen <- palmerpenguins::penguins\n```\n:::\n\n\n## 1. Identify response and explanatory variables\n\n-   Species = categorical explanatory variable\n-   Flipper length = quantitative response variable\n\n## 2. Visualize and summarise bivariate relationship {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggdist) # for the \"half-violin\" plot (stat_slab)\nggplot(pen, aes(x=flipper_length_mm, y=species, fill=species)) + \n      stat_slab(alpha=.5, justification = 0) + \n      geom_boxplot(width = .2,  outlier.shape = NA) + \n      geom_jitter(alpha = 0.5, height = 0.05) +\n      stat_summary(fun=\"mean\", geom=\"point\", col=\"red\", size=4, pch=17) + \n      theme_bw() + \n      labs(x=\"Flipper Length (mm)\", y = \"Species\") + \n      theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-9-1.png)\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npen %>% group_by(species) %>% \n  summarise(mean=mean(flipper_length_mm, na.rm=TRUE), \n            sd = sd(flipper_length_mm, na.rm=TRUE), \n            IQR = IQR(flipper_length_mm, na.rm=TRUE)) %>%\n  kable(digits = 1)\n```\n\n::: {.cell-output-display}\n|species   |  mean|  sd| IQR|\n|:---------|-----:|---:|---:|\n|Adelie    | 190.0| 6.5|   9|\n|Chinstrap | 195.8| 7.1|  10|\n|Gentoo    | 217.2| 6.5|   9|\n:::\n:::\n\n:::\n:::\n\nThe distribution of flipper length varies across the species, with\nGentoo having the largest flippers on average at 217.2mm compared to\nAdelie (190mm) and Chinstrap (195.8mm). The distributions are normally\ndistributed with very similar spreads, Chinstrap has the most variable\nflipper length with a SD of 7.1 compared to 6.5 for the other two\nspecies.\n\n<small> [*A blog post about raincloud plots vs\nviolins*](https://www.cedricscherer.com/2021/06/06/visualizing-distributions-with-raincloud-plots-and-how-to-create-them-with-ggplot2/)\n</small>\n\n## 3. Write the relationship you want to examine in the form of a research question.\n\n-   Null Hypothesis: There is no association between flipper length and\n    species.\n-   Alternate Hypothesis: There is an association between flipper length\n    and species.\n\n## 4. Perform an appropriate statistical analysis using Dr D's 4 step method.\n\n**a. Define parameters**\n\nLet $\\mu_{A}, \\mu_{C}$ and $\\mu_{G}$ be the average flipper length for\nthe *Adelie, Chinstrap* and *Gentoo* species of penguins respectively.\n\n\n**b. State the null and alternative hypothesis as symbols**\n\n$H_{0}: \\mu_{A} = \\mu_{C} = \\mu_{G}$\\\n$H_{A}:$ At least one $\\mu_{j}$ is different.\n\n## {.smaller}\n\n**c. State and justify the analysis model. Check assumptions.**\n\nWe are comparing means from multiple groups, so an ANOVA is the\nappropriate procedure. We need to check for independence, approximate\nnormality and approximately equal variances across groups.\n\n**Independence**: We are assuming that each penguin was sampled\nindependently of each other, and that the species themselves are\nindependent of each other.\n\n**Normality**: The distributions of flipper length within each group are\nfairly normal\n\n**Equal variances**: Both the standard deviation and IQR (as measures of\nvariability) are very similar across all groups.\n\n## \n\n**d. Conduct the test and make a decision about the plausibility of the\nalternative hypothesis.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov(flipper_length_mm ~ species, data=pen) |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value Pr(>F)    \nspecies       2  52473   26237   594.8 <2e-16 ***\nResiduals   339  14953      44                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n```\n:::\n:::\n\n\nThe pvalue is very small, so there is evidence to support $H_{a}$: at\nleast one mean is different.\n\n## 5. Write a conclusion in context of the problem.\n\nThere is sufficient evidence to believe that the average flipper length\nis significantly different between the Adelie, Chinstrap and Gentoo\nspecies of penguins (p\\<.0001).\n\n## Multiple / Post-Hoc comparisons: Which group is different? {.smaller}\n\n-   Run Post Hoc tests (\"Tukeys HSD\", or \"Duncan\"), *only* if your ANOVA\n    is significant.\n-   The overall ANOVA can be significant and NOT have any significant\n    differences when you look at the post hoc results. The reason is\n    that the two analyses ask two different questions.\n    -   The ANOVA is testing the overall pattern of the data and asking\n        if as a whole the explanatory variable has a relationship (or\n        lack thereof) with the response variable.\n    -   The post hoc is asking if one level of the explanatory variable\n        is significantly different than another for the response\n        variable. The post hoc is not as sensitive to differences as the\n        ANOVA.\n    -   **The family-wise error rate of** $\\alpha$ is maintained\n-   Differences in group means can be non-significant at the post hoc\n    level, but significant at the ANOVA level.\n\n## {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(aov(flipper_length_mm ~ species, data=pen))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = flipper_length_mm ~ species, data = pen)\n\n$species\n                      diff       lwr       upr p adj\nChinstrap-Adelie  5.869887  3.586583  8.153191     0\nGentoo-Adelie    27.233349 25.334376 29.132323     0\nGentoo-Chinstrap 21.363462 19.000841 23.726084     0\n```\n:::\n:::\n\n\nThe results of the Tukey HSD post-hoc test indicate that the average\nflipper length in mm is significantly different between all pairs of\npenguin species at the 5% significance level. Chinstrap has an average\nflipper length 5.87mm(3.59-8.15) larger than Adelie, whereas Gentoo has\nan average flipper length 27.23mm(25.33-29.13) larger than Adelie.\n\n## Coefficient of Determination $R^{2} = \\frac{SSG}{SST}$ {.smaller}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value Pr(>F)    \nspecies       2  52473   26237   594.8 <2e-16 ***\nResiduals   339  14953      44                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n```\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\n52473/(52473 + 14953)*100\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 77.82309\n```\n:::\n:::\n\n\nThe coefficient of determination is interpreted as the % of the\nvariation seen in the outcome that is due to subject level variation\nwithin each of the treatment groups. The strength of this measure can be\nthought of in a similar manner as the correlation coefficient $\\rho$,\n$<.3$ indicates a poor fit, $<.5$ indicates a medium fit, and $>.7$\nindicates a good fit.\n\n> 77.8% of the variation in flipper length can be explained by the\n> species of penguin\n\n## Non-parametric tests\n\n-   Many stat tests rely on assumptions that ensure the sample estimate\n    can be modeled with a normal distribution.\n-   What do you do if your assumptions aren't met?\n-   We can \"relax\" some of those assumptions and perform a more robust,\n    but less powerful test.\n    -   less power means you need more data to draw a conclusion with\n        the same amount of confidence.\n-   No detailed examples will be provided in these notes. You tend to\n    learn/use these on an \"as-needed\" basis.\n\n## Kruskal-Wallis {.incremental}\n\n-   The\n    [Kruskal-Wallis](https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance)\n    test is the most common **non-parametric** method for testing\n    whether or not groups of observations come from the same overall\n    distribution.\n-   By comparing the *medians* instead of the means, we can remove the\n    normality assumption on the residuals.\n-   Null hypothesis is now that the medians of all groups are equal vs\n    at least one population median is different.\n-   [Ref on how to do this in R from\n    STHDA](http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r)\n\n# Categorical Outcome \\~ Categorical Covariate {background-color=\"#6c972b\"}\n\n## Opening Remarks\n\nIf we are only concerned with testing the hypothesis that the proportion\nof successes between two groups are equal $p_{1}-p_{2}=0$, we can\nleverage the Normal distribution and conduct a Z-test for two\nproportions.\n\nHowever in this class we will use the more generalizable model via\nChi-squared test of association/equal proportions.\n\n## Chi-squared test of equal proportions [(Ref: ASCN Section 5.5)](https://norcalbiostat.github.io/AppliedStatistics_notes/bv-chisq.html)\n\nA 30-year study was conducted with nearly 90,000 female participants.\n(Miller AB. 2014) During a 5-year screening period, each woman was\nrandomized to one of two groups: in the first group, women received\nregular mammograms to screen for breast cancer, and in the second group,\nwomen received regular non-mammogram breast cancer exams. No\nintervention was made during the following 25 years of the study, and\nwe'll consider death resulting from breast cancer over the full 30-year\nperiod.\n\n## Results from study\n\n\n::: {.cell}\n::: {.cell-output-display}\n|          | Alive| Dead|   Sum|\n|:---------|-----:|----:|-----:|\n|Control   | 44405|  505| 44910|\n|Mammogram | 44425|  500| 44925|\n|Sum       | 88830| 1005| 89835|\n:::\n:::\n\n\nThe independent/explanatory variable is treatment (additional\nmammograms), and the dependent/response variable is death from breast\ncancer. Are these measures associated?\n\n## Assume independence/no association {.smaller .incremental}\n\n-   If mammograms are more effective than non-mammogram breast cancer\n    exams, then we would expect to see additional deaths from breast\n    cancer in the control group (there is a relationship).\n-   If mammograms are not as effective as regular breast cancer exams,\n    we would expect to see no difference in breast cancer deaths in the\n    two groups (there is no relationship).\n-   Need to figure out how many deaths would be **expected**, if there\n    was no relationship between treatment death by breast cancer,\n-   Then examine the **residuals** - the difference between the observed\n    counts and the expected counts in each cell.\n\n## Table notation\n\nTables can be described by $i$ rows and $j$ columns. So the cell in the\ntop left is $i=1$ and $j=1$.\n\n| $O_{ij}$ |  Alive   |         Dead         |        Total         |\n|:---------|:--------:|:--------------------:|:--------------------:|\n| Mammo    | $n_{11}$ | $n_{12}$ \\| $n_{1.}$ |                      |\n|          | Control  |       $n_{21}$       | $n_{22}$ \\| $n_{2.}$ |\n| Total    | $n_{.1}$ |       $n_{.2}$       |         $N$          |\n\nIn our DATA = MODEL + RESIDUAL framework, the DATA ($n_{11}, n_{12}$,\netc)is the observed counts $O_{ij}$ and the MODEL is the expected counts\n$E_{ij}$.\n\n## Calculating the expected count\n\nSince we assume the variables are independent (unless the data show\notherwise) the expected count for each cell is calculated as the row\ntotal times the column total for that cell, divided by the overall\ntotal.\n\n$$E_{ij} = \\frac{n_{i.}n_{.j}}{N}$$\n\nIn a probability framework this is stated as two variables $A$ and $B$\nare independent if\n$P(A \\cap B) = P(A)*P(B) = \\frac{n_{i.}}{N}*\\frac{n_{.j}}{N}$\n\n## Calculating the residuals {.smaller}\n\nThe residuals are calculated as $(O_{ij} - E_{ij})$\n\n::: columns\n::: {.column width=\"50%\"}\nExpected\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(a$Tx, a$Outcome)$expected %>% kable(digits=2)\n```\n\n::: {.cell-output-display}\n|          |    Alive|   Dead|\n|:---------|--------:|------:|\n|Control   | 44407.58| 502.42|\n|Mammogram | 44422.42| 502.58|\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nResiduals\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(a$Tx, a$Outcome)$residuals %>% kable(digits=3) \n```\n\n::: {.cell-output-display}\n|          |  Alive|   Dead|\n|:---------|------:|------:|\n|Control   | -0.012|  0.115|\n|Mammogram |  0.012| -0.115|\n:::\n:::\n\n:::\n:::\n\nIf mammograms were not associated with survival, there were 0.01 fewer\npeople still alive than expected, and 0.11 more people dead.\n\n## $\\chi^2$ test statistic\n\n::: columns\n::: {.column width=\"50%\"}\nThe $\\chi^2$ test statistic is defined as the sum of the squared\nresiduals, divided by the expected counts, and follows a $\\chi^2$\ndistribution with degrees of freedom (#rows -1)(#cols -1).\n\n$$ \\sum_{ij}\\frac{(O_{ij}-E_{ij})^{2}}{E_{ij}} $$\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ndist_chisq(chi2=.027, deg.f=1, geom.colors=c(\"#FDE725FF\", \"#440154FF\"))\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-17-1.png)\n:::\n:::\n\n:::\n:::\n\n## Conclusion\n\nIn this example, the test statistic was\n0.017 with p-value\n0.895.\n\nSo there is not enough reason to believe that mammograms in addition to\nregular exams are associated with a reduced risk of death due to breast\ncancer.\n\nThis example demonstrated how we examine the residuals to see how\nclosely our DATA fits a hypothesized MODEL.\n\n## Example: Income and General Health\n\nUsing the Addhealth data set, what can we say about the relationship\nbetween smoking status and a person's perceived level of general health?\n\nIs there an association between lifetime smoking status and perceived\ngeneral health?\n\n## 1. Identify response and explanatory variables\n\n-   The binary explanatory variable is whether the person has ever\n    smoked an entire cigarette (`eversmoke_c`).\n-   The categorical explanatory variable is the person's general health\n    (`genhealth`) and has levels \"Excellent\", \"Very Good\", \"Good\",\n    \"Fair\", and \"Poor\".\n\n## 2. Visualize and summarise bivariate relationship {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_xtab(grp=addhealth$eversmoke_c, x=addhealth$genhealth, \n                  show.total = FALSE, margin=\"row\", legend.title=\"\") \n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-18-1.png)\n:::\n:::\n\n\nThe percentage of smokers seems to increase as the general health status\ndecreases. Almost three-quarters (73%, n=40) of those reporting poor\nhealth have smoked an entire cigarette at least once in their life\ncompared to 59% (n=573) of those reporting excellent health.\n\n## 2b. Other ways to visualize this (FYI only)\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\naddhealth %>% \n  group_by(genhealth) %>% \n  summarize(p = mean(eversmoke_c == \"Smoked at least once\", na.rm=TRUE)*100, \n            n = n()) %>% \n  na.omit() %>% \n  ggplot(aes(x=genhealth, y=p, color=genhealth)) + \n  geom_point(aes(size = n)) + \n  scale_y_continuous(limits=c(0, 100)) + \n  geom_segment(aes(x=genhealth, xend=genhealth, y=0, yend=p)) +\n  scale_color_discrete(guide=\"none\") + theme_bw() + \n  ylab(\"Proportion of smokers\") + \n  xlab(\"Perceived General Health\")\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-19-1.png)\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\naddhealth %>% \n  count(genhealth, eversmoke_c) %>% \n  na.omit() %>%\n  group_by(genhealth)%>%\n  mutate(p = n/sum(n)*100) %>% \nggplot(aes(x=genhealth, y=p, fill=eversmoke_c, \n           label = paste0(round(p, 1), \"%\"))) + \n  geom_col() + theme_bw() + \n  scale_fill_discrete(name = \"\") + \n  geom_text(position=position_stack(0.5)) + \n  ylab(\"Proportion of smokers\") + \n  xlab(\"Perceived General Health\")\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-20-1.png)\n:::\n:::\n\n:::\n:::\n\n<small> These methods pre-calculate the proportions first, and then put\nthem on a ggplot canvas. As you build your expertise with R/Ggplot you\nwill find yourself wanting to enhance or move away from the\n\"pre-packaged\" plots from `sjPlot` and `ggpubr`. </small>\n\n## 3. Write the relationship you want to examine in the form of a research question.\n\n-   Null Hypothesis: The proportion of smokers is the same across all\n    levels of general health.\n-   Alternate Hypothesis: At least one group has a different proportion\n    of smokers compared to the other general health groups.\n\n## 4. Perform an appropriate statistical analysis using Dr D's 4 step method.\n\n**a. Define parameters**\n\nLet $p_{1}, p_{2}, \\ldots, p_{5}$ be the true proportion of smokers in\neach of the 5 health categories: (1) Excellent to (5) Poor.\n\n\\\n\n**b. State the null and alternative hypothesis as symbols**\n\n$H_{0}: p_{1} = p_{2} = \\ldots p_{5}$\\\n$H_{A}:$ At least one $p_{j}$ is different.\n\n## \n\n**c. State and justify the analysis model. Check assumptions.**\n\nI will conduct a $\\chi^{2}$ test of association. There is at least 10\nobservations in each combination of smoking status and general health.\n\n**d. Conduct the test and make a decision about the plausibility of the\nalternative hypothesis.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(addhealth$genhealth, addhealth$eversmoke_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  addhealth$genhealth and addhealth$eversmoke_c\nX-squared = 30.795, df = 4, p-value = 3.371e-06\n```\n:::\n:::\n\n\nWe have strong evidence in favor of the alternative hypothesis, p\\<.0001\n\n## 5. Write a conclusion in context of the problem.\n\nWe can conclude that there is an association between ever smoking a\ncigarette in their life and perceived general health\n($\\chi^{2} = 30.8, df=4, p<.0001$).\n\n## Multiple comparisons: Which group is different? {.smaller}\n\nJust like with ANOVA, if we find that the Chi-squared test indicates\nthat at least one proportion is different from the others, it's our job\nto figure out which ones might be different! We will analyze the\nresiduals to accomplish this.\n\n## Examine the residuals {.smaller}\n\nThe residuals ($O_{ij} - E_{ij}$) are automatically stored in the model\noutput. You can either print them out and look at the values directly or\ncreate a plot. You're looking for combinations that have much higher, or\nlower expected proportions.\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nhealth.smoke.model <- chisq.test(addhealth$genhealth, addhealth$eversmoke_c)\nhealth.smoke.model$residuals |> round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   addhealth$eversmoke_c\naddhealth$genhealth Never Smoked Smoked at least once\n          Excellent         3.45                -2.52\n          Very good         0.48                -0.35\n          Good             -2.44                 1.78\n          Fair             -1.06                 0.77\n          Poor             -0.94                 0.69\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot.residuals <- health.smoke.model$residuals %>% data.frame()\nggplot(plot.residuals, aes(x=addhealth.genhealth, y=addhealth.eversmoke_c)) +\n       geom_raster(aes(fill=Freq)) +  scale_fill_viridis_c()\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-23-1.png)\n:::\n:::\n\n:::\n:::\n\nThe proportion of non-smokers in the excellent health category is much\nhigher than expected if there were no relationship between these two\nvariables.\n\n## All pairwise comparisons {.smaller}\n\n::: columns\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(rcompanion)\nsmoke.by.genhealth <- table(addhealth$genhealth, addhealth$eversmoke_c)\nrcompanion::pairwiseNominalIndependence(smoke.by.genhealth, fisher = FALSE, gtest=FALSE) |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|Comparison            | p.Chisq| p.adj.Chisq|\n|:---------------------|-------:|-----------:|\n|Excellent : Very good |   0.002|       0.008|\n|Excellent : Good      |   0.000|       0.000|\n|Excellent : Fair      |   0.001|       0.005|\n|Excellent : Poor      |   0.055|       0.110|\n|Very good : Good      |   0.009|       0.022|\n|Very good : Fair      |   0.167|       0.278|\n|Very good : Poor      |   0.269|       0.384|\n|Good : Fair           |   0.886|       0.886|\n|Good : Poor           |   0.630|       0.700|\n|Fair : Poor           |   0.601|       0.700|\n:::\n:::\n\n:::\n\n::: {.column width=\"30%\"}\nUsing the adjusted (for multiple comparisons) p-value column, the\nproportion of smokers in the Excellent group (41.3%) is significantly\ndifferent from nearly all other groups (35.4% for Very Good, 31.3% for\nGood, 31.8% for Fair).\n\nBut why is it not significantly different from the 27.3% in the Poor\ngroup?\n:::\n:::\n\n## The effect of small sample sizes\n\nWhy is 41.3% significantly different from 35.4%, but NOT different from\n27.3%?\n\nThe standard error is always dependent on the sample size. Here, the\nnumber of individuals in the Poor health category is much smaller\ncompared to all other groups - so the margin of error will be larger -\nmaking it less likely to be statistically significantly different from\nother groups.\n\nWhen you have a small numbers (n\\<10) in one or more cells the\ndistribution of the test statistic can no longer be modeled well using\nthe $\\chi^{2}$ distribution. So we again go to a non-parametric test\nthat uses a randomization based method.\n\n## Fishers Exact Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfisher.test(addhealth$genhealth, addhealth$eversmoke_c, \n            simulate.p.value = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tFisher's Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\ndata:  addhealth$genhealth and addhealth$eversmoke_c\np-value = 0.0004998\nalternative hypothesis: two.sided\n```\n:::\n:::\n\n\nThen you can use the `pairwiseNominalIndependence` function for all\npairwise comparisons again, with the `fisher` argument set to `TRUE`.\n\n::: {.callout-note appearance=\"minimal\"}\n<small>Note: the `simulate.p.value = TRUE` argument here is only needed\nif the randomization space is larger than your workspace. R will let you\nknow when this is needed.</small>\n:::\n\n## Chi-Squared test of Association/Independence\n\nWe can still use the $\\chi^{2}$ test of association to compare\ncategorical variables with more than 2 levels. In this case we\ngeneralize the statement to ask: **Is the distribution of 1 variable the\nsame across levels of another variable?**. In this sense, it is very\nmuch like an ANOVA.\n\nMathematically the $\\chi^{2}$ test of association is the exact same as a\ntest of equal proportions.\n\n## Example\n\nLet's analyze the relationship between a person's income and perceived\nlevel of general health.\n\nThe categorical explanatory variable is income, binned into 4 ranges\n(`income_cat`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\naddhealth$income_cat <- Hmisc::cut2(addhealth$income, g = 4)\n```\n:::\n\n\n## State Hypothesis\n\n-   The income distribution is the same in each of the general health\n    categories (no association)\n-   The income distribution differs for at least one of the general\n    health categories (association)\n\n## Visualize the relationship\n\n::: columns\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_xtab(grp=addhealth$income_cat,\n                  x=addhealth$genhealth, \n                  show.total = FALSE, margin=\"row\",\n                  legend.title=\"\") + \n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-27-1.png)\n:::\n:::\n\n:::\n\n::: {.column width=\"40%\"}\n<small> The income distribution is nearly flat for who rate themselves\nin excellent or very good condition. However, the proportion of\nindividuals in the lower income categories increase as perceived general\nhealth decreases. Over 80% of those that rate themselves as in Poor\ncondition have an annual income less than \\$35,500.\n\nSince there are very small cell sizes, we will use a Fishers Exact test.\n</small>\n:::\n:::\n\n## Test the relationship & make a conclusion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfisher.test(addhealth$genhealth, addhealth$income_cat, \n            simulate.p.value = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tFisher's Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\ndata:  addhealth$genhealth and addhealth$income_cat\np-value = 0.0004998\nalternative hypothesis: two.sided\n```\n:::\n:::\n\n\nThere is sufficient evidence to conclude that the distribution of income\nis not the same across all general health status categories.\n\n## Other analysis for categorical variables\n\nThere is a slew of methods to analyze categorical data, we can't get\ninto them all. To learn more start with Categorical Data Analysis by\nAlan Agresti, who has written *extensively* on the subject.\n\nThis R companion page also looks very useful\nhttp://rcompanion.org/handbook/H_01.html and where I got the\n`pairwiseNominalIndependence` function from.\n\n# Quantitative Outcome \\~ Quantitative Covariate {background-color=\"#6c972b\"}\n\n## Opening Remarks\n\nThe PMA6 textbook (Chapter 7) goes into great detail on this topic,\nsince regression is typically the basis for all advanced models.\n\nThe book also distinguishes between a \"fixed-x\" case, where the values\nof the explanatory variable $x$ only take on pre-specified values, and a\n\"variable-x\" case, where the values of $x$ are observations from a\npopulation distribution of X's.\n\nThis latter case is what we will be concerning ourselves with.\n\n## Bivariate distribution {.smaller}\n\nThe *bivariate distribution* describes how of $X$ and $Y$ are jointly\ndistributed, and is best interpreted by a look at the scatter diagram.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny.bar <- mean(pen$bill_length_mm, na.rm=TRUE)\nx.bar <- mean(pen$body_mass_g, na.rm=TRUE)\n\np <- ggplot(pen, aes(x=body_mass_g, y=bill_length_mm)) + geom_point() + \n  geom_hline(yintercept = y.bar) + \n  geom_vline(xintercept = x.bar) \nggExtra::ggMarginal(p, type=\"histogram\")\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-29-1.png){fig-align='center'}\n:::\n:::\n\n\nIf $X$ and $Y$ come from independent normal distributions, the pair\n$(X,Y)$ comes from a *bivariate normal distribution*, and the data will\ntend to cluster around the means of $X$ and $Y$.\n\n## Ellipse of concentration\n\nWe can view the *ellipse of concentration* as measure of strength and\ndirection of the correlation between X and Y.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggpubr::ggscatter(pen, x = \"body_mass_g\", y = \"bill_length_mm\",\n   ellipse = TRUE, mean.point = TRUE,\n   star.plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-30-1.png){fig-align='center'}\n:::\n:::\n\n\nSee PMA6 Figure 7.5 for more examples.\n\n## Correlation\n\nThe **correlation coefficient** is designated by $r$ for the sample\ncorrelation, and $\\rho$ for the population correlation. The correlation\nis a measure of the strength and direction of a *linear relationship*\nbetween two variables.\n\nThe correlation ranges from +1 to -1. A correlation of +1 means that\nthere is a perfect, positive linear relationship between the two\nvariables. A correlation of -1 means there is a perfect, negative linear\nrelationship between the two variables. In both cases, knowing the value\nof one variable, you can perfectly predict the value of the second.\n\n## Strength of the correlation\n\nHere are rough estimates for interpreting the strengths of correlations\nbased on the magnitude of $r$.\n\n-   $|r| \\geq 0.7$: Very strong relationship\n-   $0.4 \\leq |r| < 0.7$: Strong relationship\n-   $0.3 \\leq |r| < 0.4$: Moderate relationship\n-   $0.2 \\leq |r| < 0.3:$ Weak relationship\n-   $|r| < 0.2:$ Negligible or no relationship\n\n## As a measure of model fit\n\nWhen we square $r$ (i.e. $R^{2}$), it tells us what proportion of the\nvariability in one variable that is described by variation in the second\nvariable.\n\n\\\n\nYes, this is mathematically the same as the coefficient of determination\nwe saw in ANOVA.\n\n## Pearson test of correlation\n\nTo test for a *linear* correlation between two variables we use the\n**Pearson correlation coefficient** which is defined as the covariance\nof the two variables divided by the product of their standard\ndeviations.\n\n$$\n\\rho_{X,Y} = \\frac{cov(X,Y)}{\\sigma_{x}\\sigma_{Y}}\n$$\n\nThere are many modifications and adjustments to this measure that we\nwill not get into detail with. We are using correlation as a stepping\nstool to Linear Regression.\n\n## Example: Body mass and bill length of penguins\n\n### 1. Identify response and explanatory variables\n\n-   The quantitative explanatory variable is body mass (g)\n-   The quantitative response variable is bill length (mm)\n\n## 2. Visualize and summarise bivariate relationship {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pen, aes(x=body_mass_g, y=bill_length_mm)) + \n  geom_point() + geom_smooth(col = \"red\")\n```\n\n::: {.cell-output-display}\n![](lec07b-bivariate_modeling_files/figure-pptx/unnamed-chunk-31-1.png)\n:::\n\n```{.r .cell-code}\ncor(pen$body_mass_g, pen$bill_length_mm, use = \"pairwise.complete.obs\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5951098\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nThere is a strong, positive, mostly linear relationship between the body\nmass (g) of penguins and their bill length (mm) (r=.595).\n:::\n:::\n\n## 3. Write the relationship you want to examine in the form of a research question.\n\n-   Null Hypothesis: There is no correlation between the body mass and\n    bill length of penguins.\n-   Alternate Hypothesis: There is a correlation between the body mass\n    and bill length of penguins.\n\n## 4. Perform an appropriate statistical analysis using Dr D's 4 step method.\n\n**a. Define parameters** Let $\\rho$ be the true correlation between body\nmass and bill length of penguins.\n\n**b. State the null and alternative hypothesis as symbols**\n\n$H_{0}: \\rho=0 \\qquad \\qquad H_{A}: \\rho \\neq 0$\n\n**c. State and justify the analysis model.**\n\nPearsons test of correlation will be conducted. This is appropriate\nbecause both variables are quantitative, the relationship between\nvariables are reasonably linear, and the sample size is large.\n\n## \n\n**d. Conduct the test and make a decision about the plausibility of the\nalternative hypothesis.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(pen$body_mass_g, pen$bill_length_mm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  pen$body_mass_g and pen$bill_length_mm\nt = 13.654, df = 340, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5220040 0.6595358\nsample estimates:\n      cor \n0.5951098 \n```\n:::\n:::\n\n\nThe p-value is very small, there is evidence in favor of a non-zero\ncorrelation.\n\n## 5. Write a conclusion in context of the problem.\n\nThere was a statistically significant and strong correlation between the\nbody mass (g) and bill length (mm) of penguins (r = 0.595, 95%CI\n.5220-.6595, p \\< .0001). The significant positive correlation shows\nthat as the body mass of a penguin increases so does the bill length.\nThese results suggest that 35% (95% CI: 27.2-43.5) of the variance in\nbill length can be explained by the body mass of the penguin.\n",
    "supporting": [
      "lec07b-bivariate_modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}