{
  "hash": "bedfab36ff6e73104608c7fcdd50d3ea",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Statistical Inference using Models\"\ndate: \"2025-10-06\"\ndescription: \"lec06b\"\nauthor: \"Robin Donatello\"\nfooter: \"[üîó https://math615.netlify.app](https://math615.netlify.app)\"\nfrom: markdown+emoji\nformat: \n  revealjs:\n    theme: sky\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    title-slide-attributes:\n      data-background-image: images/paranormal.png\n      data-background-size: 25% \n      data-background-position: bottom 50px right 50px\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:\n      width: 200\n---\n\n\n\n## Warm up exercise\n\nWork through the Central Limit Theorem interactive explorer for about 15 minutes. Follow the instructions on the app and take notes and be prepared to share out what you learned/your take away message.\n\n<https://mathisawesome.shinyapps.io/central-limit-theorem/>\n\n## Sampling Distributions\n\nSince *point estimates* are numbers calculated on a sample, they are also *sample statistics*. Recall that sample statistics are used to estimate parameters, the true value of the quantity of interest from the population.\n\nAs we just saw through simulation, point estimates are subject to *random variation* because they are calculated on different random samples from the population. The distribution of repeatedly calculated point estimates based on the same fixed size $n$ from a population is called a *sampling distribution*.\n\n## Mathematical theory guarantees {.smaller}\n\n-   If repeated samples are taken, a point estimate will follow something that **resembles a normal distribution** when certain conditions are met.\n    -   *Note: we typically only take one sample, but the mathematical model lets us know what to expect if we had taken repeated samples*\n\n::: callout-important\n#### Observations in the sample are independent.\n\nGuaranteed when we take a random sample from a population, or randomly divide individuals into treatment and control groups.\n:::\n\n::: callout-important\n#### The sample is large enough.\n\nWhat qualifies as ‚Äúlarge enough‚Äù differs from one context to the next. If the population is already normally distributed and the formula to calculate the sample statistic simple, then fewer samples are needed. The \"magic\" number 30 gets thrown around a lot.\n:::\n\n## The Normal Distribution {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\nThe normal distribution is used to describe the variability associated with sample statistics which are taken from either repeated samples or repeated experiments. The normal distribution is quite powerful in that it describes the variability of many different statistics such as the sample mean and sample proportions.\n\nDistributions of many variables are nearly normal, but none are exactly normal. While not perfect for any single problem, the Normal Distribution is very useful for a variety of problems.\n:::\n\n::: {.column width=\"50%\"}\n<a href=\"https://twitter.com/RiddleMeCam/status/1557402268395139077?ref_src=twsrc%5Etfw\">![](images/clt_twitter.png)</a>\n:::\n:::\n\n# The Normal Distribution\n\n::: callout-important\n#### Pre-requisite knowledge\n\nIt is expected that you have a basic understanding of the Normal distribution. If you need a detailed refresher, refer to [IMS 13.2](https://openintro-ims.netlify.app/foundations-mathematical.html#normalDist).\n\nWhat follows is a quick recap of critical details.\n:::\n\n## Distributional Notation\n\n$$ X \\sim \\mathcal{N}(\\mu, \\sigma^2)$$ This means some random variable $X$ is distributed($\\sim$), as a Normal ($\\mathcal{N}$) distribution centered on mean $\\mu$ with variance $\\sigma^{2}$.\n\n::: callout-warning\n### Notational differences\n\nNote that the IMS textbook uses the uncommon notation $\\mathcal{N}(\\mu, \\sigma)$, where the second parameter is $\\sigma$, the standard deviation.\n:::\n\n## The Normal Distribution \n\n::: columns\n::: {.column width=\"50%\"}\n-   Symmetric, \"bell shaped\"\n-   Centered on $\\mu$ and spread controlled by $\\sigma^2$\n-   Tails extend to $\\infty$\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec06b-statistical_inference_with_models_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n:::\n\n-   Area under the curve will always add to 1.\n-   Used to calculate the probability of an event occurring\n:::\n\n## Comparing values under two different distributions\n\n::: callout-tip\n### Two different college-ready exams\n\nSAT scores follow a nearly normal distribution with a mean of 1500 points and a standard deviation of 300 points.\n\nACT scores also follow a nearly normal distribution with mean of 21 points and a standard deviation of 5 points.\n\nSuppose Nel scored 1800 points on their SAT and Sian scored 24 points on their ACT.\n:::\n\nWho performed better?\n\n## Standardizing Distributions\n\nIf you overlay the two distributions, where the means line up and where each tick mark represents one standard deviation away from the mean, we can see who did better *relative to the exam average*.\n\n::: columns\n::: {.column width=\"70%\"}\n![](https://openintro-ims.netlify.app/foundations-mathematical_files/figure-html/fig-satActNormals-1.png)\n:::\n\n::: {.column width=\"30%\"}\n$$X_{SAT} \\sim \\mathcal{N}(1500, 300^{2})$$\\\n\n$$X_{ACT} \\sim \\mathcal{N}(21, 25)$$\n:::\n:::\n\n## Z-score\n\nThe Z score of an observation is the number of standard deviations it falls above or below the mean. We compute the Z score for an observation that follows a distribution with mean and standard deviation using\n\n$$ Z = \\frac{x- \\mu}{\\sigma} $$ If an observation $x$ comes from a $\\mathcal{N}(\\mu, \\sigma)$ distribution, then $Z \\sim \\mathcal{N}(0, 1)$. We *center* the distribution by subtracting the mean, and *scale* by dividing by the sd.\n\n## Comparing Scores\n\nCalculate the Z-score for both Nel and Sian. Who did better?\n\n::: columns\n::: {.column width=\"50%\"}\n::: incremental\n-   $X_{SAT} \\sim \\mathcal{N}(1500, 300^{2})$\n-   $x_{Nel} = 1800$ \n-   $Z_{Nel} = \\frac{1800- 1500}{300} = 1$\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: incremental\n-   $X_{ACT} \\sim \\mathcal{N}(21, 25)$\n-   $x_{Sian} = 24$\n-   $Z_{Sian} = \\frac{24- 21}{5} = 0.6$\n:::\n:::\n:::\n\n## Comparing Scores\n\nWhile we know Nel did better, Sian didn't do too bad! What was their _*percentile*_ (The percent of observations below a specified value)? \n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nopenintro::normTail(m = 21, s = 5, L = 24)\n```\n\n::: {.cell-output-display}\n![](lec06b-statistical_inference_with_models_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\nWe can find this value using `pnorm(z, mean, sd)`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(.6, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7257469\n```\n\n\n:::\n:::\n\n\n:::\n\n::::\n\n## Finding percentiles {.smaller} \n\nIf $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$, then `pnorm` calculates the probability that a value is below a certain number `a`. \n\n* $P(X < a)$ is found using `pnorm(a, mean, sd)`\n\nA complementary function, `qnorm` calculates the _cutoff_ value `a` that is needed such that a certain percent of observations (`q`) are below that value. \n\n* $P(X < a) = q$ is found using `qnorm(q, mean, sd)`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(.90, 21, 5) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 27.40776\n```\n\n\n:::\n:::\n\n\nYou would need to score a 27.5 to be in the top 10th percentile of ACT test takers. \n\n\n# Quantifying variability of a statistic\n\nFollows [IMS 13.3](https://openintro-ims.netlify.app/foundations-mathematical.html#quantifying-the-variability-of-a-statistic)\n\n## Many estimates are normally distributed\n\n* the sample proportion $\\hat{p}$\n* the sample mean $\\bar{x}$\n* differences in two sample proportions $\\hat{p}_{1} - \\hat{p}_{2}$\n* differences in two sample means $\\bar{x}_{1} - \\bar{x}_{2}$\n* the sample slope from a linear model $\\hat{\\beta}$\n\n## 68-95-99.7 rule of thumb\n\nBecause intuition is important.\n\n![](https://openintro-ims.netlify.app/foundations-mathematical_files/figure-html/fig-er6895997-1.png)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(2, 0, 1) - pnorm(-2, 0, 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9544997\n```\n\n\n:::\n:::\n\n\n\n\n## SD vs SE\n\n::: callout-important\n### Definition: Standard Deviation (SD)\n\nVariability of the data values ($x$)\n:::\n\n::: callout-important\n### Definition: Standard Error (SE)\n\nVariability of the sample statistic (e.g. $\\bar{x}$ or $\\hat{p}$)\n:::\n\n\n## Margin of Error {.smaller}\n\n::: callout-important\n### Definition: Margin of Error (MOE)\n\nThe margin of error describes how far away observations are from their mean. \n\nOften approximated as $2 * SE$\n:::\n\n-   95% of the observations are within one margin of error of the mean.\n-   If the spread of the observations goes from some lower bound to some upper bound, a rough approximation of the $SE$ is to divide the range by 4.\n    -   If you notice the sample proportions go from 0.1 to 0.4, the SE can be approximated to be 0.075.\n\n## Summary\n\n-   Point estimates from a sample may be used to estimate population parameters.\n-   Point estimates are not exact: they vary from one sample to another.\n-   The standard error is the uncertainty of the sample statistic, and it gets smaller as you use more data to calculate the point estimate.\n-   As your standard error decreases, so does your margin of error\n\n# Case study: Stents\n\nThis example and data comes from [IMS 13.6](https://openintro-ims.netlify.app/foundations-mathematical.html#casestent)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstent30 <- openintro::stent30\n```\n:::\n\n\n\n## Observed data {.smaller}\n\nConsider an experiment that examined whether implanting a stent in the brain of a patient at risk for a stroke helps reduce the risk of a stroke. The results from the first 30 days of this study are summarized in the following table.\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(stent30$group, stent30$outcome) |> addmargins()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           \n            no event stroke Sum\n  control        214     13 227\n  treatment      191     33 224\n  Sum            405     46 451\n```\n\n\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(stent30$group, stent30$outcome) |>  prop.table(margin=1) |>round(digits=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           \n            no event stroke\n  control       0.94   0.06\n  treatment     0.85   0.15\n```\n\n\n:::\n:::\n\n\n:::\n:::\n\nThese results are surprising! The point estimate suggests that patients who received stents may have a higher risk of stroke: $p_{trmt}‚àíp_{ctrl}=0.090$.\n\n## Point estimate vs Interval estimate\n\nThe point estimate for the difference in proportions $p_{trmt}‚àíp_{ctrl}=0.090$ is a single point estimate, based on this single sample.\n\n\\\n\nA *point estimate* is our best guess for the value of the parameter, so it makes sense to build the confidence interval around that value.\n\n## Constructing a 95% confidence interval (CI)\n\nWhen the sampling distribution of a point estimate can *reasonably be modeled as having a normal distribution*, the point estimate we observe will be within 1.96 standard errors of the true value of interest about 95% of the time. Thus, a 95% confidence interval for such a point estimate can be constructed:\n\n$$\\mbox{point estimate} \\pm 1.96 √ó SE$$\n\nWe can be 95% confident this interval captures the true value.\n\n## Construct a 95% CI for the stent example {.smaller}\n\nThe conditions necessary to ensure the point estimate $p_{trmt}‚àíp_{ctrl}$ is nearly normal have been verified for you, and the estimate's standard error is $SE = 0.028$.\n\n-   Construct a 95% confidence interval for the change in 30-day stroke rates from usage of the stent.\n-   Interpret this interval in context of the problem.\n\n. . .\n\n$$0.090 \\pm 1.96√ó0.028 = (0.035,0.145)$$\n\nWe are 95% confident that implanting a stent in a stroke patient's brain increased the risk of stroke within 30 days by a rate of 0.035 to 0.145.\n\n## Important note\n\n:warning: it's incorrect to say that we can be 95% confident that the true value is inside the mean.\n\n![Figure 13.11: Twenty-five samples of size n=300 were collected from a population with p=0.30. For each sample, a confidence interval was created to try to capture the true proportion p. However, 1 of these 25 intervals did not capture p=0.30.](https://openintro-ims.netlify.app/foundations-mathematical_files/figure-html/fig-95PercentConfidenceInterval-1.png)\n\n## \n\n-   This is one of the most common errors: while it might be useful to think of it as a probability, the confidence level only quantifies how plausible it is that the parameter is in the interval.\n-   Our intervals say nothing about the confidence of capturing individual observations, a proportion of the observations, or about capturing point estimates.\n-   Confidence intervals provide an interval estimate for and attempt to capture population parameters.\n\n## Hypothesis test\n\n::: {.callout-note icon=\"false\"}\n## First draft\n\nLet's setup a hypothesis to test if stents work to reduce the risk of a stroke.\n:::\n\n\\\n\n$H_{0}$: Stents don't work\n\n$H_{A}$: Stents reduce the risk of a stroke\n\n## Hypothesis test\n\n::: {.callout-note icon=\"false\"}\n### Revision 1:\n\nMaking it a statement about two groups\n:::\n\n$H_{0}$: Patients who have a stent have the same risk of a stroke as patients who don't have a stent\n\n$H_{A}$: Patients who have a stent have lower risk of a stroke as patients who don't have a stent\n\n## Hypothesis test\n\n::: {.callout-note icon=\"false\"}\n### Revision 2:\n\nMake it a statement using summary statistics and removing the directionality of the hypothesis\n:::\n\n\n$H_{0}$: The proportion of patients with a stent who have a stroke is the same as the proportion of patients without a stent who have a stroke.\n\n$H_{A}$: The proportion of patients with a stent who have a stroke is different than the proportion of patients without a stent who have a stroke.\n\n## Hypothesis test\n\n::: {.callout-note icon=\"false\"}\n### Revision 3:\n\nWriting it in symbols\n:::\n\nLet $p_{trmt}$ be the proportion of patients with a stent who have a stroke, and $p_{ctrl}$ be the proportion of patients without a stent who have a stroke\n\n\\\n\n$H_{0}: p_{trmt} = p_{ctrl}$\n\n$H_{A}: p_{trmt} \\neq p_{ctrl}$\n\n## Hypothesis test\n\n::: {.callout-note icon=\"false\"}\n### Revision 3.5:\n\nRewriting as a difference in parameters\n:::\n\nLet $p_{trmt}$ be the proportion of patients with a stent who have a stroke, and $p_{ctrl}$ be the proportion of patients without a stent who have a stroke\n\n\\\n\n$H_{0}: p_{trmt} - p_{ctrl} = 0$\n\n$H_{A}: p_{trmt} - p_{ctrl} \\neq 0$\n\n## Using the Normal model\n\n-   Now we have a statistic (difference in proportions $p_{trmt} - p_{ctrl}$) and a null value of 0 to compare it to.\n\n-   The conditions necessary to ensure the point estimate is nearly normal have been verified for you.\n\n-   The estimate‚Äôs standard error is $SE = 0.028$ has been calculated for you as well.\n\n## Calculating a test statistic & p-value {.smaller}\n\n$$ Z = \\frac{\\mbox{point estimate - null value}}{SE}$$\n\n. . .\n\n$$ Z = \\frac{(p_{trmt} - p_{ctrl}) - 0}{SE_{p_{trmt} - p_{ctrl}}} = \\frac{.090}{.028} = 3.21 $$\n\n. . .\n\n$$ P(Z > 3.2) = .00068 \\qquad \\mbox{ (the p-value)}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1-pnorm(3.2, 0, 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0006871379\n```\n\n\n:::\n:::\n\n\n\n. . .\n\nIf the true difference in proportions was 0, then the probability of observing a difference of 0.09 due to random chance is 0.00068.\n\n## \n\n![https://xkcd.com/1478/](https://imgs.xkcd.com/comics/p_values.png)\n\n## Using Confidence Intervals to test a hypothesis\n\n> We are 95% confident that implanting a stent in a stroke patient's brain increased the risk of stroke within 30 days by a rate of 0.035 to 0.145.\n\nSince the interval does not contain the null hypothesized value of 0 (is completely above 0), it means the data provide convincing evidence that the stent used in the study changed the risk of stroke within 30 days\n",
    "supporting": [
      "lec06b-statistical_inference_with_models_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}