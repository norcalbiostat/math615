[
  {
    "objectID": "topics.html",
    "href": "topics.html",
    "title": "Topics",
    "section": "",
    "text": "This is the place to start to find all content related to a module.\n\n\n\n\n\n\n\n\n\n\nTopic\n\n\n\nDescription\n\n\n\n\n\n\n\n\nWelcome to Math 615\n\n\nIntroduction to class and your learning materials\n\n\n\n\n\n\nData Architecture\n\n\nData entry, spreadsheets, metadata, codebooks\n\n\n\n\n\n\nFormulating research questions\n\n\nAsking questions is easy. Asking answerable questions is more difficult.\n\n\n\n\n\n\nPreparing Data for Analysis\n\n\nWhere an inordinate amount of time is spent\n\n\n\n\n\n\nDescribing distributions of data\n\n\nVisualizing your data is the first line of defense against bad data\n\n\n\n\n\n\nDescribing Relationships\n\n\nFirst step in investigating a question about an association\n\n\n\n\n\n\nFoundations for Statistical Inference\n\n\nStudy Design, Inference using randomization and the Normal Model\n\n\n\n\n\n\nModeling Bivariate Relationships\n\n\nIdentify and conduct the most appropriate analysis for a given research topic. \n\n\n\n\n\n\nIntroduction to Regression modeling\n\n\nEverything is a linear model\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "topics/t07-bivariate_modeling.html",
    "href": "topics/t07-bivariate_modeling.html",
    "title": "Modeling Bivariate Relationships",
    "section": "",
    "text": "Visually exploring relationships between two variables by creating appropriate plots to assess how the distribution of a primary outcome (response/dependent) variable changes according to the level of a predictor (explanatory/independent/covariate) variable.\nLearning how probability is used to make inferential statements about parameters\n\n\n\n\nReady to make some statistical statements about relationships between variables.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nFully conduct the following statistical analyses: Two sample T-Test of means, ANOVA, Chi-squared test of Association, Correlation"
  },
  {
    "objectID": "topics/t07-bivariate_modeling.html#learning-path",
    "href": "topics/t07-bivariate_modeling.html#learning-path",
    "title": "Modeling Bivariate Relationships",
    "section": "",
    "text": "Visually exploring relationships between two variables by creating appropriate plots to assess how the distribution of a primary outcome (response/dependent) variable changes according to the level of a predictor (explanatory/independent/covariate) variable.\nLearning how probability is used to make inferential statements about parameters\n\n\n\n\nReady to make some statistical statements about relationships between variables.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nFully conduct the following statistical analyses: Two sample T-Test of means, ANOVA, Chi-squared test of Association, Correlation"
  },
  {
    "objectID": "topics/t07-bivariate_modeling.html#learning-materials",
    "href": "topics/t07-bivariate_modeling.html#learning-materials",
    "title": "Modeling Bivariate Relationships",
    "section": "Learning Materials",
    "text": "Learning Materials\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec07a - Choosing\n\n\nlec07b T-test\n\n\nlec07c - ANOVA\n\n\nlec07d - Chi2\n\n\nlec07e - Correlation\n\n\n\n\n\n\n\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nIMS - Chapter 20\n\n\nIMS - Chapter 22\n\n\nPMA6 Chapter 6\n\n\nASCN Ch 5\n\n\n\n\n\n\n\nüé¶ Video\nPre-recorded lectures are available in Canvas. Some recordings are from a prior semester but the slides are mostly the same."
  },
  {
    "objectID": "topics/t07-bivariate_modeling.html#assignments",
    "href": "topics/t07-bivariate_modeling.html#assignments",
    "title": "Modeling Bivariate Relationships",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nHW07"
  },
  {
    "objectID": "topics/t07-bivariate_modeling.html#assessment",
    "href": "topics/t07-bivariate_modeling.html#assessment",
    "title": "Modeling Bivariate Relationships",
    "section": "Assessment",
    "text": "Assessment\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nQuiz 07\n\n\nQuiz 08"
  },
  {
    "objectID": "topics/t05-describing_relationships.html",
    "href": "topics/t05-describing_relationships.html",
    "title": "Describing Relationships",
    "section": "",
    "text": "Visualizing a single variable\nScreening for potential errors and additional data management\nStarting to describe our project data\n\n\n\n\n\nReady to visualize and describe associations between multiple variables.\n\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nCalculate appropriate summary statistics for grouped variables\n\n\nCreate appropriate data visualizations for grouped variables\n\n\nDescribe the relationship between two measures in complete sentences with supporting numbers."
  },
  {
    "objectID": "topics/t05-describing_relationships.html#learning-path",
    "href": "topics/t05-describing_relationships.html#learning-path",
    "title": "Describing Relationships",
    "section": "",
    "text": "Visualizing a single variable\nScreening for potential errors and additional data management\nStarting to describe our project data\n\n\n\n\n\nReady to visualize and describe associations between multiple variables.\n\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nCalculate appropriate summary statistics for grouped variables\n\n\nCreate appropriate data visualizations for grouped variables\n\n\nDescribe the relationship between two measures in complete sentences with supporting numbers."
  },
  {
    "objectID": "topics/t05-describing_relationships.html#learning-materials",
    "href": "topics/t05-describing_relationships.html#learning-materials",
    "title": "Describing Relationships",
    "section": "Learning Materials",
    "text": "Learning Materials\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec05a\n\n\nlec05b\n\n\n\n\n\n\n\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nPMA6 Ch 4.6\n\n\nPMA6 Ch 4\n\n\nIMS 1.2.4 Explantory and Response Variables\n\n\nASCN Ch 2.4"
  },
  {
    "objectID": "topics/t05-describing_relationships.html#active-learning",
    "href": "topics/t05-describing_relationships.html#active-learning",
    "title": "Describing Relationships",
    "section": "üìù Active Learning",
    "text": "üìù Active Learning\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nHW05"
  },
  {
    "objectID": "topics/t05-describing_relationships.html#assessment",
    "href": "topics/t05-describing_relationships.html#assessment",
    "title": "Describing Relationships",
    "section": "Assessment",
    "text": "Assessment\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nQuiz 04\n\n\nProject Phase 3\n\n\nReport Draft"
  },
  {
    "objectID": "topics/t03-data_prep.html",
    "href": "topics/t03-data_prep.html",
    "title": "Preparing Data for Analysis",
    "section": "",
    "text": "Learning how to read our data and ask questions that are potentially answerable with this data.\n\n\n\n\nStarting to write code.\nRecognizing that this stage will take time and that you are learning something challenging.\nWilling to ask for help and collaboration\n\n\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nKnow several questions to ask yourself when preparing data for analysis\n\n\nUnderstand options for literate programming\n\n\nImport your chosen data into R\n\n\nCreate a reproducible script file that imports the raw data, performs data management tasks, exports an analysis ready data set"
  },
  {
    "objectID": "topics/t03-data_prep.html#learning-path",
    "href": "topics/t03-data_prep.html#learning-path",
    "title": "Preparing Data for Analysis",
    "section": "",
    "text": "Learning how to read our data and ask questions that are potentially answerable with this data.\n\n\n\n\nStarting to write code.\nRecognizing that this stage will take time and that you are learning something challenging.\nWilling to ask for help and collaboration\n\n\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nKnow several questions to ask yourself when preparing data for analysis\n\n\nUnderstand options for literate programming\n\n\nImport your chosen data into R\n\n\nCreate a reproducible script file that imports the raw data, performs data management tasks, exports an analysis ready data set"
  },
  {
    "objectID": "topics/t03-data_prep.html#preparation",
    "href": "topics/t03-data_prep.html#preparation",
    "title": "Preparing Data for Analysis",
    "section": "Preparation",
    "text": "Preparation\nIn Homework 00 you downloaded and installed R and R Studio, and used it to import a data file in Homework 01. There are a few more steps to take that will allow you to be best setup for using R to analyze data.\nFollow the instructions in the Appendix of the Applied Stats Course Notes to do the following:\n\nSet preferences for sanity (19.5)\nInstall the tidyverse and here packages (19.6)\nCreate a R project using the MATH615 folder that you created in step 1. (ASCN 19.7)\n\nShut down R studio fully, navigate to your class folder, and open your project file (the cube) before you continue.\n\nRead through and follow the ‚ÄúHello Quarto‚Äù tutorial (19.8 intro)\nInstall the tinytex program so you can create PDFs from your Quarto document. This is required (19.8)\n\nIf you have difficulty with any of this, visit Community Coding, my office hours, or post in Discord."
  },
  {
    "objectID": "topics/t03-data_prep.html#learning-materials",
    "href": "topics/t03-data_prep.html#learning-materials",
    "title": "Preparing Data for Analysis",
    "section": "Learning Materials",
    "text": "Learning Materials\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec03a\n\n\nlec03b\n\n\n\n\n\n\n\nWe will also be using the Data Management chapter of the Applied Stats notebook for this topic.\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nPMA6 Ch 3\n\n\nUse R Projects\n\n\nProject Structure by Danielle Navarro"
  },
  {
    "objectID": "topics/t03-data_prep.html#active-learning",
    "href": "topics/t03-data_prep.html#active-learning",
    "title": "Preparing Data for Analysis",
    "section": "üìù Active Learning",
    "text": "üìù Active Learning\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nHello, Quarto\n\n\nHW03"
  },
  {
    "objectID": "topics/t03-data_prep.html#assessment",
    "href": "topics/t03-data_prep.html#assessment",
    "title": "Preparing Data for Analysis",
    "section": "Assessment",
    "text": "Assessment\nThis quiz will contain questions that reference topics in the PMA6. Don‚Äôt rely only on the slides for your answers.\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nQuiz 02"
  },
  {
    "objectID": "topics/t03-data_prep.html#other-references",
    "href": "topics/t03-data_prep.html#other-references",
    "title": "Preparing Data for Analysis",
    "section": "Other references",
    "text": "Other references\n\nANYTHING by Danielle Navarro or Jenny Bryan\nR projects\nWhy should I use the here package when I‚Äôm already using projects?\nHello, Quarto\n\n\nWhere you‚Äôll start\n\n\n\n\nWhere you‚Äôll end up"
  },
  {
    "objectID": "topics/t01-data_arch.html",
    "href": "topics/t01-data_arch.html",
    "title": "Data Architecture",
    "section": "",
    "text": "Getting all of our learning tools together.\n\n\n\nReady to learn how to interact with data.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nData is recorded in different manners\n\n\nSpreadsheets are a common method of recording data\n\n\nCodebooks are an essential piece in learning about the data\n\n\nThere is a difference between human readable and computer readable data formats"
  },
  {
    "objectID": "topics/t01-data_arch.html#learning-path",
    "href": "topics/t01-data_arch.html#learning-path",
    "title": "Data Architecture",
    "section": "",
    "text": "Getting all of our learning tools together.\n\n\n\nReady to learn how to interact with data.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nData is recorded in different manners\n\n\nSpreadsheets are a common method of recording data\n\n\nCodebooks are an essential piece in learning about the data\n\n\nThere is a difference between human readable and computer readable data formats"
  },
  {
    "objectID": "topics/t01-data_arch.html#learning-materials",
    "href": "topics/t01-data_arch.html#learning-materials",
    "title": "Data Architecture",
    "section": "Learning Materials",
    "text": "Learning Materials\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec01\n\n\n\n\n\n\n\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nPMA6 Ch 2\n\n\nTidy data principles"
  },
  {
    "objectID": "topics/t01-data_arch.html#active-learning",
    "href": "topics/t01-data_arch.html#active-learning",
    "title": "Data Architecture",
    "section": "üìù Active Learning",
    "text": "üìù Active Learning\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nHW01"
  },
  {
    "objectID": "topics/t01-data_arch.html#assessment",
    "href": "topics/t01-data_arch.html#assessment",
    "title": "Data Architecture",
    "section": "Assessment",
    "text": "Assessment\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nQuiz 01"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course provides a hands-on introduction to using data to rigorously answer research questions. Students practice cleaning and manipulating data, creating data visualizations, and conducting introductory level statistical analysis using real-world data sets that are relevant to their field. Analysis topics include single and two-sample inference, analysis of variance, multiple regression, analysis of co-variance, experimental design, repeated measures, nonparametric procedures, and categorical data analysis. Reproducible research is strongly emphasized through the use of statistical computing software (e.g.¬†SPSS, Stata, SAS, R, Python). Recommended for all majors that use data for research. 3 hours discussion.\n\n\n\nName & pronouns: Dr.¬†Robin Donatello (Dr.¬†D, she/her)\nWebsite: https://www.norcalbiostat.com/\nOffice Location: Holt 202\nE-mail: rdonatello@csuchico.edu\nBest Contact Method: Discord\nStudent Office Hours: TBD\n\n\n\n\n\nMeeting Pattern: MW 4-5:15, Holt 155\nPrerequisites: Basic computer literacy. Recent statistics course such as Math 105, MATH 315, or MATH 350.\nMode of Instruction: In Person.\n\n\n\n\nHomework 0 provides a checklist for you to make sure you have everything.\n\nClass website: https://norcalbiostat.github.io/MATH615/\nTextbook (Required): Practical Multivariate Analysis (PMA6), 6th ed by Afifi, May, Donatello, Clark. [Link] There are several available in the library and I have two I can check out for the semester.\nTextbook (Required): Introduction to Modern Statistics (IMS). Free e-book/pdf at https://openintro-ims.netlify.app\nLaptop & Internet: Expect to bring your laptop to class every day. Contact me if this poses a problem or concern for you. Refer to ITSS for help with internet.\nData Analysis software: R and R Studio\nCanvas: Assignmnent submission, gradebook, class schedule/calendar\nGoogle Drive: Quizzes and collaborative work.\nDiscord: A free discussion platform with a lot of collaborative functionality. The defacto method of communication for the class."
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Syllabus",
    "section": "",
    "text": "Name & pronouns: Dr.¬†Robin Donatello (Dr.¬†D, she/her)\nWebsite: https://www.norcalbiostat.com/\nOffice Location: Holt 202\nE-mail: rdonatello@csuchico.edu\nBest Contact Method: Discord\nStudent Office Hours: TBD"
  },
  {
    "objectID": "syllabus.html#meeting-logistics",
    "href": "syllabus.html#meeting-logistics",
    "title": "Syllabus",
    "section": "",
    "text": "Meeting Pattern: MW 4-5:15, Holt 155\nPrerequisites: Basic computer literacy. Recent statistics course such as Math 105, MATH 315, or MATH 350.\nMode of Instruction: In Person."
  },
  {
    "objectID": "syllabus.html#required-materials-and-accounts",
    "href": "syllabus.html#required-materials-and-accounts",
    "title": "Syllabus",
    "section": "",
    "text": "Homework 0 provides a checklist for you to make sure you have everything.\n\nClass website: https://norcalbiostat.github.io/MATH615/\nTextbook (Required): Practical Multivariate Analysis (PMA6), 6th ed by Afifi, May, Donatello, Clark. [Link] There are several available in the library and I have two I can check out for the semester.\nTextbook (Required): Introduction to Modern Statistics (IMS). Free e-book/pdf at https://openintro-ims.netlify.app\nLaptop & Internet: Expect to bring your laptop to class every day. Contact me if this poses a problem or concern for you. Refer to ITSS for help with internet.\nData Analysis software: R and R Studio\nCanvas: Assignmnent submission, gradebook, class schedule/calendar\nGoogle Drive: Quizzes and collaborative work.\nDiscord: A free discussion platform with a lot of collaborative functionality. The defacto method of communication for the class."
  },
  {
    "objectID": "syllabus.html#schedule-of-topics",
    "href": "syllabus.html#schedule-of-topics",
    "title": "Syllabus",
    "section": "Schedule of Topics",
    "text": "Schedule of Topics\nThe general ordering of topics is:\n\nData Collection and recording\nPreparing data for analysis\nData Visualization\nFoundations for Inference: probability distributions, point and interval estimation, Hypothesis Testing\nInference comparing multiple samples (t-tests, ANOVA, \\(\\chi^{2}\\) tests)\nStudy design, confounding, causation\nLinear regression analysis (Simple and Multiple, Categorical predictors, variable selection)\nLogistic regression analysis\nModel building techniques and comparing model fit"
  },
  {
    "objectID": "syllabus.html#what-am-i-graded-on",
    "href": "syllabus.html#what-am-i-graded-on",
    "title": "Syllabus",
    "section": "What am I graded on?",
    "text": "What am I graded on?\nI care both that you are keeping up with the material, but also that by the end of the term you can conduct your own personalized analysis on a new data set. Here is how I check in on your progress throughout the semester\n\nQuizzes on the current or prior content. Quizzes are a great way to test yourself, enhance recall, and self-assess your comprehension of the subject. Quizzes are administered in Google Forms, and done in two parts.\n\nIndividual: First try to answer as many questions without looking at your notes. Then use your notes to answer the rest.\nGroup: After the individual quiz closes I will choose 1-4 questions that scored the lowest. We will do a class-wide discussion of those topics, then you will work in groups to redo the selected questions for half credit.\n\nAssignments This is your testing ground, your first round of practice. Can you take what you learned and apply it to a data set. Graded on completeness and effort.\nPeer reviews Helping others enhances your own understanding.\nProject Can you weave together data and story to do research? This is your second round of practice. Your work should be more polished than in your homework, and I will be grading them in more detail and using a rubric.\nComprehensive Final Exam Can you identify and apply correct statistical theory to new situations?"
  },
  {
    "objectID": "syllabus.html#okay-but-what-about-the-points",
    "href": "syllabus.html#okay-but-what-about-the-points",
    "title": "Syllabus",
    "section": "Okay, but what about the points?",
    "text": "Okay, but what about the points?\n\nThe gradebook in Canvas contains columns for all graded materials with point values and rubrics.\nThe project uses a mastery based grading system that allows you to continue to revise your work until it reaches an acceptable level of quality. The details are described on the Project page.\nSee here for info on grading peer reviews.\n\nYour final grade will be displayed as a running total in Canvas. The grades are weighted by category as follows:\n\nAssignments: 25%\nQuizzes: 25%\nPeer Reviews: 5%\n\nComprehensive Exam: 15%\nProject: 30%\n\nI use a standard grade cutoff of 100-90%: A, 89-80%: B, 79-70%: C."
  },
  {
    "objectID": "syllabus.html#late-work",
    "href": "syllabus.html#late-work",
    "title": "Syllabus",
    "section": "Late work",
    "text": "Late work\nI don‚Äôt penalize for late work, but I prioritize on time submissions. If you submit an assignment after I‚Äôm done grading everyone elses, and we‚Äôre moving on to the next topic then your assignment may have to wait a week before I can get back to it. That is likely to negatively impact your ability to move forward and to get feedback in time.\nThere are exceptions for when your work is peer reviewed. There is no grace period for peer reviews. You must be responsible and timely for your colleagues."
  },
  {
    "objectID": "syllabus.html#everyone-is-welcome-here",
    "href": "syllabus.html#everyone-is-welcome-here",
    "title": "Syllabus",
    "section": "Everyone is welcome here",
    "text": "Everyone is welcome here\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit. It is my intent to present materials and activities that are respectful of diversity: gender identity, sexuality, disability, age, socioeconomic status, ethnicity, race, nationality, religion, and culture. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nI would like to create a learning environment that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this:\n\nLet me know if you have a name and/or set of pronouns that differ from those that appear in your official Chico records. I make it a point to call on people by name, so please make sure that I know what you want to be called. - I also want to try to pronounce your name as accurately as possible. The more you help and correct me the better I can do to honor your name.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. I want to be a resource for you. Remember that you can also submit anonymous feedback using the feedback button on the schedule and help pages of the website (which will lead to me making a general announcement to the class, if necessary to address your concerns).\nIf you prefer to speak with someone outside of the course, the Office of Diversity and Inclusion is here to assist. Their number is 530-898-4764, and email diversityoffice@csuchico.edu\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it. (Again, anonymous feedback is always an option).\n\nAdapted from Monica Linden at Brown University.\nFurthermore, I would like to acknowledge that Chico State stands on lands that were originally occupied by the first people of this area, the Mechoopda. I recognize their distinctive spiritual relationship with this land and the waters that run through campus. I am humbled that our campus resides upon sacred lands that once sustained the Mechoopda people for centuries."
  },
  {
    "objectID": "syllabus.html#attendance",
    "href": "syllabus.html#attendance",
    "title": "Syllabus",
    "section": "Attendance",
    "text": "Attendance\nClass attendance is expected. Talk to me ahead of time if you need to miss a class for a planned reason. In the event of an unplanned reason, PM me in Discord when you can so that I know you are still alive.\nThis is a graduate class and you all are adults with lives outside this class. Things happen. Each class session will be live streamed, with the recording posted to Canvas within a few days. Common reasons to join the class virtually: - you‚Äôre sick - you‚Äôre out of town\nDon‚Äôt expect as good of quality of presentation, and this is not a long term solution/resource. Don‚Äôt abuse this resource."
  },
  {
    "objectID": "syllabus.html#academic-integrity",
    "href": "syllabus.html#academic-integrity",
    "title": "Syllabus",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nStudents are expected to be familiar with the University‚Äôs Policy on Student Academic Integrityhttps://www.csuchico.edu/pres/_assets/documents/em-25-015.pdf. Specific sections of this policy are highlighted below as they pertain to this class. Refer to the linked document for definitions.\nAs an instructor I recognize there are a variety of AI programs available to assist in creating text and writing code. However, I want to stress that, AI programs are not a replacement for human creativity, originality, and critical thinking. Writing (text and code) is a skill that you must nurture over time in order to develop your own individual voice, style, and view.\nThe use of chat GPT is allowed/encouraged to help you learn how to code but all code used must be fully explained in text. We will cover what this means and how to do this when we start data management around week 3. How ChatGPT can help you write code\nYou are responsible for fact checking the accuracy of statements composed by AI language models. These models are known to produce bullshit responses. And yes, this is a technical term.\n\nAI and ChatGPT Usage: AI writing or coding tools are not permitted for any stage or phase of work in this class. Using AI to help debug, or suggest coding approaches is a useful tool for any coder - but only once you have a solid foundation.\nCollaboration: You are highly encouraged to work together with a classmate to learn the materials in this class. However your work must be 100% a product of your personal effort. Coding styles are similar to writing styles, each person will have their own unique voice and style.\nPlagiarism and Self-Plagiarism: Plagiarism from the course notes and from your prior work are highly encouraged. Don‚Äôt try to start from scratch each time. If you‚Äôve done something before and need it again - find it and copy/paste/adjust. The biggest benefit to programming in a language such as R is to automate repetitive tasks, and ensure your work is reproducible. Self-plagiarism is a hallmark of a good programmer.\n\n\n\n\n\n\n\nBe up front!\n\n\n\nWhen presenting text written by Artificial intelligence (AI) language models, such as ChatGPT, you must include an appropriate citation. https://apastyle.apa.org/blog/how-to-cite-chatgpt\nThis also goes for when you have it write code for you. You need to indicate when and where you used it.\n\n\n\nNot allowed\n\nWorking with or getting help from others on exams and individual quizzes\nCopying code from another student‚Äôs homework and presenting it as your own work.\nCopy/paste from AI tools or internet sources without customization, citation or explanation\nGetting your sibling/friend/colleague to write code for you\nSubmitting any assignment that is not your own personal effort.\n\n\n\nAllowed\n\nHelping each other solve homework problems (concepts or code)\nUse AI to help explain a concept\nUse AI to generate starter code that you modify for your own example.\nUse AI to write code that you cite/disclose and you explain in your words what it is doing in details.\nCopy/paste code from my course notes (this is actually encouraged!)\n\n\nIf at any time I suspect that the work you are submitting is not reflective of your personal knowledge I may ask you to verbally explain a piece of code to me. If your explanation is insufficient may result in a 0 on that assignment.\nAny use outside of this permission constitutes a violation of Chico State‚Äôs Integrity Policy and may result in you being reported to the Office of Students Rights and Responsibilities.\nYour own commitment to learning, as evidenced by your enrollment at California State University, Chico, and the University‚Äôs Academic Integrity Policy requires you to be honest in all your academic course work. If you act against these policies your actions will be considered academically dishonest, and a violation of Chico State‚Äôs Integrity Policy and you may be reported to the Office of Students Rights and Responsibilities.Faculty members are required to report all infractions to the Office of Student Judicial Affairs."
  },
  {
    "objectID": "syllabus.html#confidentiality-and-mandatory-reporting",
    "href": "syllabus.html#confidentiality-and-mandatory-reporting",
    "title": "Syllabus",
    "section": "Confidentiality and Mandatory Reporting",
    "text": "Confidentiality and Mandatory Reporting\nAs an instructor, one of my responsibilities is to help create a safe learning environment on our campus. I also have a mandatory reporting responsibility related to my role as a your instructor. I am required to share information regarding sexual misconduct with the University. Students may speak to someone confidentially by contacting the Counseling and Wellness Center (898-6345) or Safe Place (898-3030). Information on campus reporting obligations and other Title IX related resources are available here: www.csuchico.edu/title-ix."
  },
  {
    "objectID": "slides/lec08-slr.html#purpose-of-regression-modeling",
    "href": "slides/lec08-slr.html#purpose-of-regression-modeling",
    "title": "Simple Linear Regression Modeling",
    "section": "Purpose of Regression Modeling",
    "text": "Purpose of Regression Modeling\n\nLearn more about the relationship between several independent or predictor variables and a quantitative dependent (response) variable.\nRegression is widely used in research as it allows us to ask the general question ‚Äúwhat is the best predictor of‚Ä¶‚Äù, and does ‚Äúadditional variable A‚Äù or ‚Äúadditional variable B confound the relationship between my explanatory and response variable?‚Äù\n\nBoth Regression and Correlation can be used to\n\nDescriptive: Draw inferences regarding the relationship\nPredictive: Predict the value of \\(Y\\) for given values of one or more \\(X\\)‚Äôs."
  },
  {
    "objectID": "slides/lec08-slr.html#examples-in-practice",
    "href": "slides/lec08-slr.html#examples-in-practice",
    "title": "Simple Linear Regression Modeling",
    "section": "Examples in practice",
    "text": "Examples in practice\n\nEducational researchers might want to learn about the best predictors of success in high-school.\nSociologists may want to find out which of the multiple social indicators best predict whether or not a new immigrant group will adapt to their new country of residence.\nBiologists may want to find out which factors (i.e.¬†temperature, barometric pressure, humidity, etc.) best predict caterpillar reproduction."
  },
  {
    "objectID": "slides/lec08-slr.html#example---lung-function",
    "href": "slides/lec08-slr.html#example---lung-function",
    "title": "Simple Linear Regression Modeling",
    "section": "Example - Lung function",
    "text": "Example - Lung function\n\n\n\nLung function data were obtained from an epidemiological study of households living in four areas with different amounts and types of air pollution. The data set used in PMA6 is a subset of the total data. In this example we use only the data taken on the fathers, all of whom are nonsmokers.\n\n\n\nOne of the major early indicators of reduced respiratory function is FEV1 or forced expiratory volume in the first second (amount of air exhaled in 1 second). Since it is known that taller males tend to have higher FEV1, we wish to determine the relationship between height and FEV1. We can use regression analysis for both a descriptive and predictive purpose.\n\nDescriptive: Describing the relationship between FEV1 and height\nPredictive: Determine the expected or normal FEV1 for a given height"
  },
  {
    "objectID": "slides/lec08-slr.html#visualize-the-relationship",
    "href": "slides/lec08-slr.html#visualize-the-relationship",
    "title": "Simple Linear Regression Modeling",
    "section": "Visualize the relationship",
    "text": "Visualize the relationship\n\n\n\n\nShow the code\nggplot(fev, aes(y=FFEV1, x=FHEIGHT)) + \n  geom_point() + geom_smooth(se=FALSE, col=\"blue\") + \n  geom_smooth(se=FALSE, method = \"lm\", col=\"red\") + \n      xlab(\"Height\") + ylab(\"FEV1\") + \n      ggtitle(\"Scatterplot and Regression line of FEV1 \\n Versus Height for Males.\") + theme_bw() \n\n\n\n\n\n\n\n\n\n\n\nThere does appear to be a tendency for taller men to have higher FEV1. Since this relationship is reasonably linear (the blue loess line is similar to the red linear line) we can write the model the population average FEV \\(\\mu_{y}\\) as a linear function of height \\(x\\):\n\\[\n  \\mu_{y} = \\beta_{0} + \\beta_{1}x\n\\]\nThe intercept parameter, \\(\\beta_{0}\\), represents where the line crosses the y-axis when \\(x=0\\). The slope parameter, \\(\\beta_{1}\\), represents the change in \\(\\mu_{y}\\) per 1 unit \\(x\\)."
  },
  {
    "objectID": "slides/lec08-slr.html#unifying-model-framework",
    "href": "slides/lec08-slr.html#unifying-model-framework",
    "title": "Simple Linear Regression Modeling",
    "section": "Unifying model framework",
    "text": "Unifying model framework\nWe know that there is always random noise in real data (DATA = MODEL FIT + RESIDUAL) so we introduce a random error term, \\(\\epsilon_{i}\\) and assume the model:\n\\[\ny_{i} = \\beta_{0} + \\beta_{1} X + \\epsilon_{i} \\\\\n\\epsilon_{i} \\sim N(0, \\sigma^{2})\n\\]\nThis model states that the random variable \\(y\\) to be made up of a predictable part (a linear function of \\(x\\)) and an unpredictable part (the random error, \\(\\epsilon_{i}\\)). The error (residual) term includes the effects of all other factors, known or unknown."
  },
  {
    "objectID": "slides/lec08-slr.html#least-squares-estimation",
    "href": "slides/lec08-slr.html#least-squares-estimation",
    "title": "Simple Linear Regression Modeling",
    "section": "Least Squares Estimation",
    "text": "Least Squares Estimation\n\nMost common method of fitting a straight line to two variables.\nAlso known as ‚ÄúOrdinary Least Squares (OLS)‚Äù\nCalculates sample statistics \\(b_{0}\\) and \\(b_{1}\\) to estimate the population parameter values \\(\\beta_{0}\\) and \\(\\beta_{1}\\)\nThe estimated mean function is \\(\\hat{y}_{i} = b_{0} + b_{1}x_{i}\\)\nThe fitted value, \\(\\hat{y}_{i}\\), is the estimated value for point \\(i\\), calculated by plugging in a value for \\(x_{i}\\) and calculating the result.\n\nThe residual is the difference between the observed and the fitted value: \\(\\epsilon_{i} = y_{i}-\\hat{y}_{i}\\)"
  },
  {
    "objectID": "slides/lec08-slr.html#least-squares-estimation-1",
    "href": "slides/lec08-slr.html#least-squares-estimation-1",
    "title": "Simple Linear Regression Modeling",
    "section": "Least Squares Estimation",
    "text": "Least Squares Estimation\nThe estimates \\(b_{0}\\) and \\(b_{1}\\) are found such that they minimize the sum of the squared residuals (the unexplained residual error)\n\\[ \\sum_{i=1}^{n} \\epsilon_{i} \\]\nFor simple linear regression the regression coefficient estimates that minimize the sum of squared errors can be calculated as:\n\\[ \\hat{\\beta_{0}} = \\bar{y} - \\hat{\\beta_{1}}\\bar{x} \\quad \\mbox{  and  } \\quad  \\hat{\\beta_{1}} = r\\frac{s_{y}}{s_{x}} \\]\nwhere \\(r\\) is the correlation coefficient between \\(x\\) and \\(y\\)."
  },
  {
    "objectID": "slides/lec08-slr.html#revisiting-the-sum-of-squares",
    "href": "slides/lec08-slr.html#revisiting-the-sum-of-squares",
    "title": "Simple Linear Regression Modeling",
    "section": "Revisiting the Sum of Squares",
    "text": "Revisiting the Sum of Squares\nGo to: https://paternogbc.shinyapps.io/SS_regression/. Then turn and talk to your group about the following features of the Sum of Squares Graphs\n\n\nTotal\n\nWhat are the dots?\nWhat does the horizontal line represent?\nWhat do the blue lines represent?\n\n\nRegression\n\nWhat does the horizontal line represent?\nWhat does the sloped line represent?\nWhat are the green lines?\n\nError\n\nWhat are the dots?\nWhat does the sloped line represent?\nWhat do the red lines represent?"
  },
  {
    "objectID": "slides/lec08-slr.html#sum-of-squares---regression",
    "href": "slides/lec08-slr.html#sum-of-squares---regression",
    "title": "Simple Linear Regression Modeling",
    "section": "Sum of Squares - Regression",
    "text": "Sum of Squares - Regression\n\nSS Total- how far are the points away from \\(\\bar{y}\\)?\nSS Regression - how far away is the regression line from \\(\\bar{y}\\)?\nSS Error - how far are the points away from the estimated regression line?\n\nLooking at it this way, we are asking ‚ÄúIf I know the value of \\(x\\), how much better will I be at predicting \\(y\\) than if I were just to use \\(\\bar{y}\\)?"
  },
  {
    "objectID": "slides/lec08-slr.html#least-squares-estimation---in-r",
    "href": "slides/lec08-slr.html#least-squares-estimation---in-r",
    "title": "Simple Linear Regression Modeling",
    "section": "Least Squares Estimation - in R",
    "text": "Least Squares Estimation - in R\nA linear model using least squares estimation can be performed in R using the function lm(y ~ x)\n\nfev.model &lt;- lm(FFEV1 ~ FHEIGHT, data = fev)\nfev.model\n\n\nCall:\nlm(formula = FFEV1 ~ FHEIGHT, data = fev)\n\nCoefficients:\n(Intercept)      FHEIGHT  \n    -4.0867       0.1181  \n\n\nThe regression equation for the model to explain FEV1 using height as a predictor is:\n\\[ \\hat{y} = -4.087 + 0.118x \\]"
  },
  {
    "objectID": "slides/lec08-slr.html#using-this-model",
    "href": "slides/lec08-slr.html#using-this-model",
    "title": "Simple Linear Regression Modeling",
    "section": "Using this model",
    "text": "Using this model\n\\[ \\hat{y} = -4.087 + 0.118x \\]\n\n\\(b_{0}\\): For a father that is 0 cm tall, the predicted FEV is -4.087 (an impossible result)\n\\(b_{1}\\): For every additional cm taller a father is, his predicted FEV increases by 0.118L.\n\\(\\hat{y}_{x=70}\\): A father who is 70cm tall has a predicted FEV1 of \\(-4.087 + 0.118(70) = 4.17L\\)"
  },
  {
    "objectID": "slides/lec08-slr.html#other-facts-about-ls-regression",
    "href": "slides/lec08-slr.html#other-facts-about-ls-regression",
    "title": "Simple Linear Regression Modeling",
    "section": "Other facts about LS regression",
    "text": "Other facts about LS regression\n\nA change of one sd in \\(x\\) corresponds to a change of \\(r\\) sd in \\(y\\) since \\(b_{1}=r\\frac{s_{y}}{s_{x}}\\).\nIf the correlation is 0, the slope of the LS line is 0. A test of \\(\\beta_{1}=0\\) is equivalent to a test of \\(\\rho=0\\).\nThe LS line always passes through the point \\((\\bar{x}, \\bar{y})\\).\nThe distinction between explanatory and response variables is essential in regression. Reversing \\(x\\) and \\(y\\) results in a different regression line.\nThe Root Mean Squared Error (RMSE) is an estimate for \\(\\sigma\\)."
  },
  {
    "objectID": "slides/lec08-slr.html#mathematical-model",
    "href": "slides/lec08-slr.html#mathematical-model",
    "title": "Simple Linear Regression Modeling",
    "section": "Mathematical Model",
    "text": "Mathematical Model\nThe mathematical model that we use for regression has these features that translate into assumptions.\n\n\n\\[\n\\begin{align}\n  Y|X & \\sim N(\\mu_{Y|X}, \\sigma^{2}) \\\\\n  \\mu_{Y|X} & = \\beta_{0} + \\beta_{1} X \\\\\n   \\sigma^{2} & = Var(Y|X)\n\\end{align}\n\\]\n\n\n\nFigure 6.2\n\n\n\n\nIndependence The observations are the result of a simple random sample and thus are independent from each other\nLinearity: The mean of \\(Y\\) values at any given \\(X\\) follows a straight line\nNormality: \\(Y\\) values are normally distributed at any given \\(X\\)\nHomoscedasticity The variance of \\(Y\\) values at any \\(X\\) is \\(\\sigma^2\\) (same for all X)\nThe last two assumptions are checked by examining the residuals, and so can only be checked after the model has been fit."
  },
  {
    "objectID": "slides/lec08-slr.html#assumption---independence",
    "href": "slides/lec08-slr.html#assumption---independence",
    "title": "Simple Linear Regression Modeling",
    "section": "Assumption - Independence",
    "text": "Assumption - Independence\n\nKnowledge of the method of data collection here is key!\nIf the sampling method is not random, observations may not be independent.\nNo real good way to ‚Äútest‚Äù for independence. Need to know how the sample was obtained.\nNon simple random sample will not result in the same variance estimates\nCan use hierarchical/multi-level models for clustered samples"
  },
  {
    "objectID": "slides/lec08-slr.html#assumption---linearity",
    "href": "slides/lec08-slr.html#assumption---linearity",
    "title": "Simple Linear Regression Modeling",
    "section": "Assumption - Linearity",
    "text": "Assumption - Linearity\n\n\n\n\n\n\n\n\n\n\n\n\n\nSlight departures OK\nCan use transformations of strongly skewed data to achieve it\nThe lowess trend line reasonably follows a linear pattern.\n\n\n\nggplot(fev, aes(y=FFEV1, x=FHEIGHT)) + \n  geom_point() + \n  geom_smooth(col=\"blue\", se=FALSE) + \n  geom_smooth(method = \"lm\", col=\"red\", se=FALSE) + \n  theme_minimal()"
  },
  {
    "objectID": "slides/lec08-slr.html#assumption---normality",
    "href": "slides/lec08-slr.html#assumption---normality",
    "title": "Simple Linear Regression Modeling",
    "section": "Assumption - Normality",
    "text": "Assumption - Normality\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSlight departures OK\nCan use transformations to achieve it\n\nThese plots are generated from the performance package.\n\nplot(check_normality(fev.model), type=\"density\")\nplot(check_normality(fev.model), type=\"qq\")\n\n\nThe residuals follow a normal distribution well.\nDon‚Äôt let the pattern of the residuals on the qqplot fool you, the y-axis is very zoomed in."
  },
  {
    "objectID": "slides/lec08-slr.html#assumption---homoscedasticity",
    "href": "slides/lec08-slr.html#assumption---homoscedasticity",
    "title": "Simple Linear Regression Modeling",
    "section": "Assumption - Homoscedasticity",
    "text": "Assumption - Homoscedasticity\n\n\n\n\nShow the code\nplot(check_heteroskedasticity(fev.model))\n\n\n\n\n\n\n\n\n\n\n\nIf the variance (std. residual) changes with the value of \\(\\hat{y}\\), that is a sign of non-constant variance.\nViolations result in reduced validity of inference and typically larger standard errors for the coefficients.\nCould be caused by outliers or model mis-specificiation (e.g.¬†non-normal data)\nFEV Example - even though there is a slight increase in the trend of fitted values against the residuals, this is within the tolerance range."
  },
  {
    "objectID": "slides/lec08-slr.html#out-of-range-predictions",
    "href": "slides/lec08-slr.html#out-of-range-predictions",
    "title": "Simple Linear Regression Modeling",
    "section": "Out of range predictions",
    "text": "Out of range predictions\n\n\n\n\n\n\n\nFigure 6.2\n\n\n\n\n\n\n\n\n\nCaution!\n\n\nThe linear model is only valid within the range of the data used to fit the model\nTo take an extreme example, suppose a father was 2 feet tall. Then the equation would predict an impossible negative value of FEV1 (\\(-1.255\\)).\nA safe policy is to restrict the use of the equation to the range of the \\(X\\) observed in the sample."
  },
  {
    "objectID": "slides/lec08-slr.html#model-check",
    "href": "slides/lec08-slr.html#model-check",
    "title": "Simple Linear Regression Modeling",
    "section": "Model-check",
    "text": "Model-check\n\n\n\n\nShow the code\nplot(check_predictions(fev.model))\n\n\n\n\n\n\n\n\n\n\nAnother way of assessing model fit is to check the distribution of the predictions created by this model. A good fitting model should predict values that are similar to the observed data used to fit the model."
  },
  {
    "objectID": "slides/lec08-slr.html#distribution-of-parameter-estimates",
    "href": "slides/lec08-slr.html#distribution-of-parameter-estimates",
    "title": "Simple Linear Regression Modeling",
    "section": "Distribution of parameter estimates",
    "text": "Distribution of parameter estimates\n\nThe estimated coefficients are functions of both \\(x\\) and \\(y\\), and they are not themselves independent of each other (e.g.¬†\\(Cov(b_{0}, b_{1}) \\neq 0)\\).\nThe joint vector \\(\\hat{\\beta}(y, x)= (b_{0}, b_{1})\\) has a multivariate normal distribution, with variance that depends on the predictor variables \\(x\\) only.\n\n\\[\n\\hat{\\beta}(y, x) \\sim \\mathcal{N}(\\beta, \\mathbf{x^{T}x}^{-1}\\sigma^{2})\n\\]\n\nThe normality of the vector \\(\\hat{\\beta}\\) is quite robust to the model assumptions.\nEven if the residuals are not normally distributed, the CLT ensures that the \\(\\hat{\\beta}\\) are close to normal\nWhen sample sizes are low in a category, or \\(Var(X)\\) is close to zero, \\(x^{T}x\\) can‚Äôt be inverted - leading to errors of ‚Äúnon positive definite‚Äù"
  },
  {
    "objectID": "slides/lec08-slr.html#calculating-confidence-intervals",
    "href": "slides/lec08-slr.html#calculating-confidence-intervals",
    "title": "Simple Linear Regression Modeling",
    "section": "Calculating Confidence Intervals",
    "text": "Calculating Confidence Intervals\n\\[ b_{p} \\pm 1.96*SE(b_{p})\\]\n\npoint estimate \\(\\pm\\) critical value * standard error of estimate\n\nBut calculating the variance of \\(b_{p}\\) involves \\(\\mathbf{x^{T}x}^{-1}\\sigma^{2}\\), which is outside the scope of this class. So, we use R functions\n\nconfint(fev.model)\n\n                  2.5 %     97.5 %\n(Intercept) -6.36315502 -1.8102499\nFHEIGHT      0.08526328  0.1509472\n\n\nWe can be 95% confident that the true slope parameter between a fathers height and his FEV1 is contained in the interval (0.085, 0.151)."
  },
  {
    "objectID": "slides/lec08-slr.html#hypotheis-testing",
    "href": "slides/lec08-slr.html#hypotheis-testing",
    "title": "Simple Linear Regression Modeling",
    "section": "Hypotheis Testing",
    "text": "Hypotheis Testing\nLet \\(\\beta_1\\) be the true slope parameter that describes the change in FEV1 as a function of height in cm.\n\n\\(H_{0}: \\beta_{1}=0\\) There is no linear relationship between FEV1 and Height\n\\(H_{A}: \\beta_{1} \\neq 0\\) Alternate Hypothesis: There is a linear relationship between FEV1 and Height\n\n\n\nShow the code\nbroom::tidy(fev.model) |&gt; kable(digits=3) #kable is in the knitr package\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4.087\n1.152\n-3.548\n0.001\n\n\nFHEIGHT\n0.118\n0.017\n7.106\n0.000\n\n\n\n\n\nThe p-value for \\(b_{1}\\) is &lt;.0001, so there is sufficient evidence to believe that there is a linear relationship between FEV1 and Height of fathers."
  },
  {
    "objectID": "slides/lec08-slr.html#write-a-conclusion",
    "href": "slides/lec08-slr.html#write-a-conclusion",
    "title": "Simple Linear Regression Modeling",
    "section": "Write a conclusion",
    "text": "Write a conclusion\n\n\nBase R (ish)\n\nfev.model |&gt; coefficients() \n\n(Intercept)     FHEIGHT \n -4.0867025   0.1181052 \n\nfev.model |&gt; confint()\n\n                  2.5 %     97.5 %\n(Intercept) -6.36315502 -1.8102499\nFHEIGHT      0.08526328  0.1509472\n\nfev.model |&gt; r2() # from the performance package\n\n# R2 for Linear Regression\n       R2: 0.254\n  adj. R2: 0.249\n\n\n\ngtsummary package\n\ntbl_regression(fev.model) %&gt;% \n  add_glance_table(include = c(nobs, r.squared))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\nFHEIGHT\n0.12\n0.09, 0.15\n&lt;0.001\n\n\nNo. Obs.\n150\n\n\n\n\n\n\nR¬≤\n0.254\n\n\n\n\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nConclusion\nEach 1cm increase in height of a father is associated with a significant increase of 0.118 (0.09, 0.15) L of FEV1 (p&lt;.0001). Height explains 25.4% of the variation in FEV1."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#opening-remarks",
    "href": "slides/lec07d-chi_squared.html#opening-remarks",
    "title": "Inference on proportions",
    "section": "Opening Remarks",
    "text": "Opening Remarks\nIf we are only concerned with testing the hypothesis that the proportion of successes between two groups are equal \\(p_{1}-p_{2}=0\\), we can leverage the Normal distribution and conduct a Z-test for two proportions.\nHowever in this class we will use the more generalizable model via Chi-squared test of association/equal proportions."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#chi-squared-test-of-equal-proportions",
    "href": "slides/lec07d-chi_squared.html#chi-squared-test-of-equal-proportions",
    "title": "Inference on proportions",
    "section": "Chi-squared test of equal proportions",
    "text": "Chi-squared test of equal proportions\nA 30-year study was conducted with nearly 90,000 female participants. (Miller AB. 2014) During a 5-year screening period, each woman was randomized to one of two groups: in the first group, women received regular mammograms to screen for breast cancer, and in the second group, women received regular non-mammogram breast cancer exams. No intervention was made during the following 25 years of the study, and we‚Äôll consider death resulting from breast cancer over the full 30-year period."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#results-from-study",
    "href": "slides/lec07d-chi_squared.html#results-from-study",
    "title": "Inference on proportions",
    "section": "Results from study",
    "text": "Results from study\n\n\n\n\n\n\nAlive\nDead\nSum\n\n\n\n\nControl\n44405\n505\n44910\n\n\nMammogram\n44425\n500\n44925\n\n\nSum\n88830\n1005\n89835\n\n\n\n\n\nThe explanatory variable is treatment (additional mammograms), and the response variable is death from breast cancer.\nAre these measures associated?"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#assume-independenceno-association",
    "href": "slides/lec07d-chi_squared.html#assume-independenceno-association",
    "title": "Inference on proportions",
    "section": "Assume independence/no association",
    "text": "Assume independence/no association\n\nIf mammograms are more effective than non-mammogram breast cancer exams, then we would expect to see additional deaths from breast cancer in the control group (there is a relationship).\nIf mammograms are not as effective as regular breast cancer exams, we would expect to see no difference in breast cancer deaths in the two groups (there is no relationship).\nNeed to figure out how many deaths would be expected, if there was no relationship between treatment death by breast cancer,\nThen examine the residuals - the difference between the observed counts and the expected counts in each cell."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#table-notation",
    "href": "slides/lec07d-chi_squared.html#table-notation",
    "title": "Inference on proportions",
    "section": "Table notation",
    "text": "Table notation\nTables can be described by \\(i\\) rows and \\(j\\) columns. So the cell in the top left is \\(i=1\\) and \\(j=1\\).\n\n\n\n\\(O_{ij}\\)\nAlive\nDead\nTotal\n\n\n\n\nMammo\n\\(n_{11}\\)\n\\(n_{12}\\)\n\\(n_{1.}\\)\n\n\nControl\n\\(n_{21}\\)\n\\(n_{22}\\)\n\\(n_{2.}\\)\n\n\nTotal\n\\(n_{.1}\\)\n\\(n_{.2}\\)\n\\(N\\)\n\n\n\nIn our DATA = MODEL + RESIDUAL framework, the DATA (\\(n_{11}, n_{12}\\), etc)is the observed counts \\(O_{ij}\\) and the MODEL is the expected counts \\(E_{ij}\\)."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#calculating-the-expected-count",
    "href": "slides/lec07d-chi_squared.html#calculating-the-expected-count",
    "title": "Inference on proportions",
    "section": "Calculating the expected count",
    "text": "Calculating the expected count\nSince we assume the variables are independent (unless the data show otherwise) the expected count for each cell is calculated as the row total times the column total for that cell, divided by the overall total.\n\\[E_{ij} = \\frac{n_{i.}n_{.j}}{N}\\]\nIn a probability framework this is stated as two variables \\(A\\) and \\(B\\) are independent if \\(P(A \\cap B) = P(A)*P(B) = \\frac{n_{i.}}{N}*\\frac{n_{.j}}{N}\\)"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#calculating-the-residuals",
    "href": "slides/lec07d-chi_squared.html#calculating-the-residuals",
    "title": "Inference on proportions",
    "section": "Calculating the residuals",
    "text": "Calculating the residuals\nThe residuals are calculated as \\((O_{ij} - E_{ij})\\), observed minus expected.\n\n\nExpected\n\n\nShow the code\nchisq.test(a$Tx, a$Outcome)$expected %&gt;% \n  kable(digits=2)\n\n\n\n\n\n\nAlive\nDead\n\n\n\n\nControl\n44407.58\n502.42\n\n\nMammogram\n44422.42\n502.58\n\n\n\n\n\n\nResiduals\n\n\nShow the code\nchisq.test(a$Tx, a$Outcome)$residuals %&gt;% \n  kable(digits=3) \n\n\n\n\n\n\nAlive\nDead\n\n\n\n\nControl\n-0.012\n0.115\n\n\nMammogram\n0.012\n-0.115\n\n\n\n\n\n\nIf mammograms were not associated with survival, there were 0.01 fewer people still alive than expected, and 0.11 more people dead."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#chi2-test-statistic",
    "href": "slides/lec07d-chi_squared.html#chi2-test-statistic",
    "title": "Inference on proportions",
    "section": "\\(\\chi^2\\) test statistic",
    "text": "\\(\\chi^2\\) test statistic\n\n\nThe \\(\\chi^2\\) test statistic is defined as the sum of the squared residuals, divided by the expected counts, and follows a \\(\\chi^2\\) distribution with degrees of freedom (#rows -1)(#cols -1).\n\\[ \\sum_{ij}\\frac{(O_{ij}-E_{ij})^{2}}{E_{ij}} \\]\nAssumptions for this distribution to hold\n\nSample size is large\n\\(E_{ij} \\geq 5\\) for at least 80% of cells\n\n\n\n\nShow the code\nchisq.test(a$Tx, a$Outcome)\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  a$Tx and a$Outcome\nX-squared = 0.01748, df = 1, p-value = 0.8948\n\n\nShow the code\ndist_chisq(chi2=.01748, deg.f=1, xmax = 10,\n           geom.colors=c(\"#FDE725FF\", \"#440154FF\"))"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#conclusion",
    "href": "slides/lec07d-chi_squared.html#conclusion",
    "title": "Inference on proportions",
    "section": "Conclusion",
    "text": "Conclusion\nIn this example, the test statistic was 0.017 with p-value 0.895.\nSo there is not enough reason to believe that mammograms in addition to regular exams are associated with a reduced risk of death due to breast cancer.\nThis example demonstrated how we examine the residuals to see how closely our DATA fits a hypothesized MODEL."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#example-income-and-general-health",
    "href": "slides/lec07d-chi_squared.html#example-income-and-general-health",
    "title": "Inference on proportions",
    "section": "Example: Income and General Health",
    "text": "Example: Income and General Health\nUsing the Addhealth data set, what can we say about the relationship between smoking status and a person‚Äôs perceived level of general health?\nIs there an association between lifetime smoking status and perceived general health?"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#identify-response-and-explanatory-variables",
    "href": "slides/lec07d-chi_squared.html#identify-response-and-explanatory-variables",
    "title": "Inference on proportions",
    "section": "1. Identify response and explanatory variables",
    "text": "1. Identify response and explanatory variables\n\nThe binary explanatory variable is whether the person has ever smoked an entire cigarette (eversmoke_c).\nThe categorical explanatory variable is the person‚Äôs general health (genhealth) and has levels ‚ÄúExcellent‚Äù, ‚ÄúVery Good‚Äù, ‚ÄúGood‚Äù, ‚ÄúFair‚Äù, and ‚ÄúPoor‚Äù."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#visualize-and-summarise",
    "href": "slides/lec07d-chi_squared.html#visualize-and-summarise",
    "title": "Inference on proportions",
    "section": "2. Visualize and summarise",
    "text": "2. Visualize and summarise\n\nStandardAlternative visualizations\n\n\n\n\n\n\nShow the code\nplot_xtab(grp=addhealth$eversmoke_c, x=addhealth$genhealth, \n                  show.total = FALSE, margin=\"row\", legend.title=\"\") + \n   theme_bw() + theme(legend.position=\"bottom\") + xlab(\"General Health\")\n\n\n\n\n\n\n\n\n\n\nThe percentage of smokers seems to increase as the general health status decreases. Almost three-quarters (73%, n=40) of those reporting poor health have smoked an entire cigarette at least once in their life compared to 59% (n=573) of those reporting excellent health.\n\n\n\n\n\nPlot the % who smoked at least once. This method only works when there is a binary outcome.\n\n\nShow the code\naddhealth %&gt;% \n  group_by(genhealth) %&gt;% \n  summarize(p = mean(eversmoke_c == \"Smoked at least once\", na.rm=TRUE)*100, \n            n = n()) %&gt;% \n  na.omit() %&gt;% \n  ggplot(aes(x=genhealth, y=p, color=genhealth)) + \n  geom_point(aes(size = n)) + \n  scale_y_continuous(limits=c(0, 100)) + \n  geom_segment(aes(x=genhealth, xend=genhealth, y=0, yend=p)) +\n  scale_color_discrete(guide=\"none\") + theme_bw() + \n  ylab(\"Proportion of smokers\") + \n  xlab(\"Perceived General Health\")\n\n\n\n\n\n\n\n\n\n\nA stacked barchart can work for any size categorical outcome, but the more categories/segments, the harder it will be to see the %‚Äôs.\n\n\nShow the code\naddhealth %&gt;% \n  count(genhealth, eversmoke_c) %&gt;% \n  na.omit() %&gt;%\n  group_by(genhealth)%&gt;%\n  mutate(p = n/sum(n)*100) %&gt;% \nggplot(aes(x=genhealth, y=p, fill=eversmoke_c, \n           label = paste0(round(p, 1), \"%\"))) + \n  geom_col() + theme_bw() + \n  scale_fill_discrete(name = \"\") + \n  geom_text(position=position_stack(0.5)) + \n  ylab(\"Proportion of smokers\") + \n  xlab(\"Perceived General Health\")"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#write-the-null-and-research-hypothesis-in-words-and-symbols.",
    "href": "slides/lec07d-chi_squared.html#write-the-null-and-research-hypothesis-in-words-and-symbols.",
    "title": "Inference on proportions",
    "section": "3. Write the null and research hypothesis in words and symbols.",
    "text": "3. Write the null and research hypothesis in words and symbols.\n\nNull Hypothesis: The proportion of smokers is the same across all levels of general health.\nAlternate Hypothesis: At least one group has a different proportion of smokers compared to the other general health groups.\n\nLet \\(p_{1}, p_{2}, \\ldots, p_{5}\\) be the true proportion of smokers in each of the 5 health categories: (1) Excellent to (5) Poor.\n\n\n\\(H_{0}: p_{1} = p_{2} = \\ldots p_{5}\\)\n\\(H_{A}:\\) At least one \\(p_{j}\\) is different."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#state-and-justify-the-analysis-model.-check-assumptions.",
    "href": "slides/lec07d-chi_squared.html#state-and-justify-the-analysis-model.-check-assumptions.",
    "title": "Inference on proportions",
    "section": "4. State and justify the analysis model. Check assumptions.",
    "text": "4. State and justify the analysis model. Check assumptions.\n\nI will conduct a \\(\\chi^{2}\\) test of association because both variables are categorical.\nThe expected value in each combination of smoking status and general health is at least 5.\n\n\n\nShow the code\nchisq.test(addhealth$genhealth, addhealth$eversmoke_c)$expected\n\n\n                   addhealth$eversmoke_c\naddhealth$genhealth Never Smoked Smoked at least once\n          Excellent    339.50324            636.49676\n          Very good    681.44144           1277.55856\n          Good         584.04297           1094.95703\n          Fair         148.88052            279.11948\n          Poor          19.13184             35.86816"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#conduct-the-test",
    "href": "slides/lec07d-chi_squared.html#conduct-the-test",
    "title": "Inference on proportions",
    "section": "5. Conduct the test",
    "text": "5. Conduct the test\nAnd make a decision about the plausibility of the alternative hypothesis.\n\n\nShow the code\nchisq.test(addhealth$genhealth, addhealth$eversmoke_c)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  addhealth$genhealth and addhealth$eversmoke_c\nX-squared = 30.795, df = 4, p-value = 3.371e-06\n\n\nWe have strong evidence in favor of the alternative hypothesis, p&lt;.0001\n6. Write a conclusion\nWe can conclude that there is an association between ever smoking a cigarette in their life and perceived general health (\\(\\chi^{2} = 30.8, df=4, p&lt;.0001\\))."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#multiple-comparisons-which-group-is-different",
    "href": "slides/lec07d-chi_squared.html#multiple-comparisons-which-group-is-different",
    "title": "Inference on proportions",
    "section": "Multiple comparisons: Which group is different?",
    "text": "Multiple comparisons: Which group is different?\nJust like with ANOVA, if we find that the Chi-squared test indicates that at least one proportion is different from the others, it‚Äôs our job to figure out which ones might be different! We will analyze the residuals to accomplish this."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#examine-the-residuals",
    "href": "slides/lec07d-chi_squared.html#examine-the-residuals",
    "title": "Inference on proportions",
    "section": "Examine the residuals",
    "text": "Examine the residuals\nThe residuals (\\(O_{ij} - E_{ij}\\)) are automatically stored in the model output. You can either print them out and look at the values directly or create a plot. You‚Äôre looking for combinations that have much higher, or lower expected proportions.\n\n\n\n\nShow the code\nhealth.smoke.model &lt;- chisq.test(addhealth$genhealth, addhealth$eversmoke_c)\nhealth.smoke.model$residuals |&gt; round(2)\n\n\n                   addhealth$eversmoke_c\naddhealth$genhealth Never Smoked Smoked at least once\n          Excellent         3.45                -2.52\n          Very good         0.48                -0.35\n          Good             -2.44                 1.78\n          Fair             -1.06                 0.77\n          Poor             -0.94                 0.69\n\n\n\n\n\nShow the code\nplot.residuals &lt;- health.smoke.model$residuals %&gt;% data.frame()\nggplot(plot.residuals, aes(x=addhealth.genhealth, y=addhealth.eversmoke_c)) +\n       geom_raster(aes(fill=Freq)) +  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\n\nThe proportion of non-smokers in the excellent health category is much higher than expected if there were no relationship between these two variables."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#all-pairwise-comparisons",
    "href": "slides/lec07d-chi_squared.html#all-pairwise-comparisons",
    "title": "Inference on proportions",
    "section": "All pairwise comparisons",
    "text": "All pairwise comparisons\n\n\n\n\nShow the code\n# library(rcompanion)\nsmoke.by.genhealth &lt;- table(addhealth$genhealth, addhealth$eversmoke_c)\nrcompanion::pairwiseNominalIndependence(smoke.by.genhealth, fisher = FALSE, gtest=FALSE) |&gt; kable(digits = 3)\n\n\n\n\n\nComparison\np.Chisq\np.adj.Chisq\n\n\n\n\nExcellent : Very good\n0.002\n0.007\n\n\nExcellent : Good\n0.000\n0.000\n\n\nExcellent : Fair\n0.001\n0.004\n\n\nExcellent : Poor\n0.039\n0.079\n\n\nVery good : Good\n0.008\n0.020\n\n\nVery good : Fair\n0.151\n0.252\n\n\nVery good : Poor\n0.212\n0.303\n\n\nGood : Fair\n0.840\n0.840\n\n\nGood : Poor\n0.529\n0.588\n\n\nFair : Poor\n0.498\n0.588\n\n\n\n\n\n\nUsing the adjusted (for multiple comparisons) p-value column, the proportion of smokers in the Excellent group (41.3%) is significantly different from nearly all other groups (35.4% for Very Good, 31.3% for Good, 31.8% for Fair).\nBut why is it not significantly different from the 27.3% in the Poor group?"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#the-effect-of-small-sample-sizes",
    "href": "slides/lec07d-chi_squared.html#the-effect-of-small-sample-sizes",
    "title": "Inference on proportions",
    "section": "The effect of small sample sizes",
    "text": "The effect of small sample sizes\nWhy is 41.3% significantly different from 35.4%, but NOT different from 27.3%?\nThe standard error is always dependent on the sample size. Here, the number of individuals in the Poor health category is much smaller compared to all other groups - so the margin of error will be larger - making it less likely to be statistically significantly different from other groups.\nWhen you have a small numbers (typically n&lt;10) in one or more cells the value of the expected value \\(E_{ij}\\) for that cell likely will be below, or close to 5. This means distribution of the test statistic can no longer be modeled well using the \\(\\chi^{2}\\) distribution. So we again go to a non-parametric test that uses a randomization based method."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#fishers-exact-test",
    "href": "slides/lec07d-chi_squared.html#fishers-exact-test",
    "title": "Inference on proportions",
    "section": "Fishers Exact Test",
    "text": "Fishers Exact Test\n\n\nShow the code\nfisher.test(addhealth$genhealth, addhealth$eversmoke_c, \n            simulate.p.value = TRUE)\n\n\n\n    Fisher's Exact Test for Count Data with simulated p-value (based on 2000 replicates)\n\ndata:  addhealth$genhealth and addhealth$eversmoke_c\np-value = 0.0004998\nalternative hypothesis: two.sided\n\n\nThen you can use the pairwiseNominalIndependence function for all pairwise comparisons again, with the fisher argument set to TRUE.\n\n\n\nNote: the simulate.p.value = TRUE argument here is only needed if the randomization space is larger than your workspace. R will let you know when this is needed."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#c-c",
    "href": "slides/lec07d-chi_squared.html#c-c",
    "title": "Inference on proportions",
    "section": "C ~ C",
    "text": "C ~ C\nWe can still use the \\(\\chi^{2}\\) test of association to compare categorical variables with more than 2 levels. In this case we generalize the statement to ask: Is the distribution of 1 variable the same across levels of another variable?. In this sense, it is very much like an ANOVA.\nMathematically the \\(\\chi^{2}\\) test of association is the exact same as a test of equal proportions."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#example",
    "href": "slides/lec07d-chi_squared.html#example",
    "title": "Inference on proportions",
    "section": "Example",
    "text": "Example\nLet‚Äôs analyze the relationship between a person‚Äôs income and perceived level of general health.\nThe categorical explanatory variable is income, binned into 4 ranges (income_cat).\n\n\nShow the code\naddhealth$income_cat &lt;- Hmisc::cut2(addhealth$income, g = 4)"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#visualize-and-summarize",
    "href": "slides/lec07d-chi_squared.html#visualize-and-summarize",
    "title": "Inference on proportions",
    "section": "Visualize and summarize",
    "text": "Visualize and summarize\n\n\nShow the code\nplot_xtab(grp=addhealth$income_cat,\n                  x=addhealth$genhealth, \n                  show.total = FALSE, margin=\"row\",\n                  legend.title=\"\") + \n  theme(legend.position = \"top\")\n\n\n\nThe income distribution is nearly flat for who rate themselves in excellent or very good condition. However, the proportion of individuals in the lower income categories increase as perceived general health decreases. Over 80% of those that rate themselves as in Poor condition have an annual income less than $35,500."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#state-hypothesis",
    "href": "slides/lec07d-chi_squared.html#state-hypothesis",
    "title": "Inference on proportions",
    "section": "State Hypothesis",
    "text": "State Hypothesis\nLet \\(p_{1e}, p_{2e}, p_{3e}, p_{4e}\\) be the true proportion of income brackets within those that say they are in excellent health.\nLet \\(p_{1v}, p_{2v}, p_{3v}, p_{4v}\\) be the true proportion of income brackets within those that say they are in very good health.\n‚Ä¶ and so forth for each health category.\n\\(H_{0}:\\) The income distribution (\\(p_{1j}, p_{2j}, p_{3j}, p_{4j}\\)) is the same in each of the \\(j\\) general health categories (no association)\n\\(H_{A}:\\) The income distribution differs for at least one of the general health categories (association)"
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#test-the-relationship-make-a-conclusion.",
    "href": "slides/lec07d-chi_squared.html#test-the-relationship-make-a-conclusion.",
    "title": "Inference on proportions",
    "section": "Test the relationship & make a conclusion.",
    "text": "Test the relationship & make a conclusion.\n\n\nShow the code\nchisq.test(addhealth$genhealth, addhealth$income_cat)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  addhealth$genhealth and addhealth$income_cat\nX-squared = 100.87, df = 12, p-value = 3.756e-16\n\n\nShow the code\nchisq.test(addhealth$genhealth, addhealth$income_cat)$expected\n\n\n                   addhealth$income_cat\naddhealth$genhealth [10225, 25500) [25500, 35500) [35500, 51000) [51000,250000]\n          Excellent     227.563693     187.881768     187.881768     170.672770\n          Very good     452.481297     373.578865     373.578865     339.360973\n          Good          359.280146     296.629872     296.629872     269.460110\n          Fair           77.030604      63.598221      63.598221      57.772953\n          Poor            7.644258       6.311274       6.311274       5.733194\n\n\nThere is sufficient evidence to conclude that the distribution of income is not the same across all general health status categories. The Chi-squared test of association is valid here because of the large sample size, and all expected values are over 5."
  },
  {
    "objectID": "slides/lec07d-chi_squared.html#other-analysis-for-categorical-variables",
    "href": "slides/lec07d-chi_squared.html#other-analysis-for-categorical-variables",
    "title": "Inference on proportions",
    "section": "Other analysis for categorical variables",
    "text": "Other analysis for categorical variables\nThere is a slew of methods to analyze categorical data. To learn more start with Categorical Data Analysis by Alan Agresti, who has written extensively on the subject."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#model",
    "href": "slides/lec07b-2Samp_T_test.html#model",
    "title": "Inference between two means",
    "section": "Model",
    "text": "Model\n\\[\ny_{ij} = \\mu_{j} + \\epsilon_{ij} \\qquad \\qquad\n\\epsilon_{ij} \\overset{iid}{\\sim} \\mathcal{N}(0,\\sigma^{2})\n\\]\n\nResponse data \\(y_{ij}\\) from observation \\(i=1\\ldots n\\) belonging to group \\(j=1,2\\)\nThe random error terms \\(\\epsilon_{ij}\\) are independently and identically distributed (iid) as normal with mean zero and common variance."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#sample-t-test-for-difference-in-means-between-two-independent-groups",
    "href": "slides/lec07b-2Samp_T_test.html#sample-t-test-for-difference-in-means-between-two-independent-groups",
    "title": "Inference between two means",
    "section": "2 sample T-test for difference in means between two independent groups",
    "text": "2 sample T-test for difference in means between two independent groups\n\nParameter: \\(\\mu_{1} - \\mu_{2}\\)\nEstimate: \\(\\bar{x}_{1} - \\bar{x}_{2}\\)\nAssumptions:\n\nGroup 1 & 2 are mutually exclusive and independent\nDifference \\(\\bar{x}_{1} - \\bar{x}_{2}\\) is normally distributed\nVariance within each group are approximately the same (\\(\\sigma\\))\n\n\n\\(H_{0}: \\mu_{1} - \\mu_{2} = 0\\): There is no difference in the averages between groups.\n\\(H_{A}: \\mu_{1} - \\mu_{2} \\neq 0\\): There is a difference in the averages between groups."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#example-bmi-vs-smoking",
    "href": "slides/lec07b-2Samp_T_test.html#example-bmi-vs-smoking",
    "title": "Inference between two means",
    "section": "Example: BMI vs smoking",
    "text": "Example: BMI vs smoking\nWe would like to know, is there convincing evidence that the average BMI differs between those who have ever smoked a cigarette in their life compared to those who have never smoked?\n\n\n\n\n\n\nNitty gritty detail\n\n\nFor the purposes of learning, you will be writing out each step in the analysis in depth. As you begin to master these analyses, it is natural to slowly start to blend and some steps. However it is important for you to have a baseline reference."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#identify-response-and-explanatory-variables",
    "href": "slides/lec07b-2Samp_T_test.html#identify-response-and-explanatory-variables",
    "title": "Inference between two means",
    "section": "1. Identify response and explanatory variables",
    "text": "1. Identify response and explanatory variables\n\nEver smoker = binary explanatory variable (variable eversmoke_c)\nBMI = quantitative response variable (variable BMI)"
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#visualize-and-summarise",
    "href": "slides/lec07b-2Samp_T_test.html#visualize-and-summarise",
    "title": "Inference between two means",
    "section": "2. Visualize and summarise",
    "text": "2. Visualize and summarise\n\n\n\n\nShow the code\nplot.bmi.smoke &lt;- addhealth %&gt;% select(eversmoke_c, BMI) %&gt;% na.omit()\n\nplot.bmi.smoke %&gt;% \n  ggviolin(x=\"eversmoke_c\",\n    y=\"BMI\",\n    color=\"eversmoke_c\", \n    add = c(\"mean\", \"boxplot\")) + \n  color_palette(palette = \"jco\") + xlab(\"Smoking Status\")\n\n\n\n\n\n\n\n\nShow the code\nplot.bmi.smoke %&gt;% \n  tbl_summary(\n    by=\"eversmoke_c\",\n    digits = all_continuous() ~ 1,     \n    statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"\n    ))\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Never Smoked\nN = 1,7501\n      Smoked at least once\nN = 3,2761\n    \n  \n  \n    BMI\n29.7 (7.8)\n28.8 (7.3)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\n\n\nSmokers have on average BMI of 28.8, smaller than the average BMI of non-smokers at 29.7. Non-smokers have more variation in their weights (7.8 vs 7.3lbs), but the distributions both look normal, if slightly skewed right."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#write-the-null-and-research-hypothesis-in-words-and-symbols.",
    "href": "slides/lec07b-2Samp_T_test.html#write-the-null-and-research-hypothesis-in-words-and-symbols.",
    "title": "Inference between two means",
    "section": "3. Write the null and research hypothesis in words and symbols.",
    "text": "3. Write the null and research hypothesis in words and symbols.\nLet \\(\\mu_{1}\\) be the average BMI for smokers, and \\(\\mu_{2}\\) be the average BMI for non-smokers\n\n\n\\(H_{0}: \\mu_{1} - \\mu_{2} = 0\\) There is no difference in the average BMI between smokers and non-smokers.\n\n\n\\(H_{A}: \\mu_{1} - \\mu_{2} \\neq 0\\) There is a difference in the average BMI between smokers and non-smokers."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#state-and-justify-the-analysis-model.-check-assumptions.",
    "href": "slides/lec07b-2Samp_T_test.html#state-and-justify-the-analysis-model.-check-assumptions.",
    "title": "Inference between two means",
    "section": "4. State and justify the analysis model. Check assumptions.",
    "text": "4. State and justify the analysis model. Check assumptions.\n\nWe are comparing the means between two independent samples. A Two-Sample T-Test for a difference in means will be conducted.\nThe assumptions that the groups are independent is upheld because each individual can only be either a smoker or non smoker.\nThe difference in sample means \\(\\bar{x}_{1}-\\bar{x}_{2}\\) is normally distributed - this is a valid assumption due to the large sample size and that differences typically are normally distributed.\nThe observations are independent, this was a random sample\nThe variances are roughly equal (67/44 = 1.5 is smaller than 2)."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#conduct-the-test-and-make-a-decision-about-the-plausibility-of-the-alternative-hypothesis.",
    "href": "slides/lec07b-2Samp_T_test.html#conduct-the-test-and-make-a-decision-about-the-plausibility-of-the-alternative-hypothesis.",
    "title": "Inference between two means",
    "section": "5. Conduct the test and make a decision about the plausibility of the alternative hypothesis.",
    "text": "5. Conduct the test and make a decision about the plausibility of the alternative hypothesis.\n\n\nShow the code\nt.test(BMI ~ eversmoke_c, data=addhealth)\n\n\n\n    Welch Two Sample t-test\n\ndata:  BMI by eversmoke_c\nt = 3.6937, df = 3395.3, p-value = 0.0002245\nalternative hypothesis: true difference in means between group Never Smoked and group Smoked at least once is not equal to 0\n95 percent confidence interval:\n 0.3906204 1.2744780\nsample estimates:\n        mean in group Never Smoked mean in group Smoked at least once \n                          29.67977                           28.84722 \n\n\nThere is strong evidence in favor of the alternative hypothesis. The interval for the differences (0.4, 1.3) does not contain zero and the p-value = .0002."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#write-a-conclusion-in-context-of-the-problem.-include-the-point-estimates-confidence-interval-for-the-difference-and-p-value.",
    "href": "slides/lec07b-2Samp_T_test.html#write-a-conclusion-in-context-of-the-problem.-include-the-point-estimates-confidence-interval-for-the-difference-and-p-value.",
    "title": "Inference between two means",
    "section": "6. Write a conclusion in context of the problem. Include the point estimates, confidence interval for the difference and p-value.",
    "text": "6. Write a conclusion in context of the problem. Include the point estimates, confidence interval for the difference and p-value.\nOn average, non-smokers have a significantly higher 0.82 (0.39, 1.27) BMI compared to smokers (p=.0002)."
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#but-we-could-be-wrong",
    "href": "slides/lec07b-2Samp_T_test.html#but-we-could-be-wrong",
    "title": "Inference between two means",
    "section": "But we could be wrong",
    "text": "But we could be wrong\n\nCredit: Allison Horst https://allisonhorst.com/"
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#but-we-could-be-wrong-1",
    "href": "slides/lec07b-2Samp_T_test.html#but-we-could-be-wrong-1",
    "title": "Inference between two means",
    "section": "But we could be wrong",
    "text": "But we could be wrong\n\nCredit: Allison Horst https://allisonhorst.com/"
  },
  {
    "objectID": "slides/lec07b-2Samp_T_test.html#type-i-and-type-ii-error",
    "href": "slides/lec07b-2Samp_T_test.html#type-i-and-type-ii-error",
    "title": "Inference between two means",
    "section": "Type I and Type II Error",
    "text": "Type I and Type II Error\n\nAKA False positive or false negative. Wikipedia\nThe significance level, \\(\\alpha\\), is what we use to define the amount of ‚Äúrisk‚Äù we are willing to take to falsely reject \\(H_{0}\\) (false positive).\nWe talk more about false positive & false negative, specificity and sensitivity in Math 456.\nWe will see shortly however how to conduct multiple comparisons while maintaining our ‚Äúfamily-wise‚Äù error rate at \\(\\alpha\\)\n\n\n\nüîó https://math615.netlify.app"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#warm-up-exercise",
    "href": "slides/lec06b-statistical_inference_with_models.html#warm-up-exercise",
    "title": "Statistical Inference using Models",
    "section": "Warm up exercise",
    "text": "Warm up exercise\nWork through the Central Limit Theorem interactive explorer for about 15 minutes. Follow the instructions on the app and take notes and be prepared to share out what you learned/your take away message.\nhttps://mathisawesome.shinyapps.io/central-limit-theorem/"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#sampling-distributions",
    "href": "slides/lec06b-statistical_inference_with_models.html#sampling-distributions",
    "title": "Statistical Inference using Models",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\nSince point estimates are numbers calculated on a sample, they are also sample statistics. Recall that sample statistics are used to estimate parameters, the true value of the quantity of interest from the population.\nAs we just saw through simulation, point estimates are subject to random variation because they are calculated on different random samples from the population. The distribution of repeatedly calculated point estimates based on the same fixed size \\(n\\) from a population is called a sampling distribution."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#mathematical-theory-guarantees",
    "href": "slides/lec06b-statistical_inference_with_models.html#mathematical-theory-guarantees",
    "title": "Statistical Inference using Models",
    "section": "Mathematical theory guarantees",
    "text": "Mathematical theory guarantees\n\nIf repeated samples are taken, a point estimate will follow something that resembles a normal distribution when certain conditions are met.\n\nNote: we typically only take one sample, but the mathematical model lets us know what to expect if we had taken repeated samples\n\n\n\n\n\n\n\n\nObservations in the sample are independent.\n\n\nGuaranteed when we take a random sample from a population, or randomly divide individuals into treatment and control groups.\n\n\n\n\n\n\n\n\n\nThe sample is large enough.\n\n\nWhat qualifies as ‚Äúlarge enough‚Äù differs from one context to the next. If the population is already normally distributed and the formula to calculate the sample statistic simple, then fewer samples are needed. The ‚Äúmagic‚Äù number 30 gets thrown around a lot."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#the-normal-distribution",
    "href": "slides/lec06b-statistical_inference_with_models.html#the-normal-distribution",
    "title": "Statistical Inference using Models",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\n\n\nThe normal distribution is used to describe the variability associated with sample statistics which are taken from either repeated samples or repeated experiments. The normal distribution is quite powerful in that it describes the variability of many different statistics such as the sample mean and sample proportions.\nDistributions of many variables are nearly normal, but none are exactly normal. While not perfect for any single problem, the Normal Distribution is very useful for a variety of problems."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#distributional-notation",
    "href": "slides/lec06b-statistical_inference_with_models.html#distributional-notation",
    "title": "Statistical Inference using Models",
    "section": "Distributional Notation",
    "text": "Distributional Notation\n\\[ X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\] This means some random variable \\(X\\) is distributed(\\(\\sim\\)), as a Normal (\\(\\mathcal{N}\\)) distribution centered on mean \\(\\mu\\) with variance \\(\\sigma^{2}\\).\n\n\n\n\n\n\nNotational differences\n\n\nNote that the IMS textbook uses the uncommon notation \\(\\mathcal{N}(\\mu, \\sigma)\\), where the second parameter is \\(\\sigma\\), the standard deviation."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#the-normal-distribution-2",
    "href": "slides/lec06b-statistical_inference_with_models.html#the-normal-distribution-2",
    "title": "Statistical Inference using Models",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\n\n\n\nSymmetric, ‚Äúbell shaped‚Äù\nCentered on \\(\\mu\\) and spread controlled by \\(\\sigma^2\\)\nTails extend to \\(\\infty\\)\n\n\n\n\n\n\n\n\n\n\n\n\nArea under the curve will always add to 1.\nUsed to calculate the probability of an event occurring"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#comparing-values-under-two-different-distributions",
    "href": "slides/lec06b-statistical_inference_with_models.html#comparing-values-under-two-different-distributions",
    "title": "Statistical Inference using Models",
    "section": "Comparing values under two different distributions",
    "text": "Comparing values under two different distributions\n\n\n\n\n\n\nTwo different college-ready exams\n\n\nSAT scores follow a nearly normal distribution with a mean of 1500 points and a standard deviation of 300 points.\nACT scores also follow a nearly normal distribution with mean of 21 points and a standard deviation of 5 points.\nSuppose Nel scored 1800 points on their SAT and Sian scored 24 points on their ACT.\n\n\n\nWho performed better?"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#standardizing-distributions",
    "href": "slides/lec06b-statistical_inference_with_models.html#standardizing-distributions",
    "title": "Statistical Inference using Models",
    "section": "Standardizing Distributions",
    "text": "Standardizing Distributions\nIf you overlay the two distributions, where the means line up and where each tick mark represents one standard deviation away from the mean, we can see who did better relative to the exam average.\n\n\n\n\n\\[X_{SAT} \\sim \\mathcal{N}(1500, 300^{2})\\]\n\n\\[X_{ACT} \\sim \\mathcal{N}(21, 25)\\]"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#z-score",
    "href": "slides/lec06b-statistical_inference_with_models.html#z-score",
    "title": "Statistical Inference using Models",
    "section": "Z-score",
    "text": "Z-score\nThe Z score of an observation is the number of standard deviations it falls above or below the mean. We compute the Z score for an observation that follows a distribution with mean and standard deviation using\n\\[ Z = \\frac{x- \\mu}{\\sigma} \\] If an observation \\(x\\) comes from a \\(\\mathcal{N}(\\mu, \\sigma)\\) distribution, then \\(Z \\sim \\mathcal{N}(0, 1)\\). We center the distribution by subtracting the mean, and scale by dividing by the sd."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#comparing-scores",
    "href": "slides/lec06b-statistical_inference_with_models.html#comparing-scores",
    "title": "Statistical Inference using Models",
    "section": "Comparing Scores",
    "text": "Comparing Scores\nCalculate the Z-score for both Nel and Sian. Who did better?\n\n\n\n\\(X_{SAT} \\sim \\mathcal{N}(1500, 300^{2})\\)\n\\(x_{Nel} = 1800\\)\n\\(Z_{Nel} = \\frac{1800- 1500}{300} = 1\\)\n\n\n\n\\(X_{ACT} \\sim \\mathcal{N}(21, 25)\\)\n\\(x_{Sian} = 24\\)\n\\(Z_{Sian} = \\frac{24- 21}{5} = 0.6\\)"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#comparing-scores-1",
    "href": "slides/lec06b-statistical_inference_with_models.html#comparing-scores-1",
    "title": "Statistical Inference using Models",
    "section": "Comparing Scores",
    "text": "Comparing Scores\nWhile we know Nel did better, Sian didn‚Äôt do too bad! What was their percentile (The percent of observations below a specified value)?\n\n\n\n\nShow the code\nopenintro::normTail(m = 21, s = 5, L = 24)\n\n\n\n\n\n\n\n\n\n\nWe can find this value using pnorm(z, mean, sd).\n\n\nShow the code\npnorm(.6, mean = 0, sd = 1)\n\n\n[1] 0.7257469"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#finding-percentiles",
    "href": "slides/lec06b-statistical_inference_with_models.html#finding-percentiles",
    "title": "Statistical Inference using Models",
    "section": "Finding percentiles",
    "text": "Finding percentiles\nIf \\(X \\sim \\mathcal{N}(\\mu, \\sigma^{2})\\), then pnorm calculates the probability that a value is below a certain number a.\n\n\\(P(X &lt; a)\\) is found using pnorm(a, mean, sd)\n\nA complementary function, qnorm calculates the cutoff value a that is needed such that a certain percent of observations (q) are below that value.\n\n\\(P(X &lt; a) = q\\) is found using qnorm(q, mean, sd)\n\n\n\nShow the code\nqnorm(.90, 21, 5) \n\n\n[1] 27.40776\n\n\nYou would need to score a 27.5 to be in the top 10th percentile of ACT test takers."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#many-estimates-are-normally-distributed",
    "href": "slides/lec06b-statistical_inference_with_models.html#many-estimates-are-normally-distributed",
    "title": "Statistical Inference using Models",
    "section": "Many estimates are normally distributed",
    "text": "Many estimates are normally distributed\n\nthe sample proportion \\(\\hat{p}\\)\nthe sample mean \\(\\bar{x}\\)\ndifferences in two sample proportions \\(\\hat{p}_{1} - \\hat{p}_{2}\\)\ndifferences in two sample means \\(\\bar{x}_{1} - \\bar{x}_{2}\\)\nthe sample slope from a linear model \\(\\hat{\\beta}\\)"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#rule-of-thumb",
    "href": "slides/lec06b-statistical_inference_with_models.html#rule-of-thumb",
    "title": "Statistical Inference using Models",
    "section": "68-95-99.7 rule of thumb",
    "text": "68-95-99.7 rule of thumb\nBecause intuition is important.\n\n\n\nShow the code\npnorm(2, 0, 1) - pnorm(-2, 0, 1)\n\n\n[1] 0.9544997"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#sd-vs-se",
    "href": "slides/lec06b-statistical_inference_with_models.html#sd-vs-se",
    "title": "Statistical Inference using Models",
    "section": "SD vs SE",
    "text": "SD vs SE\n\n\n\n\n\n\nDefinition: Standard Deviation (SD)\n\n\nVariability of the data values (\\(x\\))\n\n\n\n\n\n\n\n\n\nDefinition: Standard Error (SE)\n\n\nVariability of the sample statistic (e.g.¬†\\(\\bar{x}\\) or \\(\\hat{p}\\))"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#margin-of-error",
    "href": "slides/lec06b-statistical_inference_with_models.html#margin-of-error",
    "title": "Statistical Inference using Models",
    "section": "Margin of Error",
    "text": "Margin of Error\n\n\n\n\n\n\nDefinition: Margin of Error (MOE)\n\n\nThe margin of error describes how far away observations are from their mean.\nOften approximated as \\(2 * SE\\)\n\n\n\n\n95% of the observations are within one margin of error of the mean.\nIf the spread of the observations goes from some lower bound to some upper bound, a rough approximation of the \\(SE\\) is to divide the range by 4.\n\nIf you notice the sample proportions go from 0.1 to 0.4, the SE can be approximated to be 0.075."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#summary",
    "href": "slides/lec06b-statistical_inference_with_models.html#summary",
    "title": "Statistical Inference using Models",
    "section": "Summary",
    "text": "Summary\n\nPoint estimates from a sample may be used to estimate population parameters.\nPoint estimates are not exact: they vary from one sample to another.\nThe standard error is the uncertainty of the sample statistic, and it gets smaller as you use more data to calculate the point estimate.\nAs your standard error decreases, so does your margin of error"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#observed-data",
    "href": "slides/lec06b-statistical_inference_with_models.html#observed-data",
    "title": "Statistical Inference using Models",
    "section": "Observed data",
    "text": "Observed data\nConsider an experiment that examined whether implanting a stent in the brain of a patient at risk for a stroke helps reduce the risk of a stroke. The results from the first 30 days of this study are summarized in the following table.\n\n\n\n\nShow the code\ntable(stent30$group, stent30$outcome) |&gt; addmargins()\n\n\n           \n            no event stroke Sum\n  control        214     13 227\n  treatment      191     33 224\n  Sum            405     46 451\n\n\n\n\n\nShow the code\ntable(stent30$group, stent30$outcome) |&gt;  prop.table(margin=1) |&gt;round(digits=2)\n\n\n           \n            no event stroke\n  control       0.94   0.06\n  treatment     0.85   0.15\n\n\n\nThese results are surprising! The point estimate suggests that patients who received stents may have a higher risk of stroke: \\(p_{trmt}‚àíp_{ctrl}=0.090\\)."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#point-estimate-vs-interval-estimate",
    "href": "slides/lec06b-statistical_inference_with_models.html#point-estimate-vs-interval-estimate",
    "title": "Statistical Inference using Models",
    "section": "Point estimate vs Interval estimate",
    "text": "Point estimate vs Interval estimate\nThe point estimate for the difference in proportions \\(p_{trmt}‚àíp_{ctrl}=0.090\\) is a single point estimate, based on this single sample.\n\n\nA point estimate is our best guess for the value of the parameter, so it makes sense to build the confidence interval around that value."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#constructing-a-95-confidence-interval-ci",
    "href": "slides/lec06b-statistical_inference_with_models.html#constructing-a-95-confidence-interval-ci",
    "title": "Statistical Inference using Models",
    "section": "Constructing a 95% confidence interval (CI)",
    "text": "Constructing a 95% confidence interval (CI)\nWhen the sampling distribution of a point estimate can reasonably be modeled as having a normal distribution, the point estimate we observe will be within 1.96 standard errors of the true value of interest about 95% of the time. Thus, a 95% confidence interval for such a point estimate can be constructed:\n\\[\\mbox{point estimate} \\pm 1.96 √ó SE\\]\nWe can be 95% confident this interval captures the true value."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#construct-a-95-ci-for-the-stent-example",
    "href": "slides/lec06b-statistical_inference_with_models.html#construct-a-95-ci-for-the-stent-example",
    "title": "Statistical Inference using Models",
    "section": "Construct a 95% CI for the stent example",
    "text": "Construct a 95% CI for the stent example\nThe conditions necessary to ensure the point estimate \\(p_{trmt}‚àíp_{ctrl}\\) is nearly normal have been verified for you, and the estimate‚Äôs standard error is \\(SE = 0.028\\).\n\nConstruct a 95% confidence interval for the change in 30-day stroke rates from usage of the stent.\nInterpret this interval in context of the problem.\n\n\n\\[0.090 \\pm 1.96√ó0.028 = (0.035,0.145)\\]\nWe are 95% confident that implanting a stent in a stroke patient‚Äôs brain increased the risk of stroke within 30 days by a rate of 0.035 to 0.145."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#important-note",
    "href": "slides/lec06b-statistical_inference_with_models.html#important-note",
    "title": "Statistical Inference using Models",
    "section": "Important note",
    "text": "Important note\n‚ö†Ô∏è it‚Äôs incorrect to say that we can be 95% confident that the true value is inside the mean.\n\nFigure 13.11: Twenty-five samples of size n=300 were collected from a population with p=0.30. For each sample, a confidence interval was created to try to capture the true proportion p.¬†However, 1 of these 25 intervals did not capture p=0.30."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#section",
    "href": "slides/lec06b-statistical_inference_with_models.html#section",
    "title": "Statistical Inference using Models",
    "section": "",
    "text": "This is one of the most common errors: while it might be useful to think of it as a probability, the confidence level only quantifies how plausible it is that the parameter is in the interval.\nOur intervals say nothing about the confidence of capturing individual observations, a proportion of the observations, or about capturing point estimates.\nConfidence intervals provide an interval estimate for and attempt to capture population parameters."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test",
    "href": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test",
    "title": "Statistical Inference using Models",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\nFirst draft\n\n\nLet‚Äôs setup a hypothesis to test if stents work to reduce the risk of a stroke.\n\n\n\n\n\n\\(H_{0}\\): Stents don‚Äôt work\n\\(H_{A}\\): Stents reduce the risk of a stroke"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test-1",
    "href": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test-1",
    "title": "Statistical Inference using Models",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\nRevision 1:\n\n\nMaking it a statement about two groups\n\n\n\n\\(H_{0}\\): Patients who have a stent have the same risk of a stroke as patients who don‚Äôt have a stent\n\\(H_{A}\\): Patients who have a stent have lower risk of a stroke as patients who don‚Äôt have a stent"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test-2",
    "href": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test-2",
    "title": "Statistical Inference using Models",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\nRevision 2:\n\n\nMake it a statement using summary statistics and removing the directionality of the hypothesis\n\n\n\n\\(H_{0}\\): The proportion of patients with a stent who have a stroke is the same as the proportion of patients without a stent who have a stroke.\n\\(H_{A}\\): The proportion of patients with a stent who have a stroke is different than the proportion of patients without a stent who have a stroke."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test-3",
    "href": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test-3",
    "title": "Statistical Inference using Models",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\nRevision 3:\n\n\nWriting it in symbols\n\n\n\nLet \\(p_{trmt}\\) be the proportion of patients with a stent who have a stroke, and \\(p_{ctrl}\\) be the proportion of patients without a stent who have a stroke\n\n\n\\(H_{0}: p_{trmt} = p_{ctrl}\\)\n\\(H_{A}: p_{trmt} \\neq p_{ctrl}\\)"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test-4",
    "href": "slides/lec06b-statistical_inference_with_models.html#hypothesis-test-4",
    "title": "Statistical Inference using Models",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\nRevision 3.5:\n\n\nRewriting as a difference in parameters\n\n\n\nLet \\(p_{trmt}\\) be the proportion of patients with a stent who have a stroke, and \\(p_{ctrl}\\) be the proportion of patients without a stent who have a stroke\n\n\n\\(H_{0}: p_{trmt} - p_{ctrl} = 0\\)\n\\(H_{A}: p_{trmt} - p_{ctrl} \\neq 0\\)"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#using-the-normal-model",
    "href": "slides/lec06b-statistical_inference_with_models.html#using-the-normal-model",
    "title": "Statistical Inference using Models",
    "section": "Using the Normal model",
    "text": "Using the Normal model\n\nNow we have a statistic (difference in proportions \\(p_{trmt} - p_{ctrl}\\)) and a null value of 0 to compare it to.\nThe conditions necessary to ensure the point estimate is nearly normal have been verified for you.\nThe estimate‚Äôs standard error is \\(SE = 0.028\\) has been calculated for you as well."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#calculating-a-test-statistic-p-value",
    "href": "slides/lec06b-statistical_inference_with_models.html#calculating-a-test-statistic-p-value",
    "title": "Statistical Inference using Models",
    "section": "Calculating a test statistic & p-value",
    "text": "Calculating a test statistic & p-value\n\\[ Z = \\frac{\\mbox{point estimate - null value}}{SE}\\]\n\n\\[ Z = \\frac{(p_{trmt} - p_{ctrl}) - 0}{SE_{p_{trmt} - p_{ctrl}}} = \\frac{.090}{.028} = 3.21 \\]\n\n\n\\[ P(Z &gt; 3.2) = .00068 \\qquad \\mbox{ (the p-value)}\\]\n\n\nShow the code\n1-pnorm(3.2, 0, 1)\n\n\n[1] 0.0006871379\n\n\n\n\nIf the true difference in proportions was 0, then the probability of observing a difference of 0.09 due to random chance is 0.00068."
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#section-1",
    "href": "slides/lec06b-statistical_inference_with_models.html#section-1",
    "title": "Statistical Inference using Models",
    "section": "",
    "text": "https://xkcd.com/1478/"
  },
  {
    "objectID": "slides/lec06b-statistical_inference_with_models.html#using-confidence-intervals-to-test-a-hypothesis",
    "href": "slides/lec06b-statistical_inference_with_models.html#using-confidence-intervals-to-test-a-hypothesis",
    "title": "Statistical Inference using Models",
    "section": "Using Confidence Intervals to test a hypothesis",
    "text": "Using Confidence Intervals to test a hypothesis\n\nWe are 95% confident that implanting a stent in a stroke patient‚Äôs brain increased the risk of stroke within 30 days by a rate of 0.035 to 0.145.\n\nSince the interval does not contain the null hypothesized value of 0 (is completely above 0), it means the data provide convincing evidence that the stent used in the study changed the risk of stroke within 30 days"
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#recap-level-of-care-depends-on-the-audience",
    "href": "slides/lec05b-data_viz_bestpractice.html#recap-level-of-care-depends-on-the-audience",
    "title": "Best practices in Data Visualization",
    "section": "Recap: Level of care depends on the audience",
    "text": "Recap: Level of care depends on the audience\nThere are three main audiences in mind when creating data visualizations:\n\nFor your eyes only (FYEO). These are quick and dirty plots, without annotation. Meant to be looked at once or twice.\nTo share with others internally. These mostly need to stand on their own. Axes labels, titles, colors as needed, possibly captions.\nProfessional - Contains all bells and whistles needed to make it publication quality."
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#highly-recommended-references",
    "href": "slides/lec05b-data_viz_bestpractice.html#highly-recommended-references",
    "title": "Best practices in Data Visualization",
    "section": "Highly recommended references",
    "text": "Highly recommended references\n\n\n\n\nThe classic book on statistical graphics, charts, tables. Theory and practice in the design of data graphics, 250 illustrations of the best (and a few of the worst) statistical graphics, with detailed analysis of how to display data for precise, effective, quick analysis."
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#highly-recommended-references-1",
    "href": "slides/lec05b-data_viz_bestpractice.html#highly-recommended-references-1",
    "title": "Best practices in Data Visualization",
    "section": "Highly recommended references",
    "text": "Highly recommended references\n\n\n\n\nIn The Truthful Art, Cairo explains the principles of good data visualization. He describes five qualities that should be your foundation when you work with data visualization: truthful, functional, beautiful, insightful, and enlightening. Cairo also gives some great examples of biased and dishonest visualization."
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#five-qualities-of-great-visualizations-cairo",
    "href": "slides/lec05b-data_viz_bestpractice.html#five-qualities-of-great-visualizations-cairo",
    "title": "Best practices in Data Visualization",
    "section": "Five qualities of great visualizations (Cairo)",
    "text": "Five qualities of great visualizations (Cairo)\n\nTruthful. Be honest with scaling and relationships.\nFunctional. Does it accurately convey the correct information?\nBeautiful. Or at least aesthetically pleasing.\nInsightful. Does it reveal new information?\nEnlightening. Consequence of qualities 1-4\n\nReferences:\n\nUMSL Computer Science worksho on effective data viz\n\nCalling Bullshit: Spotting misleading axes"
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#graphing-with-intent",
    "href": "slides/lec05b-data_viz_bestpractice.html#graphing-with-intent",
    "title": "Best practices in Data Visualization",
    "section": "Graphing with intent",
    "text": "Graphing with intent\nAlong with having the audience in mind, it is important to give thought to the purpose of the chart.\n\nThe effectiveness of any visualization can be measured according to how well it fulfills the tasks it was designed for. (A. Cairo, 2018)."
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#manage-your-ink-to-information-ratio",
    "href": "slides/lec05b-data_viz_bestpractice.html#manage-your-ink-to-information-ratio",
    "title": "Best practices in Data Visualization",
    "section": "Manage your ink to information ratio",
    "text": "Manage your ink to information ratio\n\n‚ÄúData-ink is the non-erasable core of the graphic. (Tufte, 83)‚Äù\n\n\n\n\n\n\n\n\n\n\n\nDarkhorse Analytics demonstrates how ‚Äúdata looks better naked‚Äù"
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#what-to-watch-out-for",
    "href": "slides/lec05b-data_viz_bestpractice.html#what-to-watch-out-for",
    "title": "Best practices in Data Visualization",
    "section": "What to watch out for",
    "text": "What to watch out for\n\nAvoid complexity\nChoose colors mindfully\nDo not add extra dimensions\nBe truthful with the scaling\nCheck publishing guidelines\nBe consistent with selected themes\nDo not over-interpret\nPlotting with missing data"
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#inspirations",
    "href": "slides/lec05b-data_viz_bestpractice.html#inspirations",
    "title": "Best practices in Data Visualization",
    "section": "Inspirations",
    "text": "Inspirations\nNot sure what type of graph to create?\n\nPoke around on the R Graph Gallery or Python version. Appropriate for all languages as the goal is to identify the graph type\nfrom Data to Viz: a decision tree for graph options"
  },
  {
    "objectID": "slides/lec05b-data_viz_bestpractice.html#graphs-as-storytelling",
    "href": "slides/lec05b-data_viz_bestpractice.html#graphs-as-storytelling",
    "title": "Best practices in Data Visualization",
    "section": "Graphs as storytelling",
    "text": "Graphs as storytelling\nDifferent features (labels, colors, axes) can tell different parts of the story.\nWe‚Äôre going to do a team activity called ‚Äúslow reveal graphs‚Äù. Head to Canvas for further instruction."
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#motivation",
    "href": "slides/lec04-describing_distributions.html#motivation",
    "title": "Describing Distributions of Data",
    "section": "Motivation",
    "text": "Motivation\nVisualizing your data is hands down the most important thing you can learn to do.\n\nScreen for data entry errors\nOut of range variables\nMistakes in coding\nViolation of model assumptions"
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#level-of-care-depends-on-the-audience",
    "href": "slides/lec04-describing_distributions.html#level-of-care-depends-on-the-audience",
    "title": "Describing Distributions of Data",
    "section": "Level of care depends on the audience",
    "text": "Level of care depends on the audience\nThere are three main audiences in mind when creating data visualizations:\n\nFor your eyes only (FYEO). These are quick and dirty plots, without annotation. Meant to be looked at once or twice.\n\nYou‚Äôll create a TON of these. Don‚Äôt spend a ton of time on them.\n\n\n\n\nTo share with others internally. These mostly need to stand on their own. Axes labels, titles, colors as needed, possibly captions.\n\nYou‚Äôll create a lot of these, and you‚Äôll get better with practice at adding necessary annotation without a lot of time\n\n\n\n\n\nProfessional - Contains all bells and whistles needed to make it publication quality.\n\nYou‚Äôll create very few of these, but they demand a lot of time, detail and thought."
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#graphing-with-intent",
    "href": "slides/lec04-describing_distributions.html#graphing-with-intent",
    "title": "Describing Distributions of Data",
    "section": "Graphing with intent",
    "text": "Graphing with intent\nAlong with having the audience in mind, it is important to give thought to the purpose of the chart.\n\nThe effectiveness of any visualization can be measured according to how well it fulfills the tasks it was designed for. (A. Cairo, 2018)."
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#choosing-appropriate-visualization",
    "href": "slides/lec04-describing_distributions.html#choosing-appropriate-visualization",
    "title": "Describing Distributions of Data",
    "section": "Choosing Appropriate Visualization",
    "text": "Choosing Appropriate Visualization\n\n75% of your choice is determined by the data type\nSimilar to the data management section, after identifying what you want to do, you go look up how to do that thing.\nDon‚Äôt expect to remember the exact code yet, just know where to look up an example and copy from there\ncopy/paste/pray\nKeep graphs simple until you get more comfortable."
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#meet-the-palmer-penguins",
    "href": "slides/lec04-describing_distributions.html#meet-the-palmer-penguins",
    "title": "Describing Distributions of Data",
    "section": "Meet the Palmer Penguins",
    "text": "Meet the Palmer Penguins\n\n\nShow the code\nlibrary(palmerpenguins)\npen &lt;- penguins # because i don't want to type out penguins every time"
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#single-categorical",
    "href": "slides/lec04-describing_distributions.html#single-categorical",
    "title": "Describing Distributions of Data",
    "section": "Single Categorical",
    "text": "Single Categorical\n\nTablesPlotsDescription\n\n\nFrequencies (N)\n\n\nShow the code\ntable(pen$species)\n\n\n\n   Adelie Chinstrap    Gentoo \n      152        68       124 \n\n\nPercents (%)\n\n\nShow the code\ntable(pen$species) |&gt; proportions() |&gt; round(digits=2)\n\n\n\n   Adelie Chinstrap    Gentoo \n     0.44      0.20      0.36 \n\n\n\n\n\n\nShow the code\nsjPlot::plot_frq(pen$species) + xlab(\"Species\")\n\n\n\n\n\n\n\n\n\n\n\n\nMust include both the count N and the percent %.\nDon‚Äôt need to describe every bar, just the 1-2 that stand out. E.g. largest and smallest? Categories that you care about.\n\n\nPenguin species Adelie make up 44% of the sample (n=152)"
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#single-numeric",
    "href": "slides/lec04-describing_distributions.html#single-numeric",
    "title": "Describing Distributions of Data",
    "section": "Single Numeric",
    "text": "Single Numeric\n\nCenterShapeSpreadDescription\n\n\n\n\nShow the code\nsummary(pen$bill_depth_mm)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  13.10   15.60   17.30   17.15   18.70   21.50       2 \n\n\nThe average bill depth is 17.15mm, with a median of 17.3mm \n\n\n\n\n\n\nShow the code\nggpubr::gghistogram(pen$bill_depth_mm, add_density = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggpubr::ggviolin(pen$bill_depth_mm, add = c(\"jitter\", \"boxplot\")) + coord_flip()\n\n\n\n\n\n\n\n\n\n\nThe distribution of bill depth appears to be bimodal with peaks around 15 and 18mm.\n\n\n\n\nShow the code\nsummary(pen$bill_depth_mm)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  13.10   15.60   17.30   17.15   18.70   21.50       2 \n\n\nShow the code\nsd(pen$bill_depth_mm, na.rm=TRUE)\n\n\n[1] 1.974793\n\n\nShow the code\nIQR(pen$bill_depth_mm, na.rm=TRUE)\n\n\n[1] 3.1\n\n\nBill depth ranges from 13.1 to 21.5mm, has an IQR of 3.1mm and a standard deviation of 1.9mm.\n\n\n\nDescribe the center, shape and spread.\nInclude numbers\nAlways in context of the problem\n\nThe average penguin bill depth is 17.15mm, with a standard deviation of 1.9mm. Ranging from 13.1 to 21.5mm, there is a bimodal pattern with peaks around 15 and 18mm but otherwise no skew is noted and no outliers are present."
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#custom-summary-tables",
    "href": "slides/lec04-describing_distributions.html#custom-summary-tables",
    "title": "Describing Distributions of Data",
    "section": "Custom Summary Tables",
    "text": "Custom Summary Tables\nNice summary table of multiple variables using gtsummary. Great option for your Table 1.\n\n\n\n\nShow the code\nlibrary(gtsummary)\n\npen %&gt;% select(island, bill_depth_mm) %&gt;%\n  tbl_summary()\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 3441\n\n\n\n\nisland\n\n\n\n\n¬†¬†¬†¬†Biscoe\n168 (49%)\n\n\n¬†¬†¬†¬†Dream\n124 (36%)\n\n\n¬†¬†¬†¬†Torgersen\n52 (15%)\n\n\nbill_depth_mm\n17.30 (15.60, 18.70)\n\n\n¬†¬†¬†¬†Unknown\n2\n\n\n\n1 n (%); Median (Q1, Q3)\n\n\n\n\n\n\n\n\nDefault\n\n\n\nShow the code\npen %&gt;% select(island, bill_depth_mm) %&gt;%\n  tbl_summary(statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\",\n      all_categorical() ~ \"{n} / {N} ({p}%)\"\n    ))\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 3441\n\n\n\n\nisland\n\n\n\n\n¬†¬†¬†¬†Biscoe\n168 / 344 (49%)\n\n\n¬†¬†¬†¬†Dream\n124 / 344 (36%)\n\n\n¬†¬†¬†¬†Torgersen\n52 / 344 (15%)\n\n\nbill_depth_mm\n17.15 (1.97)\n\n\n¬†¬†¬†¬†Unknown\n2\n\n\n\n1 n / N (%); Mean (SD)\n\n\n\n\n\n\n\n\nCustom (preferred) summary statistics display"
  },
  {
    "objectID": "slides/lec04-describing_distributions.html#additional-materials",
    "href": "slides/lec04-describing_distributions.html#additional-materials",
    "title": "Describing Distributions of Data",
    "section": "Additional Materials",
    "text": "Additional Materials\n\nPMA6 Chapter 4\nApplied Stats course Notes Chapter 2\nsjPlot vignette: https://strengejacke.github.io/sjPlot/index.html\nggpubr vignette: https://rpkgs.datanovia.com/ggpubr/\nggplot vignette: https://ggplot2.tidyverse.org/index.html\ngtsummary vignette: https://www.danieldsjoberg.com/gtsummary/index.html\nR graphics cookbook: https://r-graphics.org/\nhttps://r-graph-gallery.com/"
  },
  {
    "objectID": "slides/lec03a-workflow.html#data-collection-is-only-the-start",
    "href": "slides/lec03a-workflow.html#data-collection-is-only-the-start",
    "title": "Workflows for Reproducibility",
    "section": "Data collection is only the start",
    "text": "Data collection is only the start\nOnce the data are available from a study there are still a number of steps that must be undertaken to get them into shape for analysis.\nOne of the most misunderstood parts of the analysis process is the data preparation stage. To say that 70% of any analysis is spent on the data management stage is not an understatement."
  },
  {
    "objectID": "slides/lec03a-workflow.html#example-workflow",
    "href": "slides/lec03a-workflow.html#example-workflow",
    "title": "Workflows for Reproducibility",
    "section": "Example Workflow",
    "text": "Example Workflow\n\nFig ref: Updated from Grolemund & Wickham‚Äôs classis R4DS schematic, envisioned by Dr.¬†Julia Lowndes for her 2019 useR! keynote talk and illustrated by Allison Horst."
  },
  {
    "objectID": "slides/lec03a-workflow.html#generating-a-reproducible-workflows",
    "href": "slides/lec03a-workflow.html#generating-a-reproducible-workflows",
    "title": "Workflows for Reproducibility",
    "section": "Generating a reproducible workflows",
    "text": "Generating a reproducible workflows\nReproducibility is the ability for any researcher to take the same data set and run the same set of software program instructions as another researcher and achieve the same results.\nNot the same as replicability where you re-run an experiment and achieve the same outcomes.\nThe goal is to create an exact record of what was done to a data set to produce a specific result."
  },
  {
    "objectID": "slides/lec03a-workflow.html#three-steps-to-achieve-reproducibility",
    "href": "slides/lec03a-workflow.html#three-steps-to-achieve-reproducibility",
    "title": "Workflows for Reproducibility",
    "section": "Three steps to achieve reproducibility",
    "text": "Three steps to achieve reproducibility\n\nThe un-processed data are connected directly to software code file(s) that perform data preparation techniques.\nThe processed data are connected directly to other software code file(s) that perform the analyses.\nAll data and code files are self-contained such that they could be given to another researcher to execute the code commands on a separate computer and achieve the same results as the original author."
  },
  {
    "objectID": "slides/lec03a-workflow.html#section",
    "href": "slides/lec03a-workflow.html#section",
    "title": "Workflows for Reproducibility",
    "section": "",
    "text": "Figure Credits: Roger Peng"
  },
  {
    "objectID": "slides/lec03a-workflow.html#literate-programming",
    "href": "slides/lec03a-workflow.html#literate-programming",
    "title": "Workflows for Reproducibility",
    "section": "Literate programming",
    "text": "Literate programming\n\nExplain the logic of the program or analysis process in a natural language,\nSmall code snippets included at each step act as a full set of instructions that can be executed to reproduce the result/analysis being discussed.\nLiterate programming tools such as Markdown and \\(\\LaTeX\\) are integrated into all common statistical packages except SPSS."
  },
  {
    "objectID": "slides/lec03a-workflow.html#reproducible-research-literate-programming",
    "href": "slides/lec03a-workflow.html#reproducible-research-literate-programming",
    "title": "Workflows for Reproducibility",
    "section": "Reproducible Research + Literate Programming",
    "text": "Reproducible Research + Literate Programming\n\nPracticing reproducible research techniques using literate programming tools allows such major updates to be a simple matter of re-compiling all coded instructions using the updated data set.\nThe effort then is reduced to a careful review and update of any written results.\nUsing literate programming tools create formatted documents in a streamlined manner that is fully synchronized with the code itself.\nThe author writes the text explanations, interpretations, and code in the statistical software program itself, and the program will execute all commands and combine the text, code and output all together into a final dynamic document."
  },
  {
    "objectID": "slides/lec03a-workflow.html#why-all-the-fuss",
    "href": "slides/lec03a-workflow.html#why-all-the-fuss",
    "title": "Workflows for Reproducibility",
    "section": "Why all the fuss?",
    "text": "Why all the fuss?\n\nYou are your own collaborator 6 months from now. Be nice to your future self\nExplain your steps (the WHY more than the what)\n\nHow did you get from point A to B?\nWhy did you recode this variable in this manner?\n\nFound an error in your analysis code? Need to add an analysis to your presentation?\nReproduce your steps in a few clicks using a script file (.R, .Rmd, .sas, .sps, .do, .ipynb)"
  },
  {
    "objectID": "slides/lec03a-workflow.html#data-analysis-pipeline",
    "href": "slides/lec03a-workflow.html#data-analysis-pipeline",
    "title": "Workflows for Reproducibility",
    "section": "Data Analysis Pipeline",
    "text": "Data Analysis Pipeline\n\n\n\nIn this model of the data science process, you start with data import and tidying. Next, you understand your data with an iterative cycle of transforming, visualizing, and modeling. You finish the process by communicating your results to other humans. Ref R for Data Science 2nd ed\n\n\nRegardless of the programming language you choose to use, using scripts will make this process reproducible and more powerful with less pain points."
  },
  {
    "objectID": "slides/lec03a-workflow.html#quarto-as-an-end-to-end-solution",
    "href": "slides/lec03a-workflow.html#quarto-as-an-end-to-end-solution",
    "title": "Workflows for Reproducibility",
    "section": "Quarto as an end-to-end solution",
    "text": "Quarto as an end-to-end solution\n\n\n‚ÄúNext Generation‚Äù R Markdown\nPublish reproducible, production quality articles, presentations, dashboards, websites, blogs, and books in HTML, PDF, MS Word, ePub, and more.\nWrite using Pandoc markdown, including equations, citations, crossrefs, figure panels, callouts, advanced layout, and more."
  },
  {
    "objectID": "slides/lec03a-workflow.html#using-r-projects",
    "href": "slides/lec03a-workflow.html#using-r-projects",
    "title": "Workflows for Reproducibility",
    "section": "Using R Projects",
    "text": "Using R Projects\n\nR Projects are a self contained workspace for you to keep all files and data related to a project.\nUses relative paths, enabling easier collaboration\nFollow this walk through from R Studio\n\n\n\n\n\n\n\nRequired\n\n\nUsing R Projects is a required part of this class. Spend a few minutes turning your Math 615 folder into an R project now."
  },
  {
    "objectID": "slides/lec01-data_arch.html#shared-experiences-1",
    "href": "slides/lec01-data_arch.html#shared-experiences-1",
    "title": "Data Architecture",
    "section": "Shared experiences",
    "text": "Shared experiences\n‚ùì What kind of tasks do you do in spreadsheets?\n‚ùì Which tasks do you think spreadsheets are good for?\n‚ùì Spreadsheet frustrations (Pain points) What have you accidentally done in spreadsheet that made you frustrated or sad?"
  },
  {
    "objectID": "slides/lec01-data_arch.html#formatting-data-in-spreadsheets",
    "href": "slides/lec01-data_arch.html#formatting-data-in-spreadsheets",
    "title": "Data Architecture",
    "section": "Formatting data in spreadsheets",
    "text": "Formatting data in spreadsheets\n\nHumans use spreadsheets differently than computers\nWhat do you want to do with the data is important to consider during setup\nYou can set things up in different ways in spreadsheets, but some of these choices can limit your ability to work with the data in other programs"
  },
  {
    "objectID": "slides/lec01-data_arch.html#good-data-handling-practices",
    "href": "slides/lec01-data_arch.html#good-data-handling-practices",
    "title": "Data Architecture",
    "section": "Good data handling practices",
    "text": "Good data handling practices\n\n‚ùå Leave raw data alone\nMinimize the amount of tidying you do to the data outside of a script.\n\nIf you have to make an adjustment, write down exactly what you did in a notes file.\n\nExport the cleaned data to a text based format like CSV (comma separated values)\nLeave missing data cells blank: don‚Äôt put a ., or missing, or 0, or NULL"
  },
  {
    "objectID": "slides/lec01-data_arch.html#tidy-data-principles",
    "href": "slides/lec01-data_arch.html#tidy-data-principles",
    "title": "Data Architecture",
    "section": "Tidy Data principles",
    "text": "Tidy Data principles\n\nPut all variables in columns - this is the thing that you‚Äôre measuring (weight, temp, address)\nOne observation per row\nDon‚Äôt combine multiple pieces of information in once cell.\npct_5_10_F : percent of females between 5 & 10 years old in that county\n\n\n\n\n\n\n\nTip\n\n\nCorresponding read: Tidy data principles by Hadley Wickham."
  },
  {
    "objectID": "slides/lec01-data_arch.html#example---livestock-data",
    "href": "slides/lec01-data_arch.html#example---livestock-data",
    "title": "Data Architecture",
    "section": "Example - livestock data",
    "text": "Example - livestock data\nConsider a study of agricultural practices among farmers in two countries in eastern sub-Saharan Africa (Mozambique and Tanzania). Researchers conducted interviews with farmers in these countries to collect data on household statistics (e.g.¬†number of household members, number of meals eaten per day, availability of water), farming practices (e.g.¬†water usage), and assets (e.g.¬†number of farm plots, number of livestock). They also recorded the dates and locations of each interview.\n\n\nThis example is from the Data Carpentry for Social Science lesson"
  },
  {
    "objectID": "slides/lec01-data_arch.html#data-for-humans",
    "href": "slides/lec01-data_arch.html#data-for-humans",
    "title": "Data Architecture",
    "section": "Data for humans",
    "text": "Data for humans\nIf they were to keep track of the data like this:\n\n‚ùì What are some of the problems with this?\n‚ùì What is actually being measured?"
  },
  {
    "objectID": "slides/lec01-data_arch.html#what-would-this-data-look-like-in-a-tidy-data-format",
    "href": "slides/lec01-data_arch.html#what-would-this-data-look-like-in-a-tidy-data-format",
    "title": "Data Architecture",
    "section": "What would this data look like in a tidy data format?",
    "text": "What would this data look like in a tidy data format?\n\n\n\n\n\n\n\n\n\nOne row per observation (farmer)\nOne topic per column (animal)\nCell value is a count of the unique combination between animal type and farmer."
  },
  {
    "objectID": "slides/lec01-data_arch.html#metadata-1",
    "href": "slides/lec01-data_arch.html#metadata-1",
    "title": "Data Architecture",
    "section": "Metadata",
    "text": "Metadata\n\nRecording data about your data (‚Äúmetadata‚Äù‚Äú) is essential.\nThink about yourself. You may know now, but the chances that you will still remember the exact wording of the question you asked about your informants‚Äô water use (the data recorded in the column water use), for example, are slim.\nThink about others. Other people may want to examine or use your data - to understand your findings, to verify your findings, to review your submitted publication, to replicate your results, to design a similar study, or even to archive your data for access and re-use by others.\n\nShould not be contained in the data file itself.\nMade for humans, not computers.\nOften called codebooks or data dictionaries"
  },
  {
    "objectID": "slides/lec01-data_arch.html#codebooks-contain-the-following-information",
    "href": "slides/lec01-data_arch.html#codebooks-contain-the-following-information",
    "title": "Data Architecture",
    "section": "Codebooks contain the following information",
    "text": "Codebooks contain the following information\n\n\n\n\nvariable name (for the computer)\nvariable label (for the human)\nthe prompt (e.g.¬†survey text question)\nplausible values\ncategorical value labels"
  },
  {
    "objectID": "slides/lec00a-welcome.html#dr.-robin-donatello-sheher",
    "href": "slides/lec00a-welcome.html#dr.-robin-donatello-sheher",
    "title": "Welcome to MATH 615",
    "section": "Dr.¬†Robin Donatello (she/her)",
    "text": "Dr.¬†Robin Donatello (she/her)\nYou can address me as ‚ÄúRobin‚Äù, ‚ÄúDr.¬†D‚Äù, or some other respectful title.\nI have a Doctorate in Public Health (DrPH) Biostatistics from UCLA, but I‚Äôm a Chico alum. I double majored in Statistics & Biology, with minor in Chemistry, and a first generation college student who started at Butte College.\nMy campus life consists of training the next generation of Scientists how to harness the power of Statistics and Data in a responsible and ethical manner, leading the Data Science Initiative (DSI) provide training and experiences for students and faculty, and providing analytical support and statistical consulting for many projects on and off campus.\nWhen I‚Äôm not on campus, typically I‚Äôm growing food for my family, out adventuring with my dogs, working on some homesteading/DIY project or getting some game time in. You can learn more about the projects i‚Äôm involved in on my website."
  },
  {
    "objectID": "slides/lec00a-welcome.html#your-turn",
    "href": "slides/lec00a-welcome.html#your-turn",
    "title": "Welcome to MATH 615",
    "section": "Your turn",
    "text": "Your turn\n\nTurn to your neighbor and introduce yourself.\nYou‚Äôll post an introduction in Discord this week so everyone will get to know everyone else."
  },
  {
    "objectID": "slides/lec00a-welcome.html#everyone-is-welcome-here",
    "href": "slides/lec00a-welcome.html#everyone-is-welcome-here",
    "title": "Welcome to MATH 615",
    "section": "Everyone is welcome here",
    "text": "Everyone is welcome here\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\nIt is my intent to present materials and activities that are respectful of diversity: gender identity, sexuality, disability, age, socioeconomic status, ethnicity, race, nationality, religion, and culture."
  },
  {
    "objectID": "slides/lec00a-welcome.html#supportive-learning-environment",
    "href": "slides/lec00a-welcome.html#supportive-learning-environment",
    "title": "Welcome to MATH 615",
    "section": "Supportive Learning Environment",
    "text": "Supportive Learning Environment\nI would like to create a learning environment that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.)"
  },
  {
    "objectID": "slides/lec00a-welcome.html#to-help-accomplish-this",
    "href": "slides/lec00a-welcome.html#to-help-accomplish-this",
    "title": "Welcome to MATH 615",
    "section": "To help accomplish this:",
    "text": "To help accomplish this:\n\nLet me know if you have a name and/or set of pronouns that differ from those that appear in your official Chico records.\nHelp me pronounce your name as accurately as possible. Corrections are welcome.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. I want to be a resource for you."
  },
  {
    "objectID": "slides/lec00a-welcome.html#learning-goals",
    "href": "slides/lec00a-welcome.html#learning-goals",
    "title": "Welcome to MATH 615",
    "section": "Learning goals",
    "text": "Learning goals\n\nDeveloping the skills to conduct statistically valid and reproducible research.\nUnderstanding how data needs to be structured and formatted for analysis, so you can better prepare data collection methods for future research.\nPracticing the skills to be the boss of your own data without relying on others to ‚Äúrun the numbers‚Äù for you.\nLearning basic statistical techniques for a small selection of analysis situations.\nLearning how to do all of this in a reproducible manner to save you headache and time during your research.\nLaying the statistical foundation so you can learn to apply more advanced statistical models as needed, such as those covered in Applied Statistics II (Math 456).\n\nSee the syllabus for more detailed learning objectives."
  },
  {
    "objectID": "slides/lec00a-welcome.html#lots-of-course-materials-and-tools",
    "href": "slides/lec00a-welcome.html#lots-of-course-materials-and-tools",
    "title": "Welcome to MATH 615",
    "section": "Lots of course materials and tools",
    "text": "Lots of course materials and tools\n\nI don‚Äôt sanitize this class for you by keeping everything in a learning management system like Canvas.\nIn a working environment you have to deal with multiple platforms, multiple accounts and manage multiple locations for files and content. I use the best tools for the job.\nHomework 0 provides a checklist for getting connected and testing out your tools.\nVideo also that goes over the details of each tool to not take up class time."
  },
  {
    "objectID": "slides/lec00a-welcome.html#project-overview",
    "href": "slides/lec00a-welcome.html#project-overview",
    "title": "Welcome to MATH 615",
    "section": "Project Overview",
    "text": "Project Overview\n\nSemester long project\nCo-authored research project with regular peer review\nAll regular assignments are designed to support your research.\nYour choice (within guidelines) of research topic and data set.\nEnd goal is a research poster presentation and research report."
  },
  {
    "objectID": "slides/lec00a-welcome.html#mode-of-instruction-attendance",
    "href": "slides/lec00a-welcome.html#mode-of-instruction-attendance",
    "title": "Welcome to MATH 615",
    "section": "Mode of Instruction / Attendance",
    "text": "Mode of Instruction / Attendance\n\nThis is an in person class. Attendance is expected\nThis is a graduate class and you all are adults with lives outside this class.\nEach class session will be live streamed, with the recording posted to Canvas within a few days.\nCommon reasons to join the class virtually:\n\nyou‚Äôre sick\nyou‚Äôre out of town on field work"
  },
  {
    "objectID": "slides/lec00a-welcome.html#collaboration-plagerism",
    "href": "slides/lec00a-welcome.html#collaboration-plagerism",
    "title": "Welcome to MATH 615",
    "section": "Collaboration & Plagerism",
    "text": "Collaboration & Plagerism\nCollaboration on assignments is encouraged. People learn better when they have someone else to talk through concepts and debugging with. However your submitted work must represent your personal effort on all parts.\n\nCollaboration on exams and individual quizzes is not allowed.\nYou can use ChatGPT/AI tools to help you learn, but you must disclose when you do.\nYour work must be your own.\n\nSee the syllabus for details on acceptable uses of collaboration."
  },
  {
    "objectID": "slides/lec00a-welcome.html#time-commitment",
    "href": "slides/lec00a-welcome.html#time-commitment",
    "title": "Welcome to MATH 615",
    "section": "Time Commitment",
    "text": "Time Commitment\n\nExpect to spend 10-12 hours each week on this class.\n\nNote that this is 1-2 hours more than an undergraduate 3 unit course would take (9 hrs). This is to acknowledge that it may take you longer than expected to complete the work until you gain practice coding.\n\nI will do my best not to move due dates so you can plan accordingly.\nUse the calendar in Canvas"
  },
  {
    "objectID": "slides/lec00a-welcome.html#syllabus",
    "href": "slides/lec00a-welcome.html#syllabus",
    "title": "Welcome to MATH 615",
    "section": "Syllabus",
    "text": "Syllabus\nThis overview is not a replacement for reading the syllabus. That document contains more information on policies and procedures that you need to be aware of. You can access an HTML version on the course website in the navigation bar, and a PDF version from inside Canvas."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Research Project Overview",
    "section": "",
    "text": "Throughout the entire semester you will work with a co-author to analyze a data set and present the results of your research. Regular homework assignments will serve as a first draft of exploration into your research questions, and helps you build your story. However expect to visualize and analyze your data outside the those assignments.\nYou will build up your project in phases, revising multiple times. Here is the general outline, with each phase is explained in detail further below.\n\nPhase 1: Data and Topic approval\nPhase 2: Introduce your project and variables of interest\nPhase 3: Explore your data and relationships\nPhase 4: Analyze bivariate relationships\nPhase 5: Multivariable modeling\nPhase 6: Summarize Findings"
  },
  {
    "objectID": "project.html#learning-resources",
    "href": "project.html#learning-resources",
    "title": "Research Project Overview",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nOur Library subject research guides. There is a guide for Math 315 (the undergraduate version of this class) that can be helpful\nUCI Library research guide: How to write a research paper\nHow to peer review by Wiley Author Services\nPeer review guide by Bates college"
  },
  {
    "objectID": "project.html#phase-1-data-and-topic-propsal",
    "href": "project.html#phase-1-data-and-topic-propsal",
    "title": "Research Project Overview",
    "section": "Phase 1: Data and Topic Propsal",
    "text": "Phase 1: Data and Topic Propsal\nIdentify a research partner, propose a research topic and corresponding data set.\nOpen source data repositories to peruse:\n\nDr.D‚Äôs curated data sets (start here)\nTeaching of Statistics in the Health Sciences Resources Portal\nData.gov\nIPUMS\nTeaching of Statistics in Health Sciences\nCity of Minneapolis data (includes police use of force)\nPew Research Center is ‚Äúa nonpartisan fact tank that informs the public about the issues, attitudes and trends shaping the world.‚Äù\nBureau of Labor Statistics\nThe All of Us Research Hub stores health data from participants from across the United States\nOther?\n\n‚ùå Sources not allowed: Machine learning repositories such as Kaggle or UCI. Data generated from experimental lab designs with few variables.\n\n\n\n\n\n\nCriteria for choosing a data set\n\n\n\n\nYou either know something about the topic or it is something you want to learn about\nFile type must be a .txt, .csv, .xlsx or .xls file\nFile size is less than 1 Gig\nA codebook or data dictionary that fully explains what each variable means is available.\nThere are at least 200 rows (observations), but ideally between 500-10,000.\nThere are 10 or more unique and interesting variables\n\nAt least 4 quantitative variables\nVariables are not functions of each other (e.g.¬†weight in lbs and weight in kg)\n\n\n\n\nYour data set must be approved before you are allowed to work with it.\nThe sooner your data is approved the sooner you can work with it! If your proposed data set is turned down twice in a row get turned down, you will be required to use one of Dr.¬†D‚Äôs curated data sets."
  },
  {
    "objectID": "project.html#phase-2-introduce-your-research-question-and-variables-of-interest",
    "href": "project.html#phase-2-introduce-your-research-question-and-variables-of-interest",
    "title": "Research Project Overview",
    "section": "Phase 2: Introduce your research question and variables of interest",
    "text": "Phase 2: Introduce your research question and variables of interest\n\nMake a copy of this Template and save it in the Poster Prep folder in our Google Drive. This template provides instructions and tips on what should be included on each slide.\nName your file using the last names of your research team. E.g. Donatello, Raymond\nFill out the required information on slides 1-5 (yellow).\n\n\nSlide 01. Title\nSlide 02. Introduction & Background\nSlide 03. Research Gap & Purpose\nSlide 04. Research Questions\nSlide 05. Study Design & Data Source"
  },
  {
    "objectID": "project.html#phase-3-exploratory-data-analysis",
    "href": "project.html#phase-3-exploratory-data-analysis",
    "title": "Research Project Overview",
    "section": "Phase 3: Exploratory data analysis",
    "text": "Phase 3: Exploratory data analysis\nFill out the required information on slides 6-9 (blue).\n\nSlide 06. Variables of Interest\nSlide 07. Response Variable Description\nSlide 08. Explanatory Variable Description\nSlide 09. Descriptive Relationship"
  },
  {
    "objectID": "project.html#phase-4-bivariate-inference",
    "href": "project.html#phase-4-bivariate-inference",
    "title": "Research Project Overview",
    "section": "Phase 4: Bivariate Inference",
    "text": "Phase 4: Bivariate Inference\nFill out the required information on slides 10-11 (purple).\nNote that if you decided to change variables since the last time, you will need to update the corresponding descriptions and graphs on prior slides.\n\nSlide 10. Statistical Analysis Methods\nSlide 11. Bivariate Analysis Results"
  },
  {
    "objectID": "project.html#phase-5-multivariable-modeling",
    "href": "project.html#phase-5-multivariable-modeling",
    "title": "Research Project Overview",
    "section": "Phase 5: Multivariable modeling",
    "text": "Phase 5: Multivariable modeling\nFill out the required information on slides 12-14 (green).\n\nSlide 12. Model building process\nSlide 13. Multivariable model result\nSlide 14. Model Assessment"
  },
  {
    "objectID": "project.html#phase-6-summarize-findings",
    "href": "project.html#phase-6-summarize-findings",
    "title": "Research Project Overview",
    "section": "Phase 6: Summarize Findings",
    "text": "Phase 6: Summarize Findings\nFill out the required information on slides 15-17 (orange).\n\nSlide 15. Discussion & Conclusions\nSlide 16. Implications & Limitations\nSlide 17. References"
  },
  {
    "objectID": "project.html#research-poster",
    "href": "project.html#research-poster",
    "title": "Research Project Overview",
    "section": "Research Poster",
    "text": "Research Poster\n\nYou will transfer all findings into a research poster, print the poster, and then present your research to your classmates during our class final period in a poster symposium format.\nFull guidelines including examples and evaluation criteria are written in this blog post.\nSubmit the poster file as printed to Canvas by the due date.\n\nDraft version\nThis draft is graded based on how complete the poster is. You should consider this a draft that you would circulate to your colleagues for final review and comments. There is a rubric in Canvas with details.\nSave your poster as a PDF and upload to the Poster-Draft folder in Google Drive.\nFinal Version\nUpload your final poster as it is printed in PDF format Canvas.\nPresentation at the Poster Symposium\nWhen not presenting, you will walk around and learn about others research. Ask the presenters questions and fill out an evaluation form as you go. Poster scoring follows the above evaluation criteria and will be done via Google Forms. The link to this semesters form is in Canvas. Printed copies will be available upon request."
  },
  {
    "objectID": "project.html#research-report",
    "href": "project.html#research-report",
    "title": "Research Project Overview",
    "section": "Research Report",
    "text": "Research Report\nFollowing the Guide for Authors you will submit a draft after Phase 3 that will be peer reviewed, and a final report at the end of the semester."
  },
  {
    "objectID": "project.html#research-development-slides",
    "href": "project.html#research-development-slides",
    "title": "Research Project Overview",
    "section": "Research Development Slides",
    "text": "Research Development Slides\nThis work will be done through a series of revisions gaining feedback from the instructor at each phase.\nEach slide will be marked one of the following categories\n\nNot Available: No content presented.\nUN: Unsatisfactory level of work. Chances are you didn‚Äôt follow instructions.\nBE: Below Expectations. Major revisions needed.\nNR: Needs Revisions. You generally got it right, but some revisions are required. This is B level work.\nME : Meets Expectations. This may still come with revisions requested.\n\n\nRubric / Assessment form\nEach team has their own ‚Äòproject assessment‚Äô Google spreadsheet that shows you what achievement level you are at for each slide. It is locked to only view mode and only you and I have access to it. At the bottom of this file you will find a personalized grading rubric containing an estimate of your final score.\nI will update your status column for the slides that are being assessed at that Phase, and enter your score into the Research Development assignment in Canvas."
  },
  {
    "objectID": "project.html#research-report-1",
    "href": "project.html#research-report-1",
    "title": "Research Project Overview",
    "section": "Research Report",
    "text": "Research Report\nSee Canvas for details and rubrics."
  },
  {
    "objectID": "modules.html",
    "href": "modules.html",
    "title": "Class Overview",
    "section": "",
    "text": "‚ö†Ô∏è Details are subject to change. See Canvas for due dates.\nLast Updated: Sun Oct 26 7:43:16 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTopic\nReading\nVideo\nSlides\nActivities\nAssess\n\n\n\n\nWelcome!\n\n\nIntroduction to the class\nTopic Overview\nSyllabus\nHelp page\n\nlec00a\nHW 0 Checklist (Canvas)\n\n\n\nHow to use the class tools\n\nposted\nlec00b\n\n\n\n\nResearch Project\n\nposted\n\n\nProject Phase 1\n\n\nData Architecture\n\n\nThe uses and structure of data\nTopic Overview\nPMA6 Ch 2\nTidy data principles\n\nlec01\nHW01\nQuiz 01\n\n\nFormulating Research Questions\n\n\nAsking Answerable Questions\nTopic Overview\nHow to Write an Effective Research Question\n\nlec02\nHW02\n\n\n\nResearch Project\n\n\n\n\nProject Phase 2\n\n\nPreparing data for analysis\n\n\nReproducible workflows\nTopic Overview\nPMA6 Ch 3\nUse R Projects\nProject Structure by Danielle Navarro\n\nlec03a\nHello, Quarto HW03\nQuiz 02\n\n\nData cleaning\n\nposted\nlec03b\n\n\n\n\nDescribing distributions of data\n\n\nDescribing a single categorical variable\nTopic Overview\nPMA6 Ch 4\nASCN Ch 2.3\nposted\nlec04\nHW04\nQuiz 03\n\n\nDescribing a single numeric variable\n\n\n\n\n\n\n\nDescribing relationships between two variables\n\n\nDescribing relationships between two variables\nTopic Overview\nPMA6 Ch 4\nIMS 1.2.4 Explantory and Response Variables\nASCN Ch 2.4\nposted\nlec05a\nHW05\nQuiz 04\n\n\nBest practices in Data Visualization\nPMA6 Ch 4.6\nposted\nlec05b\n\n\n\n\nResearch Project\n\n\n\n\nProject Phase 3 Report Draft\n\n\nFoundations for Inference\n\n\nStudy Design\nTopic Overview\nIMS - Chapter 2\n\n\nStudy Design HW06\nQuiz 05\n\n\nStatistical Inference with randomization\nIMS Chapter 11-11.1\n\nlec06a\nBias in hiring\n\n\n\nStatistical Inference with mathmatical models\nIMS - Chapter 13.1-13.3\nposted\nlec06b\nCLT Explorer\nQuiz 06\n\n\nModeling Bivariate relationships\n\n\nChoosing appropriate analysis\nTopic Overview\nPMA6 Chapter 6\nASCN Ch 5\n\nlec07a - Choosing\nHW07\n\n\n\nTwo Sample T-Test\nIMS - Chapter 20\nposted\nlec07b T-test\n\n\n\n\nANOVA\nIMS - Chapter 22\nposted\nlec07c - ANOVA\n\nQuiz 07\n\n\nChi-Squared\n\nposted\nlec07d - Chi2\n\n\n\n\nCorrelation\n\nposted\nlec07e - Correlation\n\nQuiz 08\n\n\nRegression Modeling\n\n\nSimple Linear Regression\nTopic Overview\nPMA6 Ch 7 (p98-103 Sec 7.8- 7.9 robustness, AND Section 7.13)\nAdditional reference: IMS Ch 24\nposted\nlec08\nHW08\nQuiz 09\n\n\nResearch Project\n\n\n\n\nProject Phase 4\n\n\nMultiple & Generalized Regression\n\n\nMultiple Linear Regression\nPMA6 Ch 8\nASCN Ch 9\nA blog about statistical musings\nHow to control confounding effects by statistical analysis\nposted\nlec09\nHW09\n\n\n\nGeneralized Linear Models\nPMA6 Ch 12\nASCN 11.1-11.3\n\n\n\nQuiz 10\n\n\nResearch Project\n\n\n\n\nProject Phase 5\n\n\nMeasures of Model Fit\nASCN 10.5\n\n\n\n\n\n\nVariable Selection\nASCN 10.2.1, ASCN 10.4 Intro, ASCN 10.3\n\n\n\n\n\n\nResearch Project\n\n\n\n\nProject Phase 6"
  },
  {
    "objectID": "journal/2025_Figueroa_Woodward/Figueroa-Woodward.html",
    "href": "journal/2025_Figueroa_Woodward/Figueroa-Woodward.html",
    "title": "Exploring Soil Health Indicators: Yearly Trends in PLFA Biomass and Bacteria-to-Fungi Ratios Across Depths Regenerative Farming Systems",
    "section": "",
    "text": "Abstract\nThis study aims to assess how regenerative agriculture affects PLFA biomass and fungal-to-bacteria ratios in soil systems by depth yearly. There is an increased demand for food systems and overwhelming evidence that our current agricultural practices have devastating environmental effects. Results demonstrate that RA significantly enhances microbial biomass compared to conventional methods, with consistently higher biomass across all years. However, both systems experienced declines in biomass in 2023, with RA showing partial recovery in 2024 while conventional systems stagnated. Depth-specific analyses revealed significant increases in F:B ratios at deeper soil layers, though overall trends in F:B ratios fluctuated, with an increase in 2023 followed by a decline in 2024. These patterns suggest that while RA supports soil microbial health, broader environmental or systemic pressures, such as climate variability or soil management practices, may also influence microbial dynamics.\nThese findings align with existing literature highlighting the benefits of RA for soil health and microbial diversity, yet underscore the complexity of soil ecosystems and the need for further research. The work supports the hypothesis that RA enhances microbial biomass over time and offers valuable insights for sustainable agricultural policy and practice while emphasizing the necessity of long-term studies to capture its potential benefits fully.\nRead their paper here"
  },
  {
    "objectID": "journal/2025_Cloeter_Scharberg/Cloeter-Scharberg.html",
    "href": "journal/2025_Cloeter_Scharberg/Cloeter-Scharberg.html",
    "title": "The relationship between tree-removal treatments and soil hydrophobicity in woodland encroached sagebrush ecosystems",
    "section": "",
    "text": "Abstract\nThe sagebrush ecosystem is one of the most at-risk ecosystems in the United States. Sagebrush ecosystem degradation has mostly been attributed to human disturbances, invasive plants, and woody plant encroachment. These hydrological impacts in sagebrush ecosystems are attributed to the change in vegetation structure and alterations in the ecosystem‚Äôs fire regime. Soil hydrophobicity is one hydrologic characteristic that is influenced by these changes. This analysis seeks to clarify the effect of tree-removal treatments and fire on soil hydrophobicity in a woodland-encroached sagebrush ecosystem.\n\nAbstract written by Dr.D. by copying selected lines from the intro.\n\nRead their paper here"
  },
  {
    "objectID": "hw.html",
    "href": "hw.html",
    "title": "Assignments",
    "section": "",
    "text": "Assignment\n\n\nLearning Objective\n\n\n\n\n\n\nHW 01: Data Entry\n\n\nRecording data to maintain your sanity.\n\n\n\n\nHW 02: Formulating a research hypothesis\n\n\nBrainstorming research questions to investigate\n\n\n\n\nHW 03: Data Management\n\n\nWrangling your data into analyzable form\n\n\n\n\nHW 04: Describing Distributions\n\n\nLet the data be beautiful\n\n\n\n\nHW 05: Describing Relationships\n\n\nExploring Associations between two variables\n\n\n\n\nHW 06: Foundations for Inference\n\n\nStudy design and the Normal Model\n\n\n\n\nHW 07: Bivariate Modeling\n\n\nThe starting point for most models\n\n\n\n\nHW 08: Fitting Simple Regression models\n\n\nIntro to regression\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hw/hw07-bivariate_modeling.html",
    "href": "hw/hw07-bivariate_modeling.html",
    "title": "HW 07: Bivariate Modeling",
    "section": "",
    "text": "Purpose\nWe‚Äôve been visually exploring relationships between two variables by creating appropriate plots to assess how the distribution of a primary outcome (response/dependent) variable changes according to the level of a predictor (explanatory/independent/covariate) variable. We can learn a lot by conducting exploratory data analysis, and if description is the goal then this is where your work can stop.\nHowever, if you want to make conclusions or inference about a relationship, then formal statistical analysis techniques are needed. We start here by formally testing if relationships or associations between two measures exist, then later will see how additional third variables can potentially disrupt or enhance any association that you may find.\n\n\n\nSubmission instructions\n\nUse the QMD template answer the questions.\nThis is a big assignment, so it will be broken into two stages.\n\nFirst draft will be on analyses 1-2, to make sure you are making correct progress.\nUpload a PDF of your work to the assignment to Gradescope via Canvas\n\n\n\n\n\nInstructions\nIn this assignment you will practice FOUR(4) different types of bivariate analysis:\n\n(Q~B) Quantitative Outcome ~ Binary Categorical Explanatory == Two-sample t-tests for a difference in means\n(Q~C) Quantitative Outcome ~ Categorical Explanatory == ANOVA\n(B~C) Binary Outcome ~ Categorical (or Binary) Explanatory == \\(\\chi^{2}\\) test of Association.\n(Q~Q) Quantitative Outcome ~ Quantitative Explanatory == Correlation analysis\n\nFor each analysis you will do the following steps:\n\nState which variable (including the variable name from your codebook) will be your explanatory variable and which will be your response variable.\n\nRemember, you have some variables in your codebook that can act as both categorical and quantitative.\nDecide which of those variables makes sense to ‚Äúexplain‚Äù the other. Don‚Äôt just blindly pick a bunch of variables.\nThink about the relationship among your variables, keeping in mind your original research questions. You may use gender as your categorical explanatory variable if you are struggling to find an explanatory and response relationship that makes sense.\n\nCreate an appropriate bivariate plot to visualize the relationship you are exploring. Calculate appropriate summary statistics. Summarize the relationship between the explanatory and outcome variables in short paragraph form.\nWrite the relationship you want to examine in the form of a research question using symbols and words.\n\nDefine the parameters being tested. (\\(\\rho\\), \\(p_{1}\\), \\(\\mu_{1}\\), \\(\\rho_{1}\\) etc)\nTranslate the null and alternative hypotheses into \\(H_{0}\\) and \\(H_{A}\\) with symbols.\n\nState and justify the analysis model. Check assumptions.\n\nEven if these assumptions are potentially violated, for the purposes of this assignment, acknowledge this limitation and continue with the prescribed analysis. (If a non-parametric test is appropriate, state it here.)\n\nConduct the test and make a decision about the plausibility of the alternative hypothesis.\nWrite a conclusion in context of the problem that includes a point estimate, confidence interval, and p-value."
  },
  {
    "objectID": "hw/hw05-describing_relationships.html",
    "href": "hw/hw05-describing_relationships.html",
    "title": "HW 05: Describing Relationships",
    "section": "",
    "text": "To fully explore the relationship between two variables both summary statistics and visualizations are important."
  },
  {
    "objectID": "hw/hw05-describing_relationships.html#before-you-start",
    "href": "hw/hw05-describing_relationships.html#before-you-start",
    "title": "HW 05: Describing Relationships",
    "section": "Before you start,",
    "text": "Before you start,\n\nDetermine what variables you want to graph based on your research topic.\n\nYou will need a mixture of categorical and quantitative variables for this assignment.\nYou should use variables that are relevant to your research topic.\nIf you have not yet identified both a quantitative (Q), a binary (B), and a categorical (C) variable that you are interested in, now is the time to go back to the codebook and figure this out.\n\nRecode variables as needed.\n\nIf your response variable is categorical with many levels, you may want to collapse it down to fewer than 5 levels.\n\n\nIf you do not already have a binary (B) variable in your clean data you can either a) go back and edit your dm file to include a binary varible, or b) dichotomize one of your categorical (C) varibles into two levels. (Make a new variable, don‚Äôt overwrite your categorical variable)."
  },
  {
    "objectID": "hw/hw05-describing_relationships.html#for-each-bivariate-relationship-under-consideration-you-will-do-the-following",
    "href": "hw/hw05-describing_relationships.html#for-each-bivariate-relationship-under-consideration-you-will-do-the-following",
    "title": "HW 05: Describing Relationships",
    "section": "For each bivariate relationship under consideration you will do the following:",
    "text": "For each bivariate relationship under consideration you will do the following:\n\nName and explain the two variables under consideration.\nCreate the appropriate graphic for bivariate relationship under consideration. For these plots binary variables are treated as categorical variables with only 2 levels.\n\nC ~ C: Side by side barplot\nQ ~ C: Paneled histogram with density overlaid, or a grouped boxplot with overlaid violin plot.\nQ ~ Q: Scatterplot. Add both lowess and linear trend lines.\n\nCalculate appropriate grouped summary statistics\n\nFor continuous outcomes you‚Äôll want to describe measures including the sample size, mean, median, range and variance for each level of the categorical variable.\nFor categorical outcomes you‚Äôll want to calculate %‚Äôs of your outcome measurement across levels of your covariate. Create an appropriate table using tbl_summary\n\ni.e.¬†proportion of males who are smokers compared to proportion of females who are smokers\nor proportion of smokers who are male, compared to proportion of non-smokers who are male.\n\n\nExplain the relationship or trends you see in the data in a summary paragraph. Put this paragraph below the graphic.\n\nUse summary statistics in your text explanation.\nUse specific features of the graphic in your text explanation.\n\ni.e.¬†are there outliers only in one group?\nDo the data seem clumped or clustered in one region of the scatterplot?\nIs there a linear or non-linear pattern?\nDoes one combination of categorical levels (C~C) seem to hold most the data?\nAre there any outlying data points? Don‚Äôt list off each one, just state if there is and where approximately it‚Äôs at."
  },
  {
    "objectID": "hw/hw05-describing_relationships.html#example",
    "href": "hw/hw05-describing_relationships.html#example",
    "title": "HW 05: Describing Relationships",
    "section": "Example",
    "text": "Example\n\nlibrary(tidyverse); library(ggdist)\nlibrary(sjPlot); library(gtsummary)\n\nnc &lt;- read.csv(\"https://norcalbiostat.netlify.app/data/NCbirths.csv\", header=TRUE)\npen &lt;- palmerpenguins::penguins\n\n\nC ~ C Association\nFor this example I am using the NC Births data set, data on 1000 births in 2004 from North Carolina. This example explores the association between the smoking status of the mother (habit) and whether or not the baby was born prematurely (premie). I specifically want to compare the percent of premie babies within the smoking and non-smoking groups.\n\nnc %&gt;% select(habit, premie) %&gt;%\n  tbl_summary(by = \"habit\")\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nnonsmoker\nN = 8731\nsmoker\nN = 1261\n\n\n\n\npremie\n\n\n\n\n\n\n¬†¬†¬†¬†full term\n739 (85%)\n107 (85%)\n\n\n¬†¬†¬†¬†premie\n133 (15%)\n19 (15%)\n\n\n¬†¬†¬†¬†Unknown\n1\n0\n\n\n\n1 n (%)\n\n\n\n\n\n\n\nplot_xtab(x=nc$habit, grp=nc$premie, show.total=FALSE, margin='row')\n\n\n\n\n\n\n\n\nContrary to what I was expecting, there is equal proportion of prematurely born babies to non-smokers (133/873, 15%) compared to babies born to smokers (19/126, 15%). There is no association between the smoking status of the mother and the likelihood of the baby being born prematurely.\n\n\nQ ~ C Association\nThis example explores the association between the depth of a penguins bill and the species of the penguin. The quantitative response variable is bill depth in mm (bill_depth_mm) and the categorical explanatory variable is species (species).\n\npen %&gt;% group_by(species) %&gt;% \n  summarize(n=n(), \n            mean = mean(bill_depth_mm, na.rm = TRUE), \n            median = median(bill_depth_mm, na.rm = TRUE), \n            sd = sd(bill_depth_mm, na.rm = TRUE), \n            IQR = IQR(bill_depth_mm, na.rm = TRUE)) %&gt;%\n  knitr::kable(digits=2) # for nice table format printing\n\n\n\n\nspecies\nn\nmean\nmedian\nsd\nIQR\n\n\n\n\nAdelie\n152\n18.35\n18.40\n1.22\n1.5\n\n\nChinstrap\n68\n18.42\n18.45\n1.14\n1.9\n\n\nGentoo\n124\n14.98\n15.00\n0.98\n1.5\n\n\n\n\n\n\nggplot(pen, aes(x=bill_depth_mm, y=species, fill=species)) + \n      stat_slab(alpha=.5, justification = 0) + \n      geom_boxplot(width = .2,  outlier.shape = NA) + \n      geom_jitter(alpha = 0.5, height = 0.05) +\n      stat_summary(fun=\"mean\", geom=\"point\", col=\"red\", size=4, pch=17) + \n      theme_bw() + \n      labs(x=\"Bill depth (mm)\", y = \"Species\") + \n      theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe distribution of bill depth are fairly normal for each species, with some higher end values causing a slight right skew for Adelie and Gentoo. Gentoo penguins have lower average bill depth compared to Adelie or Chinstrap (15.0mm vs 18.3 and 18.4mm respectively). Chinstrap however have a larger IQR at 1.9 compared to 1.5 for the others.\n\n\nQ ~ Q Association\nThis example explores the association between the length of a penguins flipper and it‚Äôs body mass. The quantitative response variable is body mass(body_mass_g) and the quantitative explanatory variable is flipper length (flipper_length_mm).\n\ncor(pen$flipper_length_mm, pen$body_mass_g, \n    use=\"pairwise.complete.obs\") # calculate the correlation\n\n[1] 0.8712018\n\nggplot(pen, aes(x=flipper_length_mm, y=body_mass_g)) + geom_point() + \n  geom_smooth(se=FALSE, col=\"brown\") + geom_smooth(se=FALSE, method=\"lm\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nThere is a positive association between flipper length and body mass of a penguin. The correlation coefficient is 0.87, and the form of the relationship is relatively linear."
  },
  {
    "objectID": "hw/hw03-dm.html",
    "href": "hw/hw03-dm.html",
    "title": "HW 03: Data Management",
    "section": "",
    "text": "By now you should know what variables you want to use, and you‚Äôve looked over the codebook enough now that you have an idea of some potential problems that you will encounter. This assignment uses your chosen research data, and the variables that you chose in the last assignment when you created a personal research codebook. You will thoughtfully review the variables you are interested in, document which ones will need changed and how.\nAll raw data needs to stay raw, and all changes need to be documented. You will create a script/code file that will make all changes to the data in a programatically and reproducible way. You will create a single code file that imports your raw data, performs some data cleaning steps, and saves out an analysis ready data set that you will use throughout the semester.\nYou are not expected to have completed data management for every one of your variables under consideration by the submission date. I want to see a VERY good effort has been made (raw data read in, at least 2 quant and 2 cat variables dealt with, analysis data saved out.)\nCheck the rubric in Canvas for more grade specific details."
  },
  {
    "objectID": "hw/hw03-dm.html#setup",
    "href": "hw/hw03-dm.html#setup",
    "title": "HW 03: Data Management",
    "section": "Setup",
    "text": "Setup\n\n# Load libraries\nlibrary(tidyverse)\n\n# Read in the data \nraw &lt;- read.delim(here::here(\"data/Depress.txt\"), sep=\"\\t\",  header=TRUE) %&gt;%\n  # convert all variable names to lowercase\n  janitor::clean_names()\n\n# Select only the variables that I am interested in\nmydata  &lt;- raw %&gt;% select(age, marital, cesd, health)\n\n\nGeneral Health\nThe variable health records a persons perceived general health as being either Excellent, Good, Fair or Poor. This is considered an ordinal categorical variable.\n\ntable(mydata$health)\n\n\n  1   2   3   4 \n130 115  35  14 \n\nclass(mydata$health)\n\n[1] \"integer\"\n\n\nThe variable health currently is an integer with numeric values 1-4, but the codebook states that this is a categorical variable where 1=Excellent, 2=Good, 3=Fair, 4=Poor. So I need to convert this numeric variable to a factor variable. There are no values outside the 1-4 range, such as a -9 that codes for missing data so I do not need to make any further adjustments (You want to code out missing before you convert variables to factors)\n\nmydata$health_cat &lt;- factor(mydata$health, labels=c(\"Excellent\", \"Good\", \"Fair\", \"Poor\"))\n\nI will confirm that the recode worked by making a two-way table\n\ntable(mydata$health, mydata$health_cat, useNA=\"always\")\n\n      \n       Excellent Good Fair Poor &lt;NA&gt;\n  1          130    0    0    0    0\n  2            0  115    0    0    0\n  3            0    0   35    0    0\n  4            0    0    0   14    0\n  &lt;NA&gt;         0    0    0    0    0\n\n\nThis shows that all 1‚Äôs are now ‚Äòexcellent‚Äô, 4‚Äôs are now ‚Äòpoor‚Äô and so forth.\n\n\nCESD\nThe numeric variable CESD represents the depression index scale, which is a sum of 20 component variables. A high score indicates a person who is depressed, with 16 being the typical cutoff for creating a binary indicator of depression.\n\nsummary(mydata$cesd)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   3.000   7.000   8.884  12.000  47.000 \n\nhist(mydata$cesd)\n\n\n\n\n\n\n\n\nThere are no values outside of the expected range, and no missing values.\n\n\nIndicator of Depression\nCreate the binary indicator of depression using CESD\n\nmydata$depressed &lt;- ifelse(mydata$cesd &gt; 16, \"depressed\", \"not depressed\")\ntable(mydata$depressed, useNA=\"always\")\n\n\n    depressed not depressed          &lt;NA&gt; \n           45           249             0 \n\n\nNo missing values were accidentally generated,"
  },
  {
    "objectID": "hw/hw03-dm.html#export-cleaned-data-set",
    "href": "hw/hw03-dm.html#export-cleaned-data-set",
    "title": "HW 03: Data Management",
    "section": "Export cleaned data set",
    "text": "Export cleaned data set\nKeep only selected variables and save to an external file\n\nclean &lt;- mydata %&gt;% select(age, marital, cesd, depressed, health_cat)\nsave(clean, file=here::here(\"data/depression_clean.Rdata\"))"
  },
  {
    "objectID": "hw/hw01-data_entry.html",
    "href": "hw/hw01-data_entry.html",
    "title": "HW 01: Data Entry",
    "section": "",
    "text": "Although you will be working with previously collected data, it is important to understand what data looks like as well as how it is coded and entered into a spreadsheet or dataset for analysis. This can help you identify and avoid problems later when reading data into an analysis software program. For example if you mix letters and numbers in the same cell, the variable will be treated as character not numeric."
  },
  {
    "objectID": "hw/hw01-data_entry.html#where-to-do-the-work",
    "href": "hw/hw01-data_entry.html#where-to-do-the-work",
    "title": "HW 01: Data Entry",
    "section": "Where to do the work",
    "text": "Where to do the work\nYou will enter data and create your codebook directly in Google Sheets\n\nStart a new Google spreadsheet in the 01 Data Entry folder in our shared Google Drive.\nName this file medrecords_userid where userid is your chico state user id.\nCreate and name the following worksheets: data, codebook, import."
  },
  {
    "objectID": "hw/hw01-data_entry.html#submission-instructions",
    "href": "hw/hw01-data_entry.html#submission-instructions",
    "title": "HW 01: Data Entry",
    "section": "Submission Instructions",
    "text": "Submission Instructions\nDownload your google workbook (all sheets) as an Excel file (.xlsx or .xls) and upload to Canvas by the due date."
  },
  {
    "objectID": "hw/hw01-data_entry.html#data-entry",
    "href": "hw/hw01-data_entry.html#data-entry",
    "title": "HW 01: Data Entry",
    "section": "1. Data Entry",
    "text": "1. Data Entry\n\nSelect 4 variables recorded on the medical forms\n\none should be a unique identifier, at least one should be a quantitative variable and at least one should be a categorical variable. (Ref PMA6 Ch2)\n\nSelect a brief name for each variable - write this in the first row\n\nUse good variable naming conventions:\n\nshort\nno special characters\nno spaces\ndoesn‚Äôt start with a number\n\n\nDetermine what range of values is needed for recording each variable\nEnter the data for each patient, one patient per row.\nIf data is missing for a particular value, leave the cell blank.\n\n\nRecall the tidy data principles state to put one observation per row, and one variable (characteristic) per column."
  },
  {
    "objectID": "hw/hw01-data_entry.html#codebook-creation",
    "href": "hw/hw01-data_entry.html#codebook-creation",
    "title": "HW 01: Data Entry",
    "section": "2. Codebook Creation",
    "text": "2. Codebook Creation\nIn a separate worksheet list the variable names, labels, data types, and response code or ranges in separate columns (4 columns total).\nAn example of what this should look like is below. (With the exception of the red error)"
  },
  {
    "objectID": "hw/hw01-data_entry.html#data-import",
    "href": "hw/hw01-data_entry.html#data-import",
    "title": "HW 01: Data Entry",
    "section": "3. Data Import",
    "text": "3. Data Import\n\nExport your file to your hard drive as a Comma Separated Value (*.csv).\n\nIf it asks you, only save thedata worksheet.\n\nImport this data into R.\n\nCode is fine if you already know how. Point and click is also fine for now.\nPoint and click instructions\nCode examples from R for data science and Statology\n\nNote and record any problems that you noticed and/or had to fix at the bottom of your codebook worksheet.\n\nDoes your data file look like your spreadsheet?\nDid you have to specify missing values in any specific way?\n\nShow that it worked by taking a screenshot of BOTH the code, and the view of the data.\n\nPaste these images into your import tab.\n\n\n\nExamples of import code\n\n\n\nExample R code"
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "Get help with‚Ä¶",
    "section": "",
    "text": "Helper doge wants to help you\nThis page is full of information. Use the navigation table of contents on the right side or the search bar on the left to help you find the content you are looking for."
  },
  {
    "objectID": "help.html#logistics",
    "href": "help.html#logistics",
    "title": "Get help with‚Ä¶",
    "section": "Logistics",
    "text": "Logistics\n\nWhen can I get help outside of class?\nThe home page of this website and canvas page shows the times I am available for drop in student help hours, and community coding. There is also a link to book an appointment if none of those times work for you.\nThis is when you can come talk to me about the course material, the subject in general, or life. These are my hours that I dedicate specifically to helping you. Use them! I am here to help you.\n\n\nHow do I use Discord?\nHow to use Discord YouTube video channel: https://www.youtube.com/watch?v=ppN9YbPX1Zo\n\nNOTE: You will be/have joined the Math & Stats server. You do not need to create one of your own.\n\n\n\nHow can I submit feedback?\nI want to make this class a welcome learning opportunity for everyone. I welcome your comments and constructive critique. What I do not welcome is flaming, trolling or insults. Here are some examples of appropriate uses of this feedback form.\n\nClass activities. What should I start doing, stop doing, and keep doing? Is the pace too fast? To slow?\nTopics: Is there something specific you would like brought up in class, but don‚Äôt want to be the one to bring it up?\nFlagging the Misfires. I am bound to make mistakes and microaggressions regarding culture, religion, gender, and diversity. Helping you feel safe is a real-time pursuit. If my remarks created discomfort, you can use this form to voice the concern quickly rather than saving it for the course evaluation months later.\nWords of Encouragement. I need positive feedback to keep me recharged!\n\nAnonymous Feedback Form"
  },
  {
    "objectID": "help.html#software",
    "href": "help.html#software",
    "title": "Get help with‚Ä¶",
    "section": "Software",
    "text": "Software\n\nCommunity Coding\n\nThe Data Science Initiative offers year-round training workshops and seminars on data-science related topics including R.\nCommunity Coding (CC): Students, staff, faculty, and the public are invited to join the Community Coding sessions. Bring your computer, coding projects, and your questions to this open working environment. Think of CC as additional office hours where you have access to more teachers than just me.\n\nI highly recommend making a habit to attend CC at minimum to do your homework in a supportive environment.\n\n\n\n\nR, R Studio, R Markdown/Quarto\n\nThe Math 130 Introduction to R Help page\nHello Quarto Tutorial\nUCLA IDRE R Learning modules\nR studio guides\nR for Data Science\nR graphics cookbook\n\n\n\n\nTechnology\n\nWildcat computing support page\nIT Support Services will provide comprehensive technology support, including laptop loans and virtual technology assistance.\nThe Office of Accessible Technology Services will offer all students online access to a staff member during normal business hours Monday‚ÄìFriday via email at oats@csuchico.edu. Students with questions on inclusive technology or who need assistance setting up technology accommodations are encouraged to reach out.\nIf you do not have off-campus access to the Internet, resources are available."
  },
  {
    "objectID": "help.html#assignments",
    "href": "help.html#assignments",
    "title": "Get help with‚Ä¶",
    "section": "Assignments",
    "text": "Assignments\n\nHow do I complete the assignments?\nMost homework assignments will come with a Quarto (*.qmd) template to use. You will write your code and answers directly into this .qmd file, then compile to PDF and submit to Canvas by the due date.\nLinks to the templates can be found in the homework assignment itself. A list of all assignment files can be found on the Assignments page.\n\n\nWhat are you looking for when you grade?\n\nMost assignments include examples directly in the assignment file itself.\nCorrect English grammer, spelling, formatting.\nConcise, clear and complete answers.\nCorrect statistical methods used\nThat you answered the question posed.\nNo extraneous output or code"
  },
  {
    "objectID": "help.html#peer-review",
    "href": "help.html#peer-review",
    "title": "Get help with‚Ä¶",
    "section": "Peer Review",
    "text": "Peer Review\n\nWhy do we do peer review?\n\nEveryone has different thought processes and may have approached the question from a different perspective that can help you learn the material.\nCo-authoring and reviewing your peers work is part of a professional research position.\nLearning how to provide good feedback will make you a better collaborator\nThis is a delayed version of paired programming - another set of eyeballs can typically help you find your mistake.\nI have 10fold more assignments to review than you do.\n\nYou‚Äôll get your peer‚Äôs reviews back faster than I can get yours back.\nThe more eyes on your document the better.\n\nI will be looking for different things than your peers will be. This is a good thing. They are looking from ‚Äúuntrained eyes‚Äù, which can be very critical to make sure you are explaining yourself clearly. I can better ‚Äúfigure out‚Äù what you are meaning to say - they are the ones that will best tell you when/where you need to explain your findings better.\nYou are expected to read your peer‚Äôs feedback and revise your work before it is graded.\n\n\n\nHow do I review my peers work?\n\nCheck the Peer Review Rotation spreadsheet in Google Drive to see who you are scheduled to review.\n\nIf one of your reviewees did not submit the assignment DM them in Discord first to see if they are just running a little late. If it‚Äôs getting reasonably late then just pick another person to review that doesn‚Äôt have a lot of comments so far and DM me to let me know.\n\nBy using comment bubbles, provide feedback to your peers.\n\nBe specific. Give the type of feedback that you want to receive.\nMinimum three corrections or suggestions for improvement.\n\n‚ùó Use the ‚Äúguide for peer reviews‚Äù included in each assignment. ‚≠ê\n\n\n\nGiving good feedback\n\nCompliment the author. What did you like about their writing or plots?\nMake specific suggestions regarding things like word choices, use of details, organization, topic\nMark corrections such as spelling, grammar, punctuation, analysis methods, coding errors, but don‚Äôt try to turn their paper or style into your style.\nIf you find a claim that is not supported by data in the document (or cited) be sure to point it out.\nCheck their work against what is required. Do they have all required elements?\n\nOther resources (I‚Äôm always looking for more)\n\nhttps://blog.scholasticahq.com/post/how-to-write-helpful-peer-review-comments/\nLook at the questions posed in the bubbles for each section. https://violentmetaphors.com/2013/12/13/how-to-become-good-at-peer-review-a-guide-for-young-scientists/\nhttps://blog.cengage.com/top_blog/suggested-guidelines-for-student-peer-review/\n\n\n\nGrading of peer reviews\nI will be reading and assessing your peer review. If I find your review is not providing quality feedback to the author you will not receive credit for that review. If you consistently do not provide quality feedback I reserve the right to not assign any reviews to you."
  },
  {
    "objectID": "help.html#general-resources",
    "href": "help.html#general-resources",
    "title": "Get help with‚Ä¶",
    "section": "General Resources",
    "text": "General Resources\n\nBasic Needs\nThe Hungry Wildcat Food Pantry provides supplemental food, fresh produce, CalFresh application assistance and basic needs referral services for students experiencing food and housing insecurity.\nAll students are welcomed to visit the Pantry located in the Student Service Center 196. Check the website for current hours.\nPlease visit the Chico State Basic Needs website http://www.csuchico.edu/basic-needs for more information.\n\n\nCelebrating Diversity\nThe Diversity resources for students webpage has a lot of information on clubs, organizations, resources and opportunities available to our wonderful body of non-[white/cis/hetero/able] students.\n\n\nAccomodations\nIf you need course adaptations or accommodations because of a disability or chronic illness, or if you need to make special arrangements in case the building must be evacuated, please make an appointment with me as soon as possible, or see me during office hours. Please also contact Accessibility Resource Center (ARC) as they are the designated department responsible for approving and coordinating reasonable accommodations and services for students with disabilities. ARC will help you understand your rights and responsibilities under the Americans with Disabilities Act and provide you further assistance with requesting and arranging accommodations.\n\n\nTutoring\nThe Student Learning Center will provide all learning support services online. Students can schedule appointments on the Center‚Äôs website. The Supplemental Instruction program will also be available virtually, utilizing peer-assisted study sessions to increase student success in historically difficult courses. Student leaders are faculty-recommended and trained to facilitate group sessions. Math tutoring is available via Zoom from the Math Learning Lab.\nFor help specifically with programming, seek Community Coding\n\n\nFinancial Aid\nFinancial Aid & Scholarship Office is providing financial aid assistance virtually. Contact finaid@csuchico.edu or call 530-898-6451 and to set up an appointment by phone or Zoom.\n\n\nHealth Center\nThe WellCat Health Center is available by appointment for regular healthcare services. Visit their website for current hours and appointment times.\n\n\nCovid-19\nJust a reminder that COVID is still a nasty and deadly disease for some. Each time you contract Covid you increase your chance of getting long covid, which is a debilitating and disabling disease. In this class it is critical that we respect each others‚Äô choices to mask or not.\nCampus information can be found here.\n\n\nMental Health\nOnline counseling is available through the WellCat Counseling Center and Safe Place. Find specific information on their websites.\n\n\nCareer Center\nThe Career Center remains virtual only, but will continue providing a wide variety of career development programs for students of all majors and class levels, and for all alumni. It also offers services to help students with the transition from student to working professional."
  },
  {
    "objectID": "author_guide.html",
    "href": "author_guide.html",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "",
    "text": "The Journal of MATH 615 is the official internal publication of the Data Analysis for Graduate Research course at California State University at Chico. Specific details as to project deadlines, rubrics, and more can be found for current students on the Canvas course page."
  },
  {
    "objectID": "author_guide.html#reproducibility",
    "href": "author_guide.html#reproducibility",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Reproducibility",
    "text": "Reproducibility\nTo ensure reproducibility and provide transparency, all results from the manuscript must be generated via a single, commented standalone replication script. This includes any necessary data preparation steps. Code that was ultimately not used in the final report should be excluded."
  },
  {
    "objectID": "author_guide.html#required-template",
    "href": "author_guide.html#required-template",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Required template",
    "text": "Required template\nTo facilitate authoring manuscripts in the required style, we require authors to use this custom quarto template and bibliography file."
  },
  {
    "objectID": "author_guide.html#cover-image",
    "href": "author_guide.html#cover-image",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Cover image",
    "text": "Cover image\nAuthors are encouraged to submit a .jpg or .png image that would be used as a cover image in the publication."
  },
  {
    "objectID": "author_guide.html#page-limits",
    "href": "author_guide.html#page-limits",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Page Limits",
    "text": "Page Limits\nArticles are expected to be between 10 and 15 pages. These pages limits include the required figures and tables, but not references nor the Appendix."
  },
  {
    "objectID": "author_guide.html#title-and-author-information",
    "href": "author_guide.html#title-and-author-information",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Title and Author Information",
    "text": "Title and Author Information\nThe article should have an informative title. Additionally, author information should include:\n\nAuthor name\nAuthor degrees\nAuthor affiliation (e.g., BIOL MS Student, MSDSA Student, Center for Regenerative Agriculture, etc.)"
  },
  {
    "objectID": "author_guide.html#abstract-and-keywords",
    "href": "author_guide.html#abstract-and-keywords",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Abstract and Keywords",
    "text": "Abstract and Keywords\nA short abstract should describe the problem, data, and results.\nImmediately after the abstract, provide a maximum of 5 keywords, avoiding general and plural terms and multiple concepts (avoid, for example, ‚Äòand‚Äô, ‚Äòof‚Äô). These keywords will be used for indexing purposes."
  },
  {
    "objectID": "author_guide.html#tables-and-figures",
    "href": "author_guide.html#tables-and-figures",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Tables and Figures",
    "text": "Tables and Figures\nA minimum of one table and one figure is required for all publications.\nAll tables and figures should be ‚Äúpublication ready‚Äù with informative titles, labels, and captions. Where applicable, units of measurement should be included. Variable names from code should be replaced with meaningful labels (e.g., instead of outcome_variable4 write the actual outcome).\nArticles must include a ‚ÄúTable 1‚Äù that describes the study population in a tabular format. Additional tables and figures may be included as necessary to present and summarize results. These count towards the page limit."
  },
  {
    "objectID": "author_guide.html#decimal-numerals",
    "href": "author_guide.html#decimal-numerals",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Decimal Numerals",
    "text": "Decimal Numerals\nTo enhance readability and clarity of the text as well as tables and figures, decimal numerals should - with the obvious exception of P-values - be rounded to the unit whenever possible (i.e.¬†in all cases in which the rounding procedure does not change the meaning). Consider using the scales::label_pvalue function as applicable."
  },
  {
    "objectID": "author_guide.html#tbl-cap",
    "href": "author_guide.html#tbl-cap",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Captions",
    "text": "Captions\n\nFor Tables use tbl-\n\n```{r}\n#| label: tbl-lm\n#| tbl-cap: \"A regression model.\"\n\npen &lt;- palmerpenguins::penguins\nlm(body_mass_g ~ island + bill_length_mm, data = pen) |&gt;\n  gtsummary::tbl_regression()\n```\n\n\n\nTable¬†1: A regression model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\nisland\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Biscoe\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Dream\n-919\n-1,034, -804\n&lt;0.001\n\n\n¬†¬†¬†¬†Torgersen\n-523\n-692, -355\n&lt;0.001\n\n\nbill_length_mm\n77\n67, 88\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor Figures use fig-\n\n```{r}\n#| label: fig-scatter\n#| fig-cap: \"A scatterplot\"\n#| fig-width: 4\n#| fig-height: 4\n\nggpubr::ggscatter(pen, x = \"bill_length_mm\", y = \"body_mass_g\", \n                  color = \"island\",\n                  add = \"loess\", conf.int = TRUE)\n```\n\n\n\n\n\n\n\nFigure¬†1: A scatterplot"
  },
  {
    "objectID": "author_guide.html#sec-crf",
    "href": "author_guide.html#sec-crf",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Cross-references",
    "text": "Cross-references\n\n\n\n\n\n\n\nMarkdown Format\nOutput\n\n\n\n\n@fig-scatter is pretty.\nFigure¬†1 is pretty.\n\n\n@tbl-lm was created from code.\nTable¬†1 was created from code.\n\n\n@sec-crf is this section.\nSection¬†2.7 is this section.\n\n\n@eq-black-scholes is above.\n?@eq-black-scholes is above.\n\n\n\nSee the Quarto documentation on cross-references for more info."
  },
  {
    "objectID": "author_guide.html#sec-citations",
    "href": "author_guide.html#sec-citations",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Citation Syntax",
    "text": "Citation Syntax\nThe journal template contains a Bibtex .bib file for you to use. Any style of reference is acceptable as long as formatting is consistent. See the Quarto section of the BibTeX guide and the Citation guide from the Quarto documentation for information on how to cite articles and include a reference section in Quarto.\n\n\n\n\n\n\n\nMarkdown Format\nOutput\n\n\n\n\nBlah Blah [see @knuth1984, pp. 33-35;\nalso @wickham2015, chap. 1]\nBlah Blah (see Knuth 1984, 33‚Äì35; also Wickham 2015, chap. 1)\n\n\nBlah Blah [@knuth1984, pp. 33-35,\n38-39 and passim]\nBlah Blah (Knuth 1984, 33‚Äì35, 38‚Äì39 and passim)\n\n\nBlah Blah [@wickham2015; @knuth1984].\nBlah Blah (Wickham 2015; Knuth 1984).\n\n\nWickham says blah [-@wickham2015]\nWickham says blah (2015)\n\n\n\nYou can also write in-text citations, as follows:\n\n\n\n\n\n\n\nMarkdown Format\nOutput\n\n\n\n\n@knuth1984 says blah.\nKnuth (1984) says blah.\n\n\n@knuth1984 [p. 33] says blah.\nKnuth (1984, 33) says blah."
  },
  {
    "objectID": "author_guide.html#introduction-and-background",
    "href": "author_guide.html#introduction-and-background",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Introduction and Background",
    "text": "Introduction and Background\nThis section sets the stage for your study by explaining the context, importance, and purpose of your work. It should give the reader enough background to understand why your research matters.\n\nBriefly describe the problem or topic and why it is important.\nSummarize relevant literature and clearly state your research question or hypothesis."
  },
  {
    "objectID": "author_guide.html#study-design-and-data-collection",
    "href": "author_guide.html#study-design-and-data-collection",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Study Design and Data collection",
    "text": "Study Design and Data collection\nHere you explain how the study was planned and how data were obtained. This ensures the reader can understand and evaluate the reliability of your results.\n\nDescribe the type of study (e.g., observational, experimental) and its key features.\nExplain how data were collected, including sources, time frames, and any selection criteria."
  },
  {
    "objectID": "author_guide.html#methods",
    "href": "author_guide.html#methods",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Methods",
    "text": "Methods\nUse separate sub-sections for data preparation and statistical analysis methods.\n\nData Preparation\nThis part details the steps taken to clean, organize, and prepare the data before analysis.\n\nDescribe any data cleaning procedures (e.g., handling missing values, correcting errors).\nExplain how variables were defined, transformed, or categorized.\n\n\n\nStatistical Analysis\nThis section explains the techniques and tools used to answer your research question.\n\nIdentify the statistical methods and justify why they were appropriate.\nSpecify the software or packages used for analysis."
  },
  {
    "objectID": "author_guide.html#results",
    "href": "author_guide.html#results",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Results",
    "text": "Results\nPresent your findings clearly and objectively, without interpretation or speculation. Use separate sub-sections for descriptive statistics and results of statistical models.\n\nReport key results in text, tables, or figures, focusing on what is most relevant to the research question.\nInclude appropriate summary statistics and measures of uncertainty (e.g., confidence intervals, p-values)."
  },
  {
    "objectID": "author_guide.html#discussion-conclusion",
    "href": "author_guide.html#discussion-conclusion",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Discussion, Conclusion",
    "text": "Discussion, Conclusion\nInterpret your results, explain their meaning, and place them in context with existing knowledge.\n\nSummarize the main findings and discuss their implications or applications.\nAddress limitations of the study and suggest directions for future research."
  },
  {
    "objectID": "author_guide.html#references",
    "href": "author_guide.html#references",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "References",
    "text": "References\nThe journal template contains a Bibtex .bib file for you to use. Any style of reference is acceptable as long as formatting is consistent. See the Quarto section of the BibTeX guide and the Citation guide from the Quarto documentation for information on how to cite articles and include a reference section in Quarto."
  },
  {
    "objectID": "author_guide.html#appendix",
    "href": "author_guide.html#appendix",
    "title": "Journal of Math 615 Guide for Authors",
    "section": "Appendix",
    "text": "Appendix\nAll of the code used for this report should be included and executed here. Do not include extraneous code or output not directly relevant to the results reported in this research report.\nCode that are used in the body of the text to produce results should not be showing. You can turn off code chunk ‚Äúechoing‚Äù at the chunk level. See the Quarto Execution Options documentation for examples."
  },
  {
    "objectID": "helper_code.html",
    "href": "helper_code.html",
    "title": "How do I‚Ä¶.",
    "section": "",
    "text": "This page is dedicated to showing example code for selected tasks.\npen &lt;- palmerpenguins::penguins\nlibrary(gtsummary)\nlibrary(tidyverse)\nlibrary(performance) # for check_model. You will also need to install the `see` package\n# webshot2 -- You will have to install this package to use gtsave but don't need to load it"
  },
  {
    "objectID": "helper_code.html#export-to-a-file",
    "href": "helper_code.html#export-to-a-file",
    "title": "How do I‚Ä¶.",
    "section": "Export to a file",
    "text": "Export to a file\nMake it look good first.\n\nggplot(analysis.data, aes(x=`Bill Length (mm)`, \n                          y = `Bill Depth (mm)`, \n                          color = Sex)) + \n  geom_point() + \n  theme_bw(base_size=18)\n\n\n\n\n\n\n\n\nThen save. Import this into your poster file and adjust the width and height as needed.\n\nggplot(analysis.data, aes(x=`Bill Length (mm)`, \n                          y = `Bill Depth (mm)`, \n                          color = Sex)) + \n  geom_point() + \n  theme_bw(base_size=18) \n  ggsave(filename = \"myplot.png\",  plot = get_last_plot(),\n         width = 6, height = 6, units = \"in\")"
  },
  {
    "objectID": "helper_code.html#remove-a-legend",
    "href": "helper_code.html#remove-a-legend",
    "title": "How do I‚Ä¶.",
    "section": "Remove a legend",
    "text": "Remove a legend\n\nggplot(pen, aes(x=island, fill = island)) + geom_bar() + \n  theme(legend.position=\"none\")"
  },
  {
    "objectID": "helper_code.html#resizing-your-output",
    "href": "helper_code.html#resizing-your-output",
    "title": "How do I‚Ä¶.",
    "section": "Resizing your output",
    "text": "Resizing your output\nNecessary to not make certain plots super squished.\nWithout resizing.\n\ncheck_model(model) # from the performance package\n\n\n\n\n\n\n\n\nApply a code chunk option (#|) to resize the height\n\n```{r}\n#| fig-height: 10\ncheck_model(model)\n```"
  },
  {
    "objectID": "hw/hw02-rq_formulation.html",
    "href": "hw/hw02-rq_formulation.html",
    "title": "HW 02: Formulating a research hypothesis",
    "section": "",
    "text": "Learn more about your chosen research data and formulate a testable research hypothesis. This will guide your focus for the rest of the semester. In this assignment you will\n\nDecide on a specific research topic\nChoose variables that relate to your topic\nFormulate a testable research hypothesis (or Research Question - RQ)\nConduct a literature review to learn more about your topic"
  },
  {
    "objectID": "hw/hw02-rq_formulation.html#topic-area-statement",
    "href": "hw/hw02-rq_formulation.html#topic-area-statement",
    "title": "HW 02: Formulating a research hypothesis",
    "section": "1. Topic area statement:",
    "text": "1. Topic area statement:\nThoroughly review the codebook for your dataset of choice and make note of topics that interest you. Use this as a brainstorming session and identify as much as you can. Write a statement similar to the one below regarding what topic(s) you are interested in. You should also explain WHY you are interested in your topic.\n\nExample: After looking through the codebook for the U.S. Longitudinal Study of Adolescent to Adult Health study database, I have decided that I am particularly interested in nicotine dependence. I am not sure which variables I will use regarding nicotine dependence (e.g.¬†symptoms or diagnosis) so for now I will include all of the relevant variables in my personal codebook. While nicotine dependence is a good starting point, I need to determine what it is about nicotine dependence that I am interested in. It strikes me that friends and acquaintances that I have known through the years that became hooked on cigarettes did so across very different periods of time. Some seemed to be dependent soon after their first few experiences with smoking and others after many years of generally irregular smoking behavior. I decided that I am most interested in exploring the association between level of smoking and nicotine dependence. Below I have added to my codebook variables reflecting smoking levels (e.g.¬†smoking quantity and frequency). If my topic is too vague, I would like to bring suicide in. I would be interested to see if there is any relationship between level of smoking with nicotine dependence and suicide."
  },
  {
    "objectID": "hw/hw02-rq_formulation.html#personal-codebook",
    "href": "hw/hw02-rq_formulation.html#personal-codebook",
    "title": "HW 02: Formulating a research hypothesis",
    "section": "2. Personal Codebook:",
    "text": "2. Personal Codebook:\nCreate your personal codebook. You will create a trimmed down version of the codebook to help you not get overwhelmed with the larger pool of available questions.\n\nNarrow focus to reduce cognitive load\nCreate a trimmed down version of the codebook\nInclude the questions/items/variables from the full data codebook that measure your selected topics.\nChoose between 5 and 20 variables. This is just a starting point, you can modify anytime later.\nDon‚Äôt reinvent the wheel - take little screenshots with the snipping tool. - In the pdf file, go to Edit, Take a Snap Shot, then click and drag over what you want. - If you are on a MAC, press Shift+Command+Ctrl+4 to get the snip tool.\n\n\nExample Codebook screenshots"
  },
  {
    "objectID": "hw/hw02-rq_formulation.html#draft-a-few-research-questions",
    "href": "hw/hw02-rq_formulation.html#draft-a-few-research-questions",
    "title": "HW 02: Formulating a research hypothesis",
    "section": "3. Draft a few Research Questions",
    "text": "3. Draft a few Research Questions\nNow that you have a few topics and picked out variables for each topic, what questions are you interested in trying to answer about your topics? One of the simplest research questions that can be asked is whether two constructs are associated. You will write 2-3 questions, and then refine based off information you learn from conducting a literature review (next part of this assignment).\nYour research questions should be written as\n\na relationship between two measurements\na testable hypothesis (can you answer yes or no to the question?)\n\n\nQuestions example:\na) Does smoking quantity relate to nicotine dependence?\nb) Is there a relationship between smoking frequency and suicide?\nc) Does a smoker have more suicidal behaviors than a non-smoker?"
  },
  {
    "objectID": "hw/hw02-rq_formulation.html#literature-review",
    "href": "hw/hw02-rq_formulation.html#literature-review",
    "title": "HW 02: Formulating a research hypothesis",
    "section": "4. Literature review",
    "text": "4. Literature review\nTo refine your research question you need to know what has been studied in recent years. Before you start this assignment be sure to have read the article on ‚Äúhow to read a journal article‚Äù, and the lecture notes on ‚Äúhow to conduct a literature review‚Äù. This assignment will help you identify gaps in the current literature regarding your research topic, and refine your research question and set of potential variables substantially.\nYou need at least 3 primary source references that are directly related to your topic that were published in 2008 or more recent.\nFor each article, you will complete steps 1-3, in other words 3 times. There is an example at the bottom of this document.\n\nStep 1:\n\nPut the reference for the article in APA style. Here is a link to Purdue Owl APA style references that will guide you.\n\nNOTE: If you use a citation creator you still need to compare each part of all your references to make sure it was done correctly. The citation creator usually messes up on something.\nGood/suggested bibliography managers\n\nBibDesk (Mac) http://bibdesk.sourceforge.net/\nZotero (in browser) https://www.zotero.org/\nMendeley (download) https://www.mendeley.com/\n\n\n\n\nStep 2:\nRead an article, type up a brief summary (a few sentences) of what you learned about your topic from introduction/lit review and the discussion. This summary should convey the main themes and findings overall for the literature review and discussion in your own words.\n\n\nStep 3:\nThen explain how the article is going to help you with writing up your project. This is an explanation of what the article contributes to your project, not a restating of the summary. For example, is it going to help explain one or both of your topics, does it explain a key theory, what argument does it help you build for your project?\n\nLit review examples\n\nMy research question is: Is self-efficacy associated with parent relations and academic performance?\nWeiser, D. A., & Riggio, H. R. (2010). Family background and academic achievement: Does self-efficacy mediate outcomes? Social Psychology of Education: An International Journal, 13(3), 367-383.\n\nThis article discusses whether self-efficacy mediates the relationship between family background and academic achievement. This is very similar to my topic but I feel that the component of mediation changes it slightly. I found that family predictors did not correlate with academic achievement as much as self-efficacy correlates with parent‚Äôs expectation of academic success. Self-efficacy is linked to grade point average and academic success expectations.\nThis information will be vital to understanding the extent to which self-efficacy is related to academic performance. With the correlation being weak for family background and academic performance, it will do less to determine the connection of parental relations to self-efficacy.\n\nTurner, E. A., Chandler, M., & Heffer, R. W. (2009). The influence of parenting styles, achievement motivation, and self-efficacy on academic performance in college students. Journal of College Student Development, 50(3), 337-346.\n\nThis study looks at how parenting styles, authoritative in particular, relate to academic performance, self-efficacy, and intrinsic motivation in college students. It claims that all factors, academic performance, self-efficacy, and intrinsic motivation, are all influenced by authoritative parenting. What I learned about my topic is this study did find that self-efficacy was not significantly linked to authoritative parenting.\nThis article will help explain how this specific type of parenting, authoritative, has little affect of self-efficacy. It does not however, claim that parenting, as a whole has not effect on self-efficacy. This study does confirm that parenting does reflect on academic performance.\n\nJunttila, N., Vauras, M., & Laakkonen, E. (2007). The role of parenting self-efficacy in children‚Äôs social and academic behavior. European Journal of Psychology of Education, 22(1), 41-61.\n\nThis article looks at parenting self-efficacy. This is a little different from my topic but there are aspects of it that will be useful. It tested Finnish mothers and fathers to test for loneliness, parent self-efficacy, their child‚Äôs peer evaluated social competence, self-evaluated loneliness and academic skills. It found that parents loneliness reflected in their self-efficacy. The relationship between parent self-efficacy and the child‚Äôs academic achievement were evaluated through the child‚Äôs social competence. What I learned from this article that I can use is that parent‚Äôs self-efficacy can be reflected in the children.\nThis article is gong to help me tie in influences in the parent relations with the children to determine self-efficacy. This is an interesting perspective that wasn‚Äôt originally in my research question but I believe it will give valuable insight."
  },
  {
    "objectID": "hw/hw02-rq_formulation.html#refine-your-research-questions",
    "href": "hw/hw02-rq_formulation.html#refine-your-research-questions",
    "title": "HW 02: Formulating a research hypothesis",
    "section": "5. Refine your Research Questions",
    "text": "5. Refine your Research Questions\nBased on your literature review some of your draft questions may already be answered, or you noticed that your question is a still too vague. Now is the time to refine this question. Here are some example revisions.\n\nQuestions example:\na) Does the number of cigarettes smoked in the past month relate to nicotine dependence in college-aged adults in the United States?\nb) Is there a relationship between smoking frequency and suicide? Is this relationship the same in males and females?"
  },
  {
    "objectID": "hw/hw04-describing_distributions.html",
    "href": "hw/hw04-describing_distributions.html",
    "title": "HW 04: Describing Distributions",
    "section": "",
    "text": "Purpose\nThere are a variety of conventional ways to visualize data - tables, histograms, bar graphs, etc. The purpose is always to examine the distribution of variables related to your research question. You will create a plot, follow up each graphic with a table of summary statistics (for quantitative variables) or frequency and proportion table (for categorical), and then a summary paragraph that brings it all together.\n\n\n\nInstructions\nPART 1: Completely describe 2 categorical and 2 quantitative variables using all of the following:\n\nAn explanation of what the variable is, and how it is measured.\nA table of summary statistics,\nAn appropriate plot with titles and axes labels (include both a histogram and boxplot for numeric data)\nA short paragraph description in full complete English sentences.\n\nPART 2: Create an all-inclusive summary table using the tbl_summary() function inside the gtsummary package. See slide 10 in the lec04 notes or the gtsummary tutorial. Include all 4 variables that were analyzed as part of this assignment.\nTo guide your description of this distribution try to include the following information:\n\nWhat is the trend in the data? What exactly does the chart show? (Use the chart title to help you answer this question)\nDescribe the location of the bulk of the data. Measures include\n\nMeasures of center: mean/median\nIQR as Q3 and Q1 (i.e., 50% of the data lie between \\(x_{1}\\) and \\(x_{2}\\))\nN and (%) for categorical data for the largest category.\n\nDescribe the shape (for quantitative measures only):\n\nSymmetry/Skewness - Is it symmetric, skewed right, or skewed left?\nModality - Is it uniform, unimodal, or bimodal?\n\n\nDescribe the spread or variability in the data\n\nAppropriate measures include range, standard deviation, IQR for continuous data\nFor categorical data describe if distribution is spread across multiple response categories or mainly only one.\n\nDescribe the outliers (note: there may not be any for every graph). Continuous data only.\n\nAre there any outliers for the variable?\nIf yes, are these true outliers or false (due to data management or input error) outliers? (This could alert you to missing codes like -77 or 99 that need to be set to missing)\n\n\n\n\n\nSubmission instructions\n\nUse the template provided: [QMD]\n\nRight click and ‚Äòsave as‚Äô, put this in your scripts folder\n\nUpload your draft PDF to Canvas by the due date.\n\n\n\n\n\nExample - Part I\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(ggpubr)\nlibrary(gtsummary)\n\nload(here::here(\"data/depression_clean.Rdata\")) # your import line will look something like this\n\n\nThe depressed variable is an indicator variable created from the CESD scale to identify potential clinical depression. This variable has two levels: depressed or not depressed.\n\n\nplot_frq(clean$depressed)\n\n\n\n\n\n\n\n\n\nThe majority of respondents in this data set are not considered depressed; 84.7% (n=249) individuals did not meet the threshold on the CESD scale to indicate potential clinical depression.\n\n\nggviolin(clean$age, add = c(\"jitter\", \"boxplot\")) + \n  coord_flip() + labs(x=\"\", y=\"Age\")\ngghistogram(clean$age, add_density = TRUE) + xlab(\"Age\")\n\n\n\n\n\n\n\n\n\n\n\nThe ages of respondents range from 18 to 89 years old, is bimodal with peaks around 25 and 55ish. The mean age is 44.4 with the median very close at 42.5 - confirming the lack of skew. The standard deviation is 18, and 50% of the reported ages lie between 28 and 59.\n\n\n\nExample - Part II\n\ntbl_summary(clean, \n            include = c(age, depressed), \n            statistic = list(\n              all_continuous() ~ \"{mean} ({sd})\",\n              all_categorical() ~ \"{n} / {N} ({p}%)\"\n    ))\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2941\n\n\n\n\nage\n44 (18)\n\n\ndepressed\n\n\n\n\n¬†¬†¬†¬†depressed\n45 / 294 (15%)\n\n\n¬†¬†¬†¬†not depressed\n249 / 294 (85%)\n\n\n\n1 Mean (SD); n / N (%)"
  },
  {
    "objectID": "hw/hw06-foundations_for_inference.html",
    "href": "hw/hw06-foundations_for_inference.html",
    "title": "HW 06: Foundations for Inference",
    "section": "",
    "text": "To understand the conceptual and mathematical foundations for conducting statistical inference.\n\n\n\n\nDownload this [QMD] file and use it to write your answers in.\n\nRight click and ‚Äòsave as‚Äô, put this in your scripts folder.\n\n\n\n\n\n\n\n\nSubmission adjustments\n\n\n\nDo the work in this document, and when complete you will submit your answers into the Canvas assignment ‚Äúquiz‚Äù."
  },
  {
    "objectID": "hw/hw06-foundations_for_inference.html#purpose",
    "href": "hw/hw06-foundations_for_inference.html#purpose",
    "title": "HW 06: Foundations for Inference",
    "section": "",
    "text": "To understand the conceptual and mathematical foundations for conducting statistical inference."
  },
  {
    "objectID": "hw/hw06-foundations_for_inference.html#submission-instructions",
    "href": "hw/hw06-foundations_for_inference.html#submission-instructions",
    "title": "HW 06: Foundations for Inference",
    "section": "",
    "text": "Download this [QMD] file and use it to write your answers in.\n\nRight click and ‚Äòsave as‚Äô, put this in your scripts folder.\n\n\n\n\n\n\n\n\nSubmission adjustments\n\n\n\nDo the work in this document, and when complete you will submit your answers into the Canvas assignment ‚Äúquiz‚Äù."
  },
  {
    "objectID": "hw/hw08-slr.html",
    "href": "hw/hw08-slr.html",
    "title": "HW 08: Fitting Simple Regression models",
    "section": "",
    "text": "Practice fitting and interpreting the coefficients of a simple regression model."
  },
  {
    "objectID": "hw/hw08-slr.html#example-body-mass-and-bill-length-of-penguins",
    "href": "hw/hw08-slr.html#example-body-mass-and-bill-length-of-penguins",
    "title": "HW 08: Fitting Simple Regression models",
    "section": "Example: Body mass and bill length of penguins",
    "text": "Example: Body mass and bill length of penguins\n\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(performance)\npen &lt;- palmerpenguins::penguins\n\n\n1. Identify response and explanatory variables\n\nThe quantitative explanatory variable is body mass (g) body_mass_g\nThe quantitative response variable is bill length (mm) bill_length_mm\n\n\n\n2. Visualize and summarise bivariate relationship\n\nggplot(pen, aes(x=body_mass_g, y=bill_length_mm)) + \n  geom_point() + geom_smooth(col = \"blue\")\n\n\n\ncor(pen$body_mass_g, pen$bill_length_mm, use = \"pairwise.complete.obs\")\n\n[1] 0.5951098\n\n\nThere is a strong, positive, mostly linear relationship between the body mass (g) of penguins and their bill length (mm) (r=.595).\n\n\n3. Write the relationship you want to examine\nLet \\(\\beta_1\\) be the true slope parameter that describes the change in bill length of the penguin as body mass increases.\n\n\\(H_{0}: \\beta_{1}=0\\) There is no linear relationship between body mass and bill length.\n\\(H_{A}: \\beta_{1} \\neq 0\\) Alternate Hypothesis: There is a linear relationship between body mass and bill length.\n\n\n\n4. Fit the regression model\nDecide if there is evidence to believe that there is a relationship\n\npen.body.bill &lt;- lm(bill_length_mm ~ body_mass_g, data=pen)\npen.body.bill |&gt; summary()\n\n\nCall:\nlm(formula = bill_length_mm ~ body_mass_g, data = pen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.1251  -3.0434  -0.8089   2.0711  16.1109 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2.690e+01  1.269e+00   21.19   &lt;2e-16 ***\nbody_mass_g 4.051e-03  2.967e-04   13.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.394 on 340 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3542,    Adjusted R-squared:  0.3523 \nF-statistic: 186.4 on 1 and 340 DF,  p-value: &lt; 2.2e-16\n\n\nThe p-value for \\(b_{1}\\) is &lt;.0001, so there is sufficient evidence to believe that there is a linear relationship between body mass and bill length.\n\n\n5. Verify assumptions & assess model fit\nIn the scatterplot, Both the outcome and predictor are continuous variables that have a visible linear relationship, and we assume the observations are independent.\n\ncheck_model(pen.body.bill) |&gt; plot()\n\n\n\n\n\nThe distribution of the residuals is mostly normal, pretty heavy right tail. This is indicative of a nonlinear trend somewhere in the data.\nThe variance of Y is not constant. This is a warning that our linear model does not fit the data well and we should look into possible refinements and improvements.\nThe observed distribution of bill length is bimodal, and so the model is overestimating some values and underestimating others. There is clearly some other confounding variable that predicts bill length better than just body mass.\n\n\n\n6. Write a conclusion in context of the problem.\n\npen.body.bill |&gt; \n  tbl_regression(intercept=TRUE, \n                 # to increase the display digits\n                 estimate_fun = purrr::partial(style_ratio, digits = 3)) |&gt;\n  add_glance_source_note(include = c(r.squared))\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI\n      p-value\n    \n  \n  \n    (Intercept)\n26.90\n24.40, 29.40\n&lt;0.001\n    body_mass_g\n0.004\n0.003, 0.005\n&lt;0.001\n  \n  \n    \n      Abbreviation: CI = Confidence Interval\n    \n    \n      R¬≤ = 0.354\n    \n  \n  \n\n\n\n\n\nFor a penguin who weighs 0 kg, the predicted bill length is 26.9 (24.4, 29.4)mm. This is an impossible situation.\n\nEach 1g increase in body mass of a penguin is associated with a significant increase of 0.004 (0.0035, 0.0046) mm of bill length (p&lt;.0001). In more reasonable numbers, an increase of 1kg of body mass in a penguin corresponds to a 4(3.5, 4.6) mm increase in bill length.\nBody mass explains 35.4% of the variation in bill length.\n\nHowever, model diagnostics indicate that a linear model may not be appropriate for this relationship. The assumption of constant variance is not upheld and there may be another variable that affects bill length."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis for Graduate Research",
    "section": "",
    "text": "This course provides a hands-on introduction to using data to rigorously answer research questions. Students practice cleaning and manipulating data, creating data visualizations, and conducting introductory level statistical analysis using real-world data sets that are relevant to their field. Analysis topics include single and two-sample inference, analysis of variance, multiple regression, analysis of co-variance, experimental design, repeated measures, nonparametric procedures, and categorical data analysis. Reproducible research is required through the use of statistical computing software (e.g.¬†SPSS, Stata, SAS, R, Python). Recommended for all majors that use data for research.\n\n\n\nüìÖ ¬† Mon & Wed\nüïì ¬† 4:00 - 5:15 PM\nüèõ ¬† Holt 155\nüë•Ô∏è ¬† In Person\n\n\n\n\nBasic computer literacy. Recent statistics course such as Math 105, MATH 315, or MATH 350.\n\n\n\nMon 2-3pm, Thu 3:30-4:30 Holt 202, and Wed 1-3pm at Community Coding\n\n\n\n\nüêæ ¬† Dr.¬†Robin Donatello\nüö™ ¬† Holt 202\nüìß ¬† rdonatello@csuchico.edu\nüôã ¬† Schedule an appointment\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can toggle dark mode by clicking the  button in the top right navigation bar."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "Data Analysis for Graduate Research",
    "section": "",
    "text": "This course provides a hands-on introduction to using data to rigorously answer research questions. Students practice cleaning and manipulating data, creating data visualizations, and conducting introductory level statistical analysis using real-world data sets that are relevant to their field. Analysis topics include single and two-sample inference, analysis of variance, multiple regression, analysis of co-variance, experimental design, repeated measures, nonparametric procedures, and categorical data analysis. Reproducible research is required through the use of statistical computing software (e.g.¬†SPSS, Stata, SAS, R, Python). Recommended for all majors that use data for research.\n\n\n\nüìÖ ¬† Mon & Wed\nüïì ¬† 4:00 - 5:15 PM\nüèõ ¬† Holt 155\nüë•Ô∏è ¬† In Person\n\n\n\n\nBasic computer literacy. Recent statistics course such as Math 105, MATH 315, or MATH 350.\n\n\n\nMon 2-3pm, Thu 3:30-4:30 Holt 202, and Wed 1-3pm at Community Coding\n\n\n\n\nüêæ ¬† Dr.¬†Robin Donatello\nüö™ ¬† Holt 202\nüìß ¬† rdonatello@csuchico.edu\nüôã ¬† Schedule an appointment\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can toggle dark mode by clicking the  button in the top right navigation bar."
  },
  {
    "objectID": "journal/2025_Dailey_Pawar/Dailey_Pawar.html",
    "href": "journal/2025_Dailey_Pawar/Dailey_Pawar.html",
    "title": "Carbon respiration within the blue oak savanna ecosystem",
    "section": "",
    "text": "Abstract\nThis study investigates the relationship between the explanatory variables of soil water content (SWC) and Temperature with the response variable Ecosystem Respiration (RECO) within the blue oak savanna ecosystem of Tonzi Ranch, California, spanning 2000-2021. Data were sourced from an AmeriFlux tower, capturing a variety of weather variables. After aggregating the observations to monthly means, and shifting RECO back 2 months temporally, we found a linear relationship between RECO and soil water content with a bivariate model, and a statistically significant relationship between RECO and a combination of SWC and temperature.\nRead their paper here"
  },
  {
    "objectID": "journal.html",
    "href": "journal.html",
    "title": "Journal of Math 615",
    "section": "",
    "text": "The Journal of MATH 615 is the official internal publication of the Data Analysis for Graduate Research course at California State University at Chico. It serves as a platform for sharing high-quality student research in applied statistics and data analysis. A small selection of projects from the course are published each semester, showcasing the range of topics and analytical approaches explored by our students. Submitting to the journal gives students hands-on experience in preparing a manuscript, following professional publication guidelines, and clearly communicating statistical results. This process helps strengthen research writing skills and prepares students for future academic or professional work.\nSee the Guide for authors for details on how to submit to this journal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCarbon respiration within the blue oak savanna ecosystem\n\n\n\n\n\n\n\n\n\nDec 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Soil Health Indicators: Yearly Trends in PLFA Biomass and Bacteria-to-Fungi Ratios Across Depths Regenerative Farming Systems\n\n\n\n\n\n\n\n\n\nDec 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe relationship between tree-removal treatments and soil hydrophobicity in woodland encroached sagebrush ecosystems\n\n\n\n\n\n\n\n\n\nDec 18, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Course website for Math 615",
    "section": "",
    "text": "Course website for Math 615\nData Analysis for Graduate Research California State University, Chico Fall 2023"
  },
  {
    "objectID": "slides/lec00b-course-tools.html#class-website",
    "href": "slides/lec00b-course-tools.html#class-website",
    "title": "MATH 615 Course Tools",
    "section": "Class website",
    "text": "Class website\n\nhttps://math615.netlify.app/\n\nBookmark this page. You will be here a lot.\nContains details on weekly topics, links to notes, assignments and additional materials\nSometimes links will be broken. Typo‚Äôs happen. Notify me via Discord and I‚Äôll get to it asap.\n\n\nClass Website - Topic view\n\nOne page per Topic\nThese correspond to Modules in Canvas\nTies together what we have learned, with what we are going to learn\nStates the learning objectives for that topic\nLinks to all learning and assessment materials for this topic\nMAIN PLACE FOR LINKS I don‚Äôt like to put links in multiple places because if I make an update then I have to remember to update all places, and that is error prone.\n\n\n\nClass Website - Other tabs\n\nAll slides, all homework\nProject overview & information\nSyllabus, help\nReference materials\n\n\n\nPractical Multivariate Analysis - 6th Edition\n\nThe textbook is used for reading and learning content at a more in depth level than my overview slides.\nThis will be used in Math 456, and is an excellent reference guide for further learning.\nIf you‚Äôre curious, Afifi is a mentor of mine and invited me to participate. I used the 4th edition in grad school and really like teaching out of it. Royalties are about $100/year and is not why I require this text.\n\n\n\nCanvas\n\nAssignment submission\nGrades\nSchedule, calendar, Due dates\nRecorded lectures\n\n\n\nGoogle Drive\n\nCollaborative note taking\nQuizzes (Individual, and Group)\nOngoing research project work\n\n\n\nDiscord\n\nUsed for outside class discussions, meme sharing, homework help and general chatter.\nYour first place to ask code and homework based questions\nI will not answer most class-content based questions through email.\nDownload either the phone app or the desktop app (I use both). This is mandatory.\n\nDo not rely on remembering to log in via the web browser. You will miss important notifications.\n\n\n\n\nLecture notes (slides)\n\nStand alone lecture notes like these.\nClick on three lines in the bottom left to see options for exporting a copy in other formats.\n\n\n\nVideo\n\nPosted in Canvas\nOccasional pre-class learning content\nI will also record most class sessions\n\n\n\nStatistcal Analysis Software\n\n\n\n\n\n\n\n\nThe programming language R (syntax)\nCommunity written packages containing functions to do cool things\nNot used by itself in this class\n\n\n\n\n\n\n\n\nRStudio is the supportive working environment\nIntegrates with other tools such as Quarto, HTML and Python\nR is accessed from within R Studio\n\n\nYou will download and install both as part of homework 0.\n\n\nClosing Thoughts\n\nIt may seem like a lot in the first week or two\nYou will get used to it if you embrace it and view it as a learning opportunity\nIf you fight it because it‚Äôs not what you‚Äôre used to, or are upset because there are ‚Äútoo many places to look‚Äù, you are not in for a fun semester.\nI am open to constructive feedback about course material."
  },
  {
    "objectID": "slides/lec00b-course-tools.html#class-website---topic-view",
    "href": "slides/lec00b-course-tools.html#class-website---topic-view",
    "title": "MATH 615 Course Tools",
    "section": "Class Website - Topic view",
    "text": "Class Website - Topic view\n\nOne page per Topic\nThese correspond to Modules in Canvas\nTies together what we have learned, with what we are going to learn\nStates the learning objectives for that topic\nLinks to all learning and assessment materials for this topic\nMAIN PLACE FOR LINKS I don‚Äôt like to put links in multiple places because if I make an update then I have to remember to update all places, and that is error prone."
  },
  {
    "objectID": "slides/lec00b-course-tools.html#class-website---other-tabs",
    "href": "slides/lec00b-course-tools.html#class-website---other-tabs",
    "title": "MATH 615 Course Tools",
    "section": "Class Website - Other tabs",
    "text": "Class Website - Other tabs\n\nAll slides, all homework\nProject overview & information\nSyllabus, help\nReference materials"
  },
  {
    "objectID": "slides/lec00b-course-tools.html#practical-multivariate-analysis---6th-edition",
    "href": "slides/lec00b-course-tools.html#practical-multivariate-analysis---6th-edition",
    "title": "MATH 615 Course Tools",
    "section": "Practical Multivariate Analysis - 6th Edition",
    "text": "Practical Multivariate Analysis - 6th Edition\n\nThe textbook is used for reading and learning content at a more in depth level than my overview slides.\nThis will be used in Math 456, and is an excellent reference guide for further learning.\nIf you‚Äôre curious, Afifi is a mentor of mine and invited me to participate. I used the 4th edition in grad school and really like teaching out of it. Royalties are about $100/year and is not why I require this text."
  },
  {
    "objectID": "slides/lec00b-course-tools.html#canvas",
    "href": "slides/lec00b-course-tools.html#canvas",
    "title": "MATH 615 Course Tools",
    "section": "Canvas",
    "text": "Canvas\n\nAssignment submission\nGrades\nSchedule, calendar, Due dates\nRecorded lectures"
  },
  {
    "objectID": "slides/lec00b-course-tools.html#google-drive",
    "href": "slides/lec00b-course-tools.html#google-drive",
    "title": "MATH 615 Course Tools",
    "section": "Google Drive",
    "text": "Google Drive\n\nCollaborative note taking\nQuizzes (Individual, and Group)\nOngoing research project work"
  },
  {
    "objectID": "slides/lec00b-course-tools.html#discord",
    "href": "slides/lec00b-course-tools.html#discord",
    "title": "MATH 615 Course Tools",
    "section": "Discord",
    "text": "Discord\n\nUsed for outside class discussions, meme sharing, homework help and general chatter.\nYour first place to ask code and homework based questions\nI will not answer most class-content based questions through email.\nDownload either the phone app or the desktop app (I use both). This is mandatory.\n\nDo not rely on remembering to log in via the web browser. You will miss important notifications."
  },
  {
    "objectID": "slides/lec00b-course-tools.html#lecture-notes-slides",
    "href": "slides/lec00b-course-tools.html#lecture-notes-slides",
    "title": "MATH 615 Course Tools",
    "section": "Lecture notes (slides)",
    "text": "Lecture notes (slides)\n\nStand alone lecture notes like these.\nClick on three lines in the bottom left to see options for exporting a copy in other formats."
  },
  {
    "objectID": "slides/lec00b-course-tools.html#video",
    "href": "slides/lec00b-course-tools.html#video",
    "title": "MATH 615 Course Tools",
    "section": "Video",
    "text": "Video\n\nPosted in Canvas\nOccasional pre-class learning content\nI will also record most class sessions"
  },
  {
    "objectID": "slides/lec00b-course-tools.html#statistcal-analysis-software",
    "href": "slides/lec00b-course-tools.html#statistcal-analysis-software",
    "title": "MATH 615 Course Tools",
    "section": "Statistcal Analysis Software",
    "text": "Statistcal Analysis Software\n\n\n\n\n\n\n\n\nThe programming language R (syntax)\nCommunity written packages containing functions to do cool things\nNot used by itself in this class\n\n\n\n\n\n\n\n\nRStudio is the supportive working environment\nIntegrates with other tools such as Quarto, HTML and Python\nR is accessed from within R Studio\n\n\nYou will download and install both as part of homework 0."
  },
  {
    "objectID": "slides/lec00b-course-tools.html#closing-thoughts",
    "href": "slides/lec00b-course-tools.html#closing-thoughts",
    "title": "MATH 615 Course Tools",
    "section": "Closing Thoughts",
    "text": "Closing Thoughts\n\nIt may seem like a lot in the first week or two\nYou will get used to it if you embrace it and view it as a learning opportunity\nIf you fight it because it‚Äôs not what you‚Äôre used to, or are upset because there are ‚Äútoo many places to look‚Äù, you are not in for a fun semester.\nI am open to constructive feedback about course material."
  },
  {
    "objectID": "slides/lec02-asking_q.html#a-research-hypothesis-poses-a-question-about-the-relationship-between-two-or-more-measurable-characteristics.",
    "href": "slides/lec02-asking_q.html#a-research-hypothesis-poses-a-question-about-the-relationship-between-two-or-more-measurable-characteristics.",
    "title": "Formulating research questions",
    "section": "A Research Hypothesis poses a question about the relationship between two or more measurable characteristics.",
    "text": "A Research Hypothesis poses a question about the relationship between two or more measurable characteristics.\n\n\n\nExample\n\n\nIs there a relationship between smoking frequency and suicide?"
  },
  {
    "objectID": "slides/lec02-asking_q.html#simple-vs-complex",
    "href": "slides/lec02-asking_q.html#simple-vs-complex",
    "title": "Formulating research questions",
    "section": "Simple vs Complex",
    "text": "Simple vs Complex\n\n\n\n\n\n\nSimple Hypothesis\n\n\nIs there a relationship between smoking frequency and suicide?\n\n\n\n\n\n\nSimple relationship between two measures\nCan be answered with a ‚Äòyes‚Äô or ‚Äòno‚Äô\n\n\n\n\n\n\n\n\nComplex Hypothesis\n\n\nDoes smoking frequency exacerbate poor mental health outcomes such as anxiety, depression and suicide?\n\n\n\n\n\n\nStated as a relationship between multiple variables\nCan‚Äôt be answered directly but through multiple sub-questions"
  },
  {
    "objectID": "slides/lec02-asking_q.html#null-vs-alternative",
    "href": "slides/lec02-asking_q.html#null-vs-alternative",
    "title": "Formulating research questions",
    "section": "Null vs Alternative",
    "text": "Null vs Alternative\nAKA Statistical Hypothesis\n\n\n\n\n\n\nNull Hypothesis\n\n\nDrug X has no affect on outcome Y\n\n\n\n\n\n\nStated as no relationship\nthe ‚Äòstatus quo‚Äô or current status\n\n\n\n\n\n\n\n\nAlternative Hypothesis\n\n\nDrug X is associated with a change in outcome Y\n\n\n\n\n\n\nstated as a relationship exists\ntypically what you hope to show"
  },
  {
    "objectID": "slides/lec02-asking_q.html#collaborative-discussion",
    "href": "slides/lec02-asking_q.html#collaborative-discussion",
    "title": "Formulating research questions",
    "section": "Collaborative discussion",
    "text": "Collaborative discussion\n\n\n\nDiscuss\n\n\nDiscuss each question below with your table and share out as instructed\n\nWhat are the characteristics of a good research question?\n\nWhat is the one essential document you need to review before you can formulate a research question?\nWrite an example of a research question"
  },
  {
    "objectID": "slides/lec02-asking_q.html#where-to-find-prior-information-on-your-research-topic",
    "href": "slides/lec02-asking_q.html#where-to-find-prior-information-on-your-research-topic",
    "title": "Formulating research questions",
    "section": "Where to find prior information on your research topic?",
    "text": "Where to find prior information on your research topic?\n\nGoogle ofc.\nLibrary for primary and secondary sources\n\n\n\n\nPrimary vs secondary sources\n\n\nDiscuss with your table and share out your responses as instructed.\n\nGive an example of a primary source of information.\nGive an example of a secondary source of information.\nWhat are some problems with secondary source literature?"
  },
  {
    "objectID": "slides/lec03b-data_prep.html#requirements",
    "href": "slides/lec03b-data_prep.html#requirements",
    "title": "Preparing your data for analysis",
    "section": "Requirements",
    "text": "Requirements\nThese notes assume the following‚Ä¶\n\nyou have R and R Studio installed\nat least the tidyverse and here packages installed\nConverted your Math 615 folder to an R project\nhave successfully rendered a quarto document to PDF.\n\nSee ASCN Ch 19.1-19.8 for details if you still need help."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#import",
    "href": "slides/lec03b-data_prep.html#import",
    "title": "Preparing your data for analysis",
    "section": "Import",
    "text": "Import\n\nOpen your MATH 615 R Project\nGo to Homework 03 and complete step 1 ONLY.\nConfirm your data is in your data folder.\nModify the import code on line 13 to correctly import your data set. If you are using one of my data sets, there should be a file in the folder that gives you the correct import code.\n\nRun this code chunk only (not render)\n\n\n\nShow the code\nlibrary(tidyverse)\nraw &lt;- palmerpenguins::penguins_raw # for demo only"
  },
  {
    "objectID": "slides/lec03b-data_prep.html#confirm-import-was-successful",
    "href": "slides/lec03b-data_prep.html#confirm-import-was-successful",
    "title": "Preparing your data for analysis",
    "section": "Confirm import was successful",
    "text": "Confirm import was successful\nOkay, did it work?\n\nLook in the top right Environment pane. Do you see a dataset named raw? Does it have an expected number of rows and columns?\nClick on the table icon to open the data set in a spreadsheet like view. Are the variable names correct? Does the data look correct?"
  },
  {
    "objectID": "slides/lec03b-data_prep.html#restrict-to-analysis-variables",
    "href": "slides/lec03b-data_prep.html#restrict-to-analysis-variables",
    "title": "Preparing your data for analysis",
    "section": "Restrict to analysis variables",
    "text": "Restrict to analysis variables\n\nReduce cogitative load by making a ‚Äúworking‚Äù data set that only contains variables that you immediately care about.\n\n\n\nShow the code\nmydata &lt;- raw %&gt;% select(Species, Island, `Body Mass (g)`)"
  },
  {
    "objectID": "slides/lec03b-data_prep.html#initial-data-screening",
    "href": "slides/lec03b-data_prep.html#initial-data-screening",
    "title": "Preparing your data for analysis",
    "section": "Initial Data Screening",
    "text": "Initial Data Screening\nUse functions like str() or glimpse() to see what data type R thinks your variables are for the whole data set\n\nglimpsestr\n\n\n\n\nShow the code\nglimpse(mydata)    # from the tidyverse/dplyr dataset\n\n\nRows: 344\nColumns: 3\n$ Species         &lt;chr&gt; \"Adelie Penguin (Pygoscelis adeliae)\", \"Adelie Penguin (Pygoscelis adeliae)\", \"Adelie Penguin (Pygoscelis adeliae)\", \"Adelie Penguin (Pygoscelis adeliae)\", \"Adelie Penguin (P‚Ä¶\n$ Island          &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torg‚Ä¶\n$ `Body Mass (g)` &lt;dbl&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, 3300, 3700, 3200, 3800, 4400, 3700, 3450, 4500, 3325, 4200, 3400, 3600, 3800, 3950, 3800, 3800, 3550, 3200, 3150, 39‚Ä¶\n\n\n\n\n\n\nShow the code\nstr(mydata)    \n\n\ntibble [344 √ó 3] (S3: tbl_df/tbl/data.frame)\n $ Species      : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ Island       : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ Body Mass (g): num [1:344] 3750 3800 3250 NA 3450 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n\n\n\n\n\nBoth views show you the variable names, data types, and what the data in the first few rows looks like."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#initial-data-screening---single-variable",
    "href": "slides/lec03b-data_prep.html#initial-data-screening---single-variable",
    "title": "Preparing your data for analysis",
    "section": "Initial Data Screening - single variable",
    "text": "Initial Data Screening - single variable\nYou can also look at the data type for a single variable at a time.\n\ntypeofclassstr\n\n\n\n\nShow the code\ntypeof(mydata$Island) \n\n\n[1] \"character\"\n\n\n\n\n\n\nShow the code\nclass(mydata$Island) \n\n\n[1] \"character\"\n\n\n\n\n\n\nShow the code\nstr(mydata$Island) \n\n\n chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ..."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#check-plausibility-of-data-values",
    "href": "slides/lec03b-data_prep.html#check-plausibility-of-data-values",
    "title": "Preparing your data for analysis",
    "section": "Check plausibility of data values",
    "text": "Check plausibility of data values\nConfirm these values follow the expected values according to the codebook.\n\nCategoricalNumeric\n\n\nUse table() for categorical variables to see the frequency of unique levels of that variable. Note any levels with less than 10 observations or variables with more than 10 levels.\n\n\nShow the code\ntable(mydata$Island)\n\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\n\n\nYou can use summary() on numeric variables to see the range of values present. Note the amount of missing values, the spread of the data, and any out of range values (e.g.¬†99 or 7 on a binary yes/no that should only be 0/1).\n\n\nShow the code\nsummary(mydata$`Body Mass (g)`)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2"
  },
  {
    "objectID": "slides/lec03b-data_prep.html#data-prep-questions",
    "href": "slides/lec03b-data_prep.html#data-prep-questions",
    "title": "Preparing your data for analysis",
    "section": "Data Prep questions",
    "text": "Data Prep questions\nQuestions to ask yourself (and the data) while reviewing the codebook to choose variables to be used in an analysis.\n\nAre there codes that indicate missing? E.g. MISSING or -99?\nDo you need to make response codes more logical?\n\nSome systems will record 1=YES and 2=NO. This should be changed to 0=NO.\n\nDo you need to recode numerical variables to categorical?\n\nSometimes categorical data will be recorded as 1, 2, 3 etc when those numbers represent named categories.\n\nDo you need to create secondary variables such as an average across measures to create a score.\nAre the variable names user friendly? Mixtures of CAPS and lower case, names with spaces or special characters should all be changed. Use the janitor::clean_names() function to resolve this."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#how-do-i-know-what-needs-to-be-done",
    "href": "slides/lec03b-data_prep.html#how-do-i-know-what-needs-to-be-done",
    "title": "Preparing your data for analysis",
    "section": "How do I know what needs to be done?",
    "text": "How do I know what needs to be done?\nSome of these answers will come only after you look at your data. This can be looking at the raw data itself but also looking at tables and charts generated from the data.\nOften when you try to create a plot or table you will encounter an error or something odd looking that will be the notification that something has to be adjusted."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#how-do-i-actually-make-the-necessary-changes",
    "href": "slides/lec03b-data_prep.html#how-do-i-actually-make-the-necessary-changes",
    "title": "Preparing your data for analysis",
    "section": "How do I actually make the necessary changes?",
    "text": "How do I actually make the necessary changes?\n\nAfter you identify what you need to do, you have to find an example of how to code the task you want.\nThe Applied Stats Course notes has specific examples on how to handle common changes\nTake it one variable at a time."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#looking-for-help",
    "href": "slides/lec03b-data_prep.html#looking-for-help",
    "title": "Preparing your data for analysis",
    "section": "Looking for help",
    "text": "Looking for help\n\nThe internets can be a wonderful thing when it comes to learning new things.\nThe R landscape moves fast. Restrict your search to the past ~4 years.\nUse keywords like R project or searching for package vignettes\nStack Overflow and the Posit Community can have gems!\n\nYou will start to build up your repertoire of bookmarked sites you like to use."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#using-chat-gpt-to-write-code",
    "href": "slides/lec03b-data_prep.html#using-chat-gpt-to-write-code",
    "title": "Preparing your data for analysis",
    "section": "Using Chat GPT to write code",
    "text": "Using Chat GPT to write code\n\n\n\n\n\n\nExample prompt\n\n\nUsing the palmer penguins dataset in R write me R code to change the factor order of the islands variable to put Dream first\n\n\n\n\nI told it to use a built in data set\nI told it to use R\nI used R terminology such as ‚Äúfactor order‚Äù and ‚Äúvariable‚Äù\n\nWhat did it give?"
  },
  {
    "objectID": "slides/lec03b-data_prep.html#chatgpt",
    "href": "slides/lec03b-data_prep.html#chatgpt",
    "title": "Preparing your data for analysis",
    "section": "",
    "text": "Sure, here‚Äôs an example of how you can change the factor order of the island variable in the Palmer Penguins dataset to put ‚ÄúDream‚Äù first using R:\n# Load necessary packages\nlibrary(palmerpenguins)\n\n# Load the dataset\ndata(\"penguins\")\n\n# Check the current levels of the 'island' factor\nlevels(penguins$island)\n\n# Reorder the levels of the 'island' factor to put \"Dream\" first\npenguins$island &lt;- factor(penguins$island, levels = c(\"Dream\", \"Torgersen\", \"Biscoe\"))\n\n# Check the new order of levels\nlevels(penguins$island)\nIn this code, we‚Äôre first loading the palmerpenguins package, which provides access to the dataset. Then we load the dataset itself using data(\"penguins\"). We check the current levels of the island factor using levels(penguins$island).\nNext, we use the factor() function to reorder the levels of the island variable. We specify the desired order of levels using the levels argument. In this case, we put ‚ÄúDream‚Äù first, followed by the other islands. Finally, we check the new order of levels to make sure the change was successful."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#use-it-as-a-learning-tool",
    "href": "slides/lec03b-data_prep.html#use-it-as-a-learning-tool",
    "title": "Preparing your data for analysis",
    "section": "Use it as a learning tool",
    "text": "Use it as a learning tool\nNot only did it write the code, it wrote literate code. It has code comments (lines 1, 4, 7, prefixed with a #), and a full text explanation.\nThis is GREAT for learning how to write code!\n\n\n\n\n\n\nPlagerism warning\n\n\nRead the Syllabus on what is expected of you if you use this tool to aid in your writing https://math615.netlify.app/syllabus#use-of-ai\n\n\n\n‚ö†Ô∏è Trust but verify! AI is not always correct! Also, this does not replace the necessity of you learning."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#save-an-analysis-ready-data-set",
    "href": "slides/lec03b-data_prep.html#save-an-analysis-ready-data-set",
    "title": "Preparing your data for analysis",
    "section": "Save an analysis-ready data set",
    "text": "Save an analysis-ready data set\n\nThe very last thing you should do in your data management script is save an analysis ready or ‚Äúclean‚Äù data file.\nAdvised to save it as a .Rdata file to maintain your factor orderings\nYou may want to do one more round of using select() to drop variables that you don‚Äôt want anymore\nDo this at the bottom of your homework dm script file now.\nEvery time you render this dm file, it will overwrite the cleaned data with the same name - thus ensuring that your analysis data set is always programmatically connected to your raw data set, and all choices documented."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#collaborating-with-others",
    "href": "slides/lec03b-data_prep.html#collaborating-with-others",
    "title": "Preparing your data for analysis",
    "section": "Collaborating with others",
    "text": "Collaborating with others\n\nIt‚Äôs critically important that both of you are using the same slice/filter section of data\n\nAnd if one person made a new variable, the other person should have that code also.\n\nIf you and your partner know git ‚Äì use it.\nOther methods are to store all files (and R project) in a shared Box/Dropbox/Google Drive type folder."
  },
  {
    "objectID": "slides/lec03b-data_prep.html#closing-thoughts",
    "href": "slides/lec03b-data_prep.html#closing-thoughts",
    "title": "Preparing your data for analysis",
    "section": "Closing thoughts",
    "text": "Closing thoughts\n\nDo not underestimate the importance of this step\nIt will take you far, far longer than you anticipate to ‚Äòclean‚Äô your data\nEffort spent here is a direct correlation with payoff.\nWriting code (in any language) will be challenging, but will pay off in the long run\nDon‚Äôt reinvent the wheel. If you want to do something, chances are someone else has done it before. Perhaps even yourself!\nProgramming in R is not like programming in Python or any flavor of C. Things that are efficient or necessary in those languages (e.g.¬†loops) make your R code unreadable and clunky."
  },
  {
    "objectID": "slides/lec05a-describing_relationships.html#naming-conventions",
    "href": "slides/lec05a-describing_relationships.html#naming-conventions",
    "title": "Describing Relationships between variables",
    "section": "Naming conventions",
    "text": "Naming conventions\n\n\n\nResponse\nExplanatory\n\n\n\n\ny\nx\n\n\noutcome\npredictor\n\n\ndependent variable\nindependent variable\n\n\n\ncovariate\n\n\n\nfeature\n\n\n\n\n\nModel notation: \\(y \\sim x\\)"
  },
  {
    "objectID": "slides/lec05a-describing_relationships.html#types-of-combinations",
    "href": "slides/lec05a-describing_relationships.html#types-of-combinations",
    "title": "Describing Relationships between variables",
    "section": "Types of combinations",
    "text": "Types of combinations\n\nCategorical response and categorical explanatory variable. (C ~ C)\nQuantitative response and categorical explanatory variable. (Q ~ C)\nQuantitative response and quantitative explanatory variable. (Q ~ Q)\n\nThe \\(Q\\) and \\(C\\) notation is internal to this class. Not universal."
  },
  {
    "objectID": "slides/lec05a-describing_relationships.html#q-c",
    "href": "slides/lec05a-describing_relationships.html#q-c",
    "title": "Describing Relationships between variables",
    "section": "Q ~ C",
    "text": "Q ~ C\nQuantitative Response vs Categorical Explanatory\n\nGrouped summary statisticsgtsummaryPlotsPlot2Description\n\n\nn, nean, median, sd, IQR of the quantitative variable for each level of the categorical level.\n\n\nShow the code\npen %&gt;% group_by(species) %&gt;% \n  summarize(n=n(), \n            mean   = mean(bill_depth_mm, na.rm = TRUE), \n            median = median(bill_depth_mm, na.rm = TRUE), \n            sd     = sd(bill_depth_mm, na.rm = TRUE), \n            IQR    = IQR(bill_depth_mm, na.rm = TRUE))\n\n\n# A tibble: 3 √ó 6\n  species       n  mean median    sd   IQR\n  &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie      152  18.3   18.4 1.22   1.5 \n2 Chinstrap    68  18.4   18.4 1.14   1.90\n3 Gentoo      124  15.0   15   0.981  1.5 \n\n\nGentoo penguins have lower average bill depth compared to Adelie or Chinstrap (15.0mm vs 18.3 and 18.4mm respectively). Chinstrap however have a larger IQR at 1.9 compared to 1.5 for the others.\n\n\n\n\nSimilarly nice tables, but defaults to median and IQR.\n\n\nShow the code\npen %&gt;% select(bill_depth_mm, species) %&gt;%\n  tbl_summary(by = \"species\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAdelie\nN = 1521\nChinstrap\nN = 681\nGentoo\nN = 1241\n\n\n\n\nbill_depth_mm\n18.40 (17.50, 19.00)\n18.45 (17.50, 19.40)\n15.00 (14.20, 15.70)\n\n\n¬†¬†¬†¬†Unknown\n1\n0\n1\n\n\n\n1 Median (Q1, Q3)\n\n\n\n\n\n\n\n\n\nHave to manually specify you want mean & sd.\n\n\nShow the code\npen %&gt;% select(bill_depth_mm, species) %&gt;%\n  tbl_summary(by = \"species\", \n              statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAdelie\nN = 1521\nChinstrap\nN = 681\nGentoo\nN = 1241\n\n\n\n\nbill_depth_mm\n18.35 (1.22)\n18.42 (1.14)\n14.98 (0.98)\n\n\n¬†¬†¬†¬†Unknown\n1\n0\n1\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverlaid density plots\n\n\nShow the code\ngghistogram(pen, \n    x = \"bill_depth_mm\", fill = \"species\", \n    add_density = TRUE, add=\"mean\")\n\n\n\n\n\n\n\n\n\n\nSide by side boxplots\n\n\nShow the code\nggviolin(pen, \n  x=\"species\", y = \"bill_depth_mm\", \n  color = \"species\", add = c(\"mean\", \"boxplot\"))\n\n\n\n\n\n\n\n\n\n\n The distribution of bill depth are fairly normal for each species, with some higher end values causing a slight right skew for Adelie and Gentoo.\n\n\nMore code but nice alternative to violins.\n\n\nShow the code\nlibrary(ggdist) # for the \"half-violin\" plot (stat_slab)\nggplot(pen, aes(x=bill_depth_mm, y=species, fill=species)) + \n      stat_slab(alpha=.5, justification = 0) + \n      geom_boxplot(width = .2,  outlier.shape = NA) + \n      geom_jitter(alpha = 0.5, height = 0.05) +\n      stat_summary(fun=\"mean\", geom=\"point\", col=\"red\", size=4, pch=17) + \n      theme_bw() + \n      labs(x=\"Bill depth (mm)\", y = \"Species\") + \n      theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nDiscuss shape, spread and center using comparative language.\n\n\nThe distribution of bill depth are fairly normal for each species, with some higher end values causing a slight right skew for Adelie and Gentoo. Gentoo penguins have lower average bill depth compared to Adelie or Chinstrap (15.0mm vs 18.3 and 18.4mm respectively). Chinstrap however have a larger IQR at 1.9 compared to 1.5 for the others."
  },
  {
    "objectID": "slides/lec05a-describing_relationships.html#q-q",
    "href": "slides/lec05a-describing_relationships.html#q-q",
    "title": "Describing Relationships between variables",
    "section": "Q ~ Q",
    "text": "Q ~ Q\nQuantitative Response vs Quantitative Explanatory\n\nSummary statisticPlotsDescription\n\n\n\n\nShow the code\ncor(pen$flipper_length_mm, pen$body_mass_g, \n    use=\"pairwise.complete.obs\")\n\n\n[1] 0.8712018\n\n\nThe correlation coefficient \\(r\\) is a measure of the strength and direction of a linear relationship between two variables.\n\n\\(|r| &gt; 0.6\\) Strong relationship\n\\(0.4 \\leq |r| &lt; 0.6\\) Moderate relationship\n\\(|r| &lt; 0.4\\) Weak to no relationship\n\nNote: These values are guidelines and subject to variability within different disciplines ref\n\n\n\n\n\n\nShow the code\nggscatter(pen, \n  x=\"flipper_length_mm\", y = \"body_mass_g\")\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggscatter(pen, \n  x=\"flipper_length_mm\", y = \"body_mass_g\", \n  add = \"loess\", conf.int = TRUE)\n\n\n\n\n\n\n\n\n\n The relationship between flipper length and body mass in penguins is relatively linear, but there may be possible clustering on a third variable. There appears to be two groups below and above a flipper length of about 205mm. \n\n\n\nMust include the direction (positive or negative), the strength quantified using \\(r\\), and the form (linear vs non-linear)\nThe penguin flipper length (mm) has a strong, positive, and reasonably linear correlation with body mass (g), r=0.87."
  },
  {
    "objectID": "slides/lec05a-describing_relationships.html#c-c",
    "href": "slides/lec05a-describing_relationships.html#c-c",
    "title": "Describing Relationships between variables",
    "section": "C ~ C",
    "text": "C ~ C\nCategorical Response vs Categorical Explanatory\n\nTwo way tables (cross-tabs)Plots\n\n\n\n\n\n\nShow the code\ntable(pen$species, pen$island)\n\n\n           \n            Biscoe Dream Torgersen\n  Adelie        44    56        52\n  Chinstrap      0    68         0\n  Gentoo       124     0         0\n\n\n\n\n\nShow the code\ntable(pen$species, pen$island) |&gt; \n  prop.table(margin=2) |&gt; round(2)\n\n\n           \n            Biscoe Dream Torgersen\n  Adelie      0.26  0.45      1.00\n  Chinstrap   0.00  0.55      0.00\n  Gentoo      0.74  0.00      0.00\n\n\n\n\nAll of the 52 penguins on Torgersen island are the Adelie species.\n74% of penguins on Biscoe island are Gentoo.\n\n\n\n\n\nShow the code\nplot_xtab(pen$island, grp=pen$species, show.total = FALSE)\n\n\n\n\n\n\n\n\n\n\nDo these percents match the table?"
  },
  {
    "objectID": "slides/lec05a-describing_relationships.html#watch-your-margins",
    "href": "slides/lec05a-describing_relationships.html#watch-your-margins",
    "title": "Describing Relationships between variables",
    "section": "Watch your margins",
    "text": "Watch your margins\n\n\n\n\n\n\nAlways double check your work\n\n\nOne of the most common places for a mistake when creating a plot or a table between two categorical variables is by not paying close attention to the choice of denominator. And then also confirming the interpretation matches the table, which matches the plot.\n\n\n\n\nWhat % of penguins on each island are Gentoo?\nWhat % of Gentoo penguins are on each Island?"
  },
  {
    "objectID": "slides/lec05a-describing_relationships.html#watch-your-margins-1",
    "href": "slides/lec05a-describing_relationships.html#watch-your-margins-1",
    "title": "Describing Relationships between variables",
    "section": "Watch your margins",
    "text": "Watch your margins\n\nTablesgtsummaryPlots\n\n\n\n\nRow Percents\n\n\nShow the code\ntable(pen$species, pen$island) |&gt; \n  prop.table(margin=1) |&gt; round(2)\n\n\n           \n            Biscoe Dream Torgersen\n  Adelie      0.29  0.37      0.34\n  Chinstrap   0.00  1.00      0.00\n  Gentoo      1.00  0.00      0.00\n\n\n29% of Adelie penguins are on Biscoe Island.\n\nColumn Percents\n\n\nShow the code\ntable(pen$species, pen$island) |&gt; \n  prop.table(margin=2) |&gt; round(2)\n\n\n           \n            Biscoe Dream Torgersen\n  Adelie      0.26  0.45      1.00\n  Chinstrap   0.00  0.55      0.00\n  Gentoo      0.74  0.00      0.00\n\n\n74% of penguins on Biscoe island are Gentoo.\n\n\n\n\n\nDistribution of Islands within each species\n\n\nShow the code\npen %&gt;% select(island, species) %&gt;%\n  tbl_summary(by = \"species\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAdelie\nN = 1521\nChinstrap\nN = 681\nGentoo\nN = 1241\n\n\n\n\nisland\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Biscoe\n44 (29%)\n0 (0%)\n124 (100%)\n\n\n¬†¬†¬†¬†Dream\n56 (37%)\n68 (100%)\n0 (0%)\n\n\n¬†¬†¬†¬†Torgersen\n52 (34%)\n0 (0%)\n0 (0%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\nDistribution of Species on each Island\n\n\nShow the code\npen %&gt;% select(island, species) %&gt;%\n  tbl_summary(by = \"island\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBiscoe\nN = 1681\nDream\nN = 1241\nTorgersen\nN = 521\n\n\n\n\nspecies\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Adelie\n44 (26%)\n56 (45%)\n52 (100%)\n\n\n¬†¬†¬†¬†Chinstrap\n0 (0%)\n68 (55%)\n0 (0%)\n\n\n¬†¬†¬†¬†Gentoo\n124 (74%)\n0 (0%)\n0 (0%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution of islands for each species\n\n\nShow the code\nplot_xtab(pen$species, grp=pen$island, \n          margin = \"row\", show.total = FALSE)\n\n\n\n\n\n\n\n\n\n29% of Adelie penguins are on Biscoe Island.\n\nDistribution of species on each island.\n\n\nShow the code\nplot_xtab(pen$island, grp=pen$species, \n          margin = \"row\", show.total = FALSE)\n\n\n\n\n\n\n\n\n\n74% of penguins on Biscoe island are Gentoo."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#statistical-inference-1",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#statistical-inference-1",
    "title": "Statistical Inference with Randomization",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\nPrimarily concerned with understanding and quantifying the uncertainty of parameter estimates.\nEquations and details change depending on the setting, the foundations for inference are the same throughout all of statistics.\nWe start with a case studies designed to motivate the process of making decisions about research claims.\nWe formalize the process through the introduction of the hypothesis testing framework, which allows us to formally evaluate claims about the population."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#variability-in-data",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#variability-in-data",
    "title": "Statistical Inference with Randomization",
    "section": "Variability in data",
    "text": "Variability in data\n\nSometimes the dataset at hand represents the entire research question.\nMore often than not, the data have been collected to answer a research question about a larger group of which the data are a (hopefully) representative subset.\nOne dataset will not be identical to a second dataset even if they are both collected from the same population using the same methods."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#motivating-example-case-study-in-sex-discrimination",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#motivating-example-case-study-in-sex-discrimination",
    "title": "Statistical Inference with Randomization",
    "section": "Motivating Example: Case study in sex discrimination",
    "text": "Motivating Example: Case study in sex discrimination\nWe consider a study investigating sex discrimination in the 1970s, which is set in the context of personnel decisions within a bank. The research question we hope to answer is, ‚ÄúAre individuals who identify as female discriminated against in promotion decisions made by their managers who identify as male?‚Äù (Rosen and Jerdee 1974 Note: The study allowed only for a binary classification of sex. The identities being considered are not gender identities."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#methods",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#methods",
    "title": "Statistical Inference with Randomization",
    "section": "Methods",
    "text": "Methods\n48 male-identifying bank supervisors were asked to assume the role of the personnel director and were given personnel files to judge whether the person should be promoted. The files were identical except half indicated that the candidate identified as male, the other half the candidate identified as female. The files were randomly assigned to the participants, 13 individuals were promoted and the results were recorded."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#setup",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#setup",
    "title": "Statistical Inference with Randomization",
    "section": "Setup",
    "text": "Setup\n‚ùì Is this an observational study or an experiment? Why?\n‚ùìHow does the type of study impact what can be inferred from the results?\n‚ùì What is the hypothesis being tested? (in words with no statistical jargon)."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#observed-results",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#observed-results",
    "title": "Statistical Inference with Randomization",
    "section": "Observed Results",
    "text": "Observed Results\nThe results from the study are displayed in the following contingency table. Use it to fill in the blanks below.\n\n\nShow the code\nlibrary(openintro) # to get the sex_discrimination data\ntable(sex_discrimination$sex, sex_discrimination$decision) |&gt; addmargins()\n\n\n        \n         promoted not promoted Sum\n  male         21            3  24\n  female       14           10  24\n  Sum          35           13  48\n\n\nIn this study, a (bigger/smaller) proportion of female identifying applications were promoted than males (______________ versus ______________).\nCalculate the difference (male - female) between these proportions."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#point-estimate",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#point-estimate",
    "title": "Statistical Inference with Randomization",
    "section": "Point Estimate",
    "text": "Point Estimate\nThis observed difference is what we call a point estimate of the true difference in promotional rates between males and females. This difference suggest there might be discrimination against women in promotion decisions, is unclear whether there is convincing evidence that the observed difference represents discrimination or is just due to random chance when there is no discrimination occurring."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#competing-hypothesis",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#competing-hypothesis",
    "title": "Statistical Inference with Randomization",
    "section": "Competing Hypothesis",
    "text": "Competing Hypothesis\nChance can be thought of as the claim due to natural variability; discrimination can be thought of as the claim the researchers set out to demonstrate. We label these two competing claims in the following way:\n\\(H_{0}\\): Null Hypothesis:\n\n\\(H_{A}\\): Alternative Hypothesis:\n\nOften times, the null hypothesis takes a stance of no difference or no effect. This hypothesis assumes that any differences seen are due to the variability inherent in the population and could have occurred by random chance."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#data-or-it-didnt-happen",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#data-or-it-didnt-happen",
    "title": "Statistical Inference with Randomization",
    "section": "Data or it didn‚Äôt happen",
    "text": "Data or it didn‚Äôt happen\nWe will choose between the two competing claims by assessing if the data conflict so much with \\(H_{0}\\) that the null hypothesis cannot be deemed reasonable. If data and the null claim seem to be at odds with one another, and the data seem to support \\(H_{A}\\), then we will reject the notion of independence and conclude that the data provide evidence of discrimination."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#inference-via-randomization",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#inference-via-randomization",
    "title": "Statistical Inference with Randomization",
    "section": "Inference via Randomization",
    "text": "Inference via Randomization\nTo decide whether variability in data is due to\n\n\nthe causal mechanism (the randomized explanatory variable in the experiment)\n\n\nnatural variability inherent to the data\n\n\nwe set up a sham randomized experiment as a comparison."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#sham-randomized-experiment",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#sham-randomized-experiment",
    "title": "Statistical Inference with Randomization",
    "section": "‚ÄúSham‚Äù randomized experiment",
    "text": "‚ÄúSham‚Äù randomized experiment\n\nWe assume that each observational unit (person) would have gotten the exact same response value (chance of being promoted) regardless of the treatment level (sex).\nBy reassigning the treatments many many times, we can compare the actual experiment to the sham experiment.\n\nDecision\nIf the actual experiment has more extreme results than any of the sham experiments, we are led to believe that it is the explanatory variable which is causing the result and not just variability inherent to the data."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#variability-of-the-statistic",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#variability-of-the-statistic",
    "title": "Statistical Inference with Randomization",
    "section": "Variability of the statistic",
    "text": "Variability of the statistic\nSuppose the bankers‚Äô decisions were independent of the sex of the candidate. Then, if we conducted the experiment again with a different random assignment of promotion to the files, differences in promotion rates would be based only on random fluctuation in promotion decisions. Let‚Äôs simulate this as a class so we can get lots of replications for this experiment."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#youre-in-power-now",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#youre-in-power-now",
    "title": "Statistical Inference with Randomization",
    "section": "You‚Äôre in power now",
    "text": "You‚Äôre in power now\n\n\n\n\n\n\nSimulation Study\n\n\nIt‚Äôs your turn to assume the role of the bank personnel director and make a promotional decisions. Your group has been handed a stack of 48 confidential applications. Keep them face down for now."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#to-promote-or-not-to-promote.",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#to-promote-or-not-to-promote.",
    "title": "Statistical Inference with Randomization",
    "section": "To promote, or not to promote.",
    "text": "To promote, or not to promote.\n\nIdentify someone to record your results. This person logs into our shared Google drive, opens the Randomization Experiment spreadsheet, and fills out the first two columns.\nWhile they are still face down, choose 13 of your applicant pool to be promoted. Put these files in one pile, those not promoted in another pile. Fill out the \\# of promotions column in the spreadsheet.\nFlip your candidates over to reveal their sex. Record the number of males and females, and the # of each that have been promoted in each group.\nCalculate your point estimate for the male-female difference in promotional rate and write it in your notes.\nShuffle thoroughly your application pool (face down) and repeat this experiment for simulation round 2."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#class-results",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#class-results",
    "title": "Statistical Inference with Randomization",
    "section": "Class Results",
    "text": "Class Results\n\n\n\n\nShow the code\nsim.data &lt;- googlesheets4::read_sheet(URL) %&gt;% \n  select(mfdiff = `(Male - female) difference`) \n\nggplot(sim.data, aes(x = mfdiff)) +\n  geom_histogram(binwidth = .01) +\n  theme_bw() +\n  geom_vline(xintercept = .292, color = \"blue\", lwd=2) +\n  xlab(\"point estimate\") + ylab(\"Count\")\n\n\n\n\n\n\n\n\n\n\nDescribe the distribution of this graph. What does it seem to be centered around?\n\nIn what percent of simulations did we observe a difference of at least 29.2% (0.292)?\n\n\nShow the code\n(sim.pt.est &lt;- sum(sim.data$mfdiff &gt;= .29) / NROW(sim.data))\n\n\n[1] 0.03846154"
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#decision",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#decision",
    "title": "Statistical Inference with Randomization",
    "section": "Decision",
    "text": "Decision\nIn our analysis, we determined that there was only a \\(\\approx\\) 3.7% chance of obtaining a sample where \\(\\geq\\) 29.2% more male candidates than female candidates get promoted under the null hypothesis, so we conclude that the data provide some evidence of sex discrimination against female candidates by the male supervisors. In this case, we can reject the null hypothesis in favor of the alternative."
  },
  {
    "objectID": "slides/lec06a-statistical_inference_with_randomization.html#closing",
    "href": "slides/lec06a-statistical_inference_with_randomization.html#closing",
    "title": "Statistical Inference with Randomization",
    "section": "Closing",
    "text": "Closing\nStatistical inference is the practice of making decisions and conclusions from data in the context of uncertainty.\nErrors do occur, just like rare events, and the dataset at hand might lead us to the wrong conclusion. While a given dataset may not always lead us to a correct conclusion, statistical inference gives us tools to control and evaluate how often these errors occur."
  },
  {
    "objectID": "slides/lec07a-choosing_analysis.html#a-unifying-model-framework",
    "href": "slides/lec07a-choosing_analysis.html#a-unifying-model-framework",
    "title": "Choosing Appropriate Analysis",
    "section": "A unifying model framework",
    "text": "A unifying model framework\nA good way to think about all statistical models is that the observed data comes from some true model with some random error.\n\nDATA = MODEL + RESIDUAL\n\n\nThe MODEL is a mathematical formula (like \\(y = f(x)\\)).\nThe formulation of the MODEL will change depending on the number of, and data types of explanatory variables.\nOne goal of inferential analysis is to explain the variation in our data, using information contained in other measures (the model). To minimize the unexplained, or residual error."
  },
  {
    "objectID": "slides/lec07a-choosing_analysis.html#which-model-to-use",
    "href": "slides/lec07a-choosing_analysis.html#which-model-to-use",
    "title": "Choosing Appropriate Analysis",
    "section": "Which model to use?",
    "text": "Which model to use?\nMoving from:\n\n‚ÄúWhat descriptive measures should be used to examine the data‚Äù\n\nto\n\n‚ÄúWhat statistical analyses should be performed?"
  },
  {
    "objectID": "slides/lec07a-choosing_analysis.html#choosing-appropriate-analysis",
    "href": "slides/lec07a-choosing_analysis.html#choosing-appropriate-analysis",
    "title": "Choosing Appropriate Analysis",
    "section": "Choosing Appropriate Analysis",
    "text": "Choosing Appropriate Analysis\nThis table shows which statistical analyses procedures are appropriate depending on the combination of explanatory (rows) and response (columns) variable.\n\n\n\n\n\n\n\n\n\nExp \\ Resp\nBinary\nCategorical\nQuantitative\n\n\n\n\nBinary\nChi-squared\nChi-squared\nT-Test, Linear Regression\n\n\nCategorical\nChi-squared\nChi-squared\nANOVA, Linear Regression\n\n\nQuantitative\nLogistic Regression\nMultinomial or Ordinal Regression\nCorrelation & Linear Regression\n\n\n\nSee Table 6.2 in PMA6 for a more detailed table."
  },
  {
    "objectID": "slides/lec07a-choosing_analysis.html#why-selection-can-be-difficult",
    "href": "slides/lec07a-choosing_analysis.html#why-selection-can-be-difficult",
    "title": "Choosing Appropriate Analysis",
    "section": "Why selection can be difficult",
    "text": "Why selection can be difficult\n\nClassroom instruction tends to present methods in logical order from a learning perspective. Building from simple to more complex. Exposure to complex models limited.\nReal life data often contain a mixture of data types, missing data and complex patterns. This can make the choice of analysis somewhat arbitrary at times.\nTwo trained statisticians presented with the same data will often approach the analysis from different perspectives, and may different analyses depending on what assumptions they are willing to make."
  },
  {
    "objectID": "slides/lec07a-choosing_analysis.html#not-always-clear",
    "href": "slides/lec07a-choosing_analysis.html#not-always-clear",
    "title": "Choosing Appropriate Analysis",
    "section": "Not always clear",
    "text": "Not always clear\n\nThe primary assumption of most standard statistical procedures is that the records are independent of each other.\nOften program evaluation relies on paired measurements before and after a certain exposure or treatment (pre-post).\n\nIn this case, the approach is to calculate a pairwise difference for each individual and compare the average difference to 0 (any change vs no change).\n\nFor the purposes of this class, we will only concern ourselves with independent groups.\n\nRepeated measures is a topic typically taught in MATH 456 (but also covered in Chapter 18 of PMA6)"
  },
  {
    "objectID": "slides/lec07a-choosing_analysis.html#everything-is-a-linear-model",
    "href": "slides/lec07a-choosing_analysis.html#everything-is-a-linear-model",
    "title": "Choosing Appropriate Analysis",
    "section": "Everything is a linear model",
    "text": "Everything is a linear model\n\nMost of the common statistical tests (including the ones we cover) are special cases of linear regression\nhttps://lindeloev.github.io/tests-as-linear/"
  },
  {
    "objectID": "slides/lec07a-choosing_analysis.html#additional-references",
    "href": "slides/lec07a-choosing_analysis.html#additional-references",
    "title": "Choosing Appropriate Analysis",
    "section": "Additional References",
    "text": "Additional References\nPMA6 does not go over T-test, ANOVA or \\(\\chi^{2}\\) tests. To see more examples (with R code) and more mathematical detail see Chapter 5 in the Applied Stats Course Notes"
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#analysis-of-variance-anova-model",
    "href": "slides/lec07c-ANOVA.html#analysis-of-variance-anova-model",
    "title": "Inference between multiple means",
    "section": "Analysis of Variance (ANOVA) Model",
    "text": "Analysis of Variance (ANOVA) Model\n\\[\ny_{ij} = \\mu_{j} + \\epsilon_{ij} \\qquad \\qquad\n\\epsilon_{ij} \\overset{iid}{\\sim} \\mathcal{N}(0,\\sigma^{2})\n\\]\n\nResponse data \\(y_{ij}\\) from observation \\(i=1\\ldots n\\) belonging to group \\(j=1,2, \\ldots J\\)\nThe random error terms \\(\\epsilon_{ij}\\) are independently and identically distributed (iid) as normal with mean zero and common variance.\nLook familiar? T-test is a special case of ANOVA."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#hypothesis-specification",
    "href": "slides/lec07c-ANOVA.html#hypothesis-specification",
    "title": "Inference between multiple means",
    "section": "Hypothesis specification",
    "text": "Hypothesis specification\nThe null hypothesis is that there is no difference in the mean of the quantitative variable across groups (categorical variable), while the alternative is that there is a difference.\n\n\\(H_0\\): The mean outcome is the same across all groups. \\(\\mu_1 = \\mu_2 = \\cdots = \\mu_j\\)\n\\(H_A\\): At least one mean is different."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#multiple-comparison",
    "href": "slides/lec07c-ANOVA.html#multiple-comparison",
    "title": "Inference between multiple means",
    "section": "Multiple Comparison",
    "text": "Multiple Comparison\n\n\nWhy not multiple T-tests between all pairs of groups?\n\n\nEach time you conduct a test, you risk coming to the wrong conclusion.\nRepeated tests compound that chance of being wrong.\n\n\nImg Ref: https://xkcd.com/882"
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#proof",
    "href": "slides/lec07c-ANOVA.html#proof",
    "title": "Inference between multiple means",
    "section": "Proof",
    "text": "Proof\n\nSet a Type 1 error rate of \\(\\alpha = .05\\) (significant results due to randomness)\nConduct 10 analyses on the same data, but on different subsets.\nChance of making an error on any one test: .05\nChance of NOT making an error on any one test: .95\nChance of NOT making an error on ALL 10 tests: \\(.95^{10} = .6\\)\n‚Äì&gt; 40% chance of making a Type 1 error on at least one test."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#visual-comparison",
    "href": "slides/lec07c-ANOVA.html#visual-comparison",
    "title": "Inference between multiple means",
    "section": "Visual Comparison",
    "text": "Visual Comparison\nCompare groups I, II, and III. Can you visually determine if the differences in the group centers is due to chance or not? What about groups IV, V, and VI?\n\nSide-by-side dot plot for the outcomes for six groups."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#analysis-of-variance",
    "href": "slides/lec07c-ANOVA.html#analysis-of-variance",
    "title": "Inference between multiple means",
    "section": "Analysis of Variance",
    "text": "Analysis of Variance\nThe total amount of variation in our quantitative outcome can be broken into two parts:\n\nTotal Variation = Between Group Variation (model) + Within Group Variation (residual)\n\n\nThe portion of the variance in the outcome that is explained by the groups (model)\nThe portion that‚Äôs leftover due to unexplained randomness (residual)\n\nBy looking at a ratio of these variance portions, we can determine if the variation observed is due to the groups, or random chance."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#sum-of-squares",
    "href": "slides/lec07c-ANOVA.html#sum-of-squares",
    "title": "Inference between multiple means",
    "section": "Sum of Squares",
    "text": "Sum of Squares\nVariation is measured using the Sum of Squares (SS): The sum of the squares within a group (SSE), the sum of squares between groups (SSG), and the total sum of squares (SST).\n\\[\nSST =  \\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}(y_{ij}-\\bar{y}..)^{2} = (N-1)Var(Y)\n\\]\nSST (Total): Measures the variation of the \\(N\\) data points around the overall mean."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#sum-of-squares-1",
    "href": "slides/lec07c-ANOVA.html#sum-of-squares-1",
    "title": "Inference between multiple means",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\\[\nSSG = \\sum_{i=1}^{I}n_{i}(\\bar{y}_{i.}-\\bar{y}..)^{2} = n_{1}(\\bar{y}_{1.}-\\bar{y}..)^{2} + n_{2}(\\bar{y}_{2.}-\\bar{y}..)^{2} + \\ldots + n_{I}(\\bar{y}_{I.}-\\bar{y}..)^{2}\n\\]\nSSG (Between groups): Measures the variation of the \\(I\\) group means around the overall mean.\n\\[\nSSE = \\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}(y_{ij}-\\bar{y}_{i.})^{2} = \\sum_{i=1}^{I}(n_{i}-1)Var(Y_{i})\n\\]\nSSE (Within group): Measures the variation of each observation around its group mean."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#analysis-of-variance-table",
    "href": "slides/lec07c-ANOVA.html#analysis-of-variance-table",
    "title": "Inference between multiple means",
    "section": "Analysis of Variance Table",
    "text": "Analysis of Variance Table\nThe results are typically summarized in an ANOVA table.\n\n\n\n\n\n\n\n\n\n\nSource\nSS\ndf\nMS\nF\n\n\n\n\nGroups\nSSG\n\\(I-1\\)\nMSG = \\(\\frac{SSG}{I-1}\\)\n\\(\\frac{MSG}{MSE}\\)\n\n\nError\nSSE\n\\(N-I\\)\nMSE = \\(\\frac{MSE}{N-I}\\)\n\n\n\nTotal\nSST\n\\(N-1\\)\n\n\n\n\n\nThe value in the F column is the test statistic, and has a F distribution with degrees of freedom (df) dependent on the number of groups (I-1), and the number of observations (N-I)."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#the-f-distribution",
    "href": "slides/lec07c-ANOVA.html#the-f-distribution",
    "title": "Inference between multiple means",
    "section": "The F-distribution",
    "text": "The F-distribution\nThe \\(p\\)-value is the area to the right of the F statistic density curve. This is always to the right because the F-distribution is truncated at 0 and skewed right. This is true regardless of the \\(df\\).\n\n\nShow the code\ndf1 &lt;- c(3, 5, 8)\ndf2 &lt;- c(4, 6, 10)\n\nplot(NULL, xlim = c(0, 5), ylim = c(0, 1), xlab = expression(F), ylab=\"\", main = \"F Distribution\", axes=FALSE)\naxis(2, labels = FALSE, tick = FALSE)\naxis(1); box()\nfor (i in 1:3) {\n  curve(df(x, df1[i], df2[i]), from = 0, to = 5, col = i, add = TRUE, lty = i, lwd=2)\n}\nlegend(\"topright\", legend = paste(\"df1 =\", df1, \", df2 =\", df2), col = 1:3, lty = 1:3)"
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#assumptions",
    "href": "slides/lec07c-ANOVA.html#assumptions",
    "title": "Inference between multiple means",
    "section": "Assumptions",
    "text": "Assumptions\nGenerally we must check three conditions on the data before performing ANOVA:\n\nThe observations are independent within and across groups\nThe data within each group are nearly normal\nThe variability across the groups is about equal."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#example-march-of-the-penguins",
    "href": "slides/lec07c-ANOVA.html#example-march-of-the-penguins",
    "title": "Inference between multiple means",
    "section": "Example: March of the Penguins",
    "text": "Example: March of the Penguins\n\n\nShow the code\npen &lt;- palmerpenguins::penguins\n\n\n1. Identify response and explanatory variables\n\nSpecies = categorical explanatory variable\nFlipper length = quantitative response variable"
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#visualize-and-summarise",
    "href": "slides/lec07c-ANOVA.html#visualize-and-summarise",
    "title": "Inference between multiple means",
    "section": "2. Visualize and summarise",
    "text": "2. Visualize and summarise\n\n\n\n\nShow the code\nlibrary(ggdist) # for the \"half-violin\" plot (stat_slab)\nggplot(pen, aes(x=flipper_length_mm, y=species, fill=species)) + \n      stat_slab(alpha=.5, justification = 0) + \n      geom_boxplot(width = .2,  outlier.shape = NA) + \n      geom_jitter(alpha = 0.5, height = 0.05) +\n      stat_summary(fun=\"mean\", geom=\"point\", col=\"red\", size=4, pch=17) + \n      theme_bw() + \n      labs(x=\"Flipper Length (mm)\", y = \"Species\") + \n      theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npen %&gt;% group_by(species) %&gt;% \n  summarise(mean=mean(flipper_length_mm, na.rm=TRUE), \n            sd = sd(flipper_length_mm, na.rm=TRUE), \n            IQR = IQR(flipper_length_mm, na.rm=TRUE)) %&gt;%\n  kable(digits = 1)\n\n\n\n\n\nspecies\nmean\nsd\nIQR\n\n\n\n\nAdelie\n190.0\n6.5\n9\n\n\nChinstrap\n195.8\n7.1\n10\n\n\nGentoo\n217.2\n6.5\n9\n\n\n\n\n\n\nThe distribution of flipper length varies across the species, with Gentoo having the largest flippers on average at 217.2mm compared to Adelie (190mm) and Chinstrap (195.8mm). The distributions are normally distributed with very similar spreads, Chinstrap has the most variable flipper length with a SD of 7.1 compared to 6.5 for the other two species.\n A blog post about raincloud plots vs violins"
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#write-the-null-and-research-hypothesis-in-words-and-symbols.",
    "href": "slides/lec07c-ANOVA.html#write-the-null-and-research-hypothesis-in-words-and-symbols.",
    "title": "Inference between multiple means",
    "section": "3. Write the null and research hypothesis in words and symbols.",
    "text": "3. Write the null and research hypothesis in words and symbols.\n\nNull Hypothesis: There is no association between flipper length and species.\nAlternate Hypothesis: There is an association between flipper length and species.\n\nLet \\(\\mu_{A}, \\mu_{C}\\) and \\(\\mu_{G}\\) be the average flipper length for the Adelie, Chinstrap and Gentoo species of penguins respectively.\n\n\n\\(H_{0}: \\mu_{A} = \\mu_{C} = \\mu_{G}\\)\n\\(H_{A}:\\) At least one \\(\\mu_{j}\\) is different."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#state-and-justify-the-analysis-model.-check-assumptions.",
    "href": "slides/lec07c-ANOVA.html#state-and-justify-the-analysis-model.-check-assumptions.",
    "title": "Inference between multiple means",
    "section": "4. State and justify the analysis model. Check assumptions.",
    "text": "4. State and justify the analysis model. Check assumptions.\nWe are comparing means from multiple groups, so an ANOVA is the appropriate procedure. We need to check for independence, approximate normality and approximately equal variances across groups.\nIndependence: We are assuming that each penguin was sampled independently of each other, and that the species themselves are independent of each other.\nNormality: The distributions of flipper length within each group are fairly normal\nEqual variances: Both the standard deviation and IQR (as measures of variability) are very similar across all groups."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#conduct-the-test-and-make-a-decision-about-the-plausibility-of-the-alternative-hypothesis.",
    "href": "slides/lec07c-ANOVA.html#conduct-the-test-and-make-a-decision-about-the-plausibility-of-the-alternative-hypothesis.",
    "title": "Inference between multiple means",
    "section": "5. Conduct the test and make a decision about the plausibility of the alternative hypothesis.",
    "text": "5. Conduct the test and make a decision about the plausibility of the alternative hypothesis.\n\n\nShow the code\naov(flipper_length_mm ~ species, data=pen) |&gt; summary()\n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nspecies       2  52473   26237   594.8 &lt;2e-16 ***\nResiduals   339  14953      44                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\nThe pvalue is very small, so there is evidence to support \\(H_{a}\\): at least one mean is different."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#write-a-conclusion-in-context-of-the-problem.-include-the-point-estimates-confidence-interval-for-the-difference-and-p-value.",
    "href": "slides/lec07c-ANOVA.html#write-a-conclusion-in-context-of-the-problem.-include-the-point-estimates-confidence-interval-for-the-difference-and-p-value.",
    "title": "Inference between multiple means",
    "section": "6. Write a conclusion in context of the problem. Include the point estimates, confidence interval for the difference and p-value.",
    "text": "6. Write a conclusion in context of the problem. Include the point estimates, confidence interval for the difference and p-value.\nThere is sufficient evidence to believe that the average flipper length is significantly different between the Adelie, Chinstrap and Gentoo species of penguins (p&lt;.0001)."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#multiple-post-hoc-comparisons-which-group-is-different",
    "href": "slides/lec07c-ANOVA.html#multiple-post-hoc-comparisons-which-group-is-different",
    "title": "Inference between multiple means",
    "section": "Multiple / Post-Hoc comparisons: Which group is different?",
    "text": "Multiple / Post-Hoc comparisons: Which group is different?\n\nOnly appropriate if your ANOVA is significant.\nThe overall ANOVA can be significant and NOT have any significant differences when you look at the post hoc results. The reason is that the two analyses ask two different questions.\n\nThe ANOVA is testing the overall pattern of the data and asking if as a whole the explanatory variable has a relationship (or lack thereof) with the response variable.\nThe post hoc is asking if one level of the explanatory variable is significantly different than another for the response variable. The post hoc is not as sensitive to differences as the ANOVA.\nThe family-wise error rate of \\(\\alpha\\) is maintained\n\nDifferences in group means can be non-significant at the post hoc level, but significant at the ANOVA level."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#tukey-hsd",
    "href": "slides/lec07c-ANOVA.html#tukey-hsd",
    "title": "Inference between multiple means",
    "section": "Tukey HSD",
    "text": "Tukey HSD\n\n\nShow the code\nTukeyHSD(aov(flipper_length_mm ~ species, data=pen))\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = flipper_length_mm ~ species, data = pen)\n\n$species\n                      diff       lwr       upr p adj\nChinstrap-Adelie  5.869887  3.586583  8.153191     0\nGentoo-Adelie    27.233349 25.334376 29.132323     0\nGentoo-Chinstrap 21.363462 19.000841 23.726084     0\n\n\nThe results of the Tukey HSD post-hoc test indicate that the average flipper length in mm is significantly different between all pairs of penguin species at the 5% significance level. Chinstrap has an average flipper length 5.87mm(3.59-8.15) larger than Adelie, whereas Gentoo has an average flipper length 27.23mm(25.33-29.13) larger than Adelie."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#coefficient-of-determination-r2-fracssgsst",
    "href": "slides/lec07c-ANOVA.html#coefficient-of-determination-r2-fracssgsst",
    "title": "Inference between multiple means",
    "section": "Coefficient of Determination \\(R^{2} = \\frac{SSG}{SST}\\)",
    "text": "Coefficient of Determination \\(R^{2} = \\frac{SSG}{SST}\\)\n\n\n\n\nShow the code\naov(flipper_length_mm ~ species, data=pen) |&gt; summary()\n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nspecies       2  52473   26237   594.8 &lt;2e-16 ***\nResiduals   339  14953      44                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\n\n\n52473/(52473 + 14953)*100\n\n[1] 77.82309\n\n\n\nThe coefficient of determination is interpreted as the % of the variation seen in the outcome that is due to subject level variation within each of the treatment groups. The strength of this measure can be thought of in a similar manner as the correlation coefficient \\(\\rho\\), \\(&lt;.3\\) indicates a poor fit, \\(&lt;.5\\) indicates a medium fit, and \\(&gt;.7\\) indicates a good fit.\n\n77.8% of the variation in flipper length can be explained by the species of penguin"
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#non-parametric-tests",
    "href": "slides/lec07c-ANOVA.html#non-parametric-tests",
    "title": "Inference between multiple means",
    "section": "Non-parametric tests",
    "text": "Non-parametric tests\n\nMany stat tests rely on assumptions that ensure the sample estimate can be modeled with a normal distribution.\nWhat do you do if your assumptions aren‚Äôt met?\nWe can ‚Äúrelax‚Äù some of those assumptions and perform a more robust, but less powerful test.\n\nless power means you need more data to draw a conclusion with the same amount of confidence.\n\nNo detailed examples will be provided in these notes. You tend to learn/use these on an ‚Äúas-needed‚Äù basis."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#kruskal-wallis",
    "href": "slides/lec07c-ANOVA.html#kruskal-wallis",
    "title": "Inference between multiple means",
    "section": "Kruskal-Wallis",
    "text": "Kruskal-Wallis\n\nThe Kruskal-Wallis test is the most common non-parametric method for testing whether or not groups of observations come from the same overall distribution.\nBy comparing the medians instead of the means, we can remove the normality assumption on the residuals.\nNull hypothesis is now that the medians of all groups are equal vs at least one population median is different."
  },
  {
    "objectID": "slides/lec07c-ANOVA.html#k-w-and-all-pairwise-wilcox-tests",
    "href": "slides/lec07c-ANOVA.html#k-w-and-all-pairwise-wilcox-tests",
    "title": "Inference between multiple means",
    "section": "K-W and all pairwise Wilcox Tests",
    "text": "K-W and all pairwise Wilcox Tests\n\n\nShow the code\nkruskal.test(flipper_length_mm ~ species, data = pen)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  flipper_length_mm by species\nKruskal-Wallis chi-squared = 244.89, df = 2, p-value &lt; 2.2e-16\n\n\nShow the code\npairwise.wilcox.test(pen$flipper_length_mm, pen$species)\n\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  pen$flipper_length_mm and pen$species \n\n          Adelie Chinstrap\nChinstrap 3e-08  -        \nGentoo    &lt;2e-16 &lt;2e-16   \n\nP value adjustment method: holm \n\n\nIn this case, the non-parametric tests come to the same conclusion as the parametric ones. If there is a discrepency, go with the non-parametric test since it has fewer assumptions."
  },
  {
    "objectID": "slides/lec07e-correlation.html#opening-remarks",
    "href": "slides/lec07e-correlation.html#opening-remarks",
    "title": "Correlation Analysis",
    "section": "Opening Remarks",
    "text": "Opening Remarks\nThe PMA6 textbook (Chapter 7) goes into great detail on this topic, since regression is typically the basis for all advanced models.\nThe book also distinguishes between a ‚Äúfixed-x‚Äù case, where the values of the explanatory variable \\(x\\) only take on pre-specified values, and a ‚Äúvariable-x‚Äù case, where the values of \\(x\\) are observations from a population distribution of X‚Äôs.\nThis latter case is what we will be concerning ourselves with."
  },
  {
    "objectID": "slides/lec07e-correlation.html#bivariate-distribution",
    "href": "slides/lec07e-correlation.html#bivariate-distribution",
    "title": "Correlation Analysis",
    "section": "Bivariate distribution",
    "text": "Bivariate distribution\nThe bivariate distribution describes how of \\(X\\) and \\(Y\\) are jointly distributed, and is best interpreted by a look at the scatter diagram.\n\n\nShow the code\ny.bar &lt;- mean(pen$bill_length_mm, na.rm=TRUE)\nx.bar &lt;- mean(pen$body_mass_g, na.rm=TRUE)\n\np &lt;- ggplot(pen, aes(x=body_mass_g, y=bill_length_mm)) + geom_point() + \n  geom_hline(yintercept = y.bar) + \n  geom_vline(xintercept = x.bar) \nggExtra::ggMarginal(p, type=\"histogram\")\n\n\n\nIf \\(X\\) and \\(Y\\) come from independent normal distributions, the pair \\((X,Y)\\) comes from a bivariate normal distribution, and the data will tend to cluster around the means of \\(X\\) and \\(Y\\)."
  },
  {
    "objectID": "slides/lec07e-correlation.html#ellipse-of-concentration",
    "href": "slides/lec07e-correlation.html#ellipse-of-concentration",
    "title": "Correlation Analysis",
    "section": "Ellipse of concentration",
    "text": "Ellipse of concentration\nWe can view the ellipse of concentration as measure of strength and direction of the correlation between X and Y.\n\n\nShow the code\nggpubr::ggscatter(pen, x = \"body_mass_g\", y = \"bill_length_mm\",\n   ellipse = TRUE, mean.point = TRUE,\n   star.plot = TRUE)\n\n\n\nSee PMA6 Figure 7.5 for more examples."
  },
  {
    "objectID": "slides/lec07e-correlation.html#correlation",
    "href": "slides/lec07e-correlation.html#correlation",
    "title": "Correlation Analysis",
    "section": "Correlation",
    "text": "Correlation\nThe correlation coefficient is designated by \\(r\\) for the sample correlation, and \\(\\rho\\) for the population correlation. The correlation is a measure of the strength and direction of a linear relationship between two variables.\nThe correlation ranges from +1 to -1. A correlation of +1 means that there is a perfect, positive linear relationship between the two variables. A correlation of -1 means there is a perfect, negative linear relationship between the two variables. In both cases, knowing the value of one variable, you can perfectly predict the value of the second."
  },
  {
    "objectID": "slides/lec07e-correlation.html#reminder-to-visualize-your-data-before-analysis",
    "href": "slides/lec07e-correlation.html#reminder-to-visualize-your-data-before-analysis",
    "title": "Correlation Analysis",
    "section": "Reminder to visualize your data before analysis",
    "text": "Reminder to visualize your data before analysis\n\nThese all have the same r value"
  },
  {
    "objectID": "slides/lec07e-correlation.html#strength-of-the-correlation",
    "href": "slides/lec07e-correlation.html#strength-of-the-correlation",
    "title": "Correlation Analysis",
    "section": "Strength of the correlation",
    "text": "Strength of the correlation\nHere are rough estimates for interpreting the strengths of correlations based on the magnitude of \\(r\\).\n\n\\(|r| \\geq 0.7\\): Very strong relationship\n\\(0.4 \\leq |r| &lt; 0.7\\): Strong relationship\n\\(0.3 \\leq |r| &lt; 0.4\\): Moderate relationship\n\\(0.2 \\leq |r| &lt; 0.3:\\) Weak relationship\n\\(|r| &lt; 0.2:\\) Negligible or no relationship"
  },
  {
    "objectID": "slides/lec07e-correlation.html#as-a-measure-of-model-fit",
    "href": "slides/lec07e-correlation.html#as-a-measure-of-model-fit",
    "title": "Correlation Analysis",
    "section": "As a measure of model fit",
    "text": "As a measure of model fit\nWhen we square \\(r\\) (i.e.¬†\\(R^{2}\\)), it tells us what proportion of the variability in one variable that is described by variation in the second variable.\n\n\nYes, this is mathematically the same as the coefficient of determination we saw in ANOVA."
  },
  {
    "objectID": "slides/lec07e-correlation.html#pearson-test-of-correlation",
    "href": "slides/lec07e-correlation.html#pearson-test-of-correlation",
    "title": "Correlation Analysis",
    "section": "Pearson test of correlation",
    "text": "Pearson test of correlation\nTo test for a linear correlation between two variables we use the Pearson correlation coefficient which is defined as the covariance of the two variables divided by the product of their standard deviations.\n\\[\n\\rho_{X,Y} = \\frac{cov(X,Y)}{\\sigma_{x}\\sigma_{Y}}\n\\]\nThere are many modifications and adjustments to this measure that we will not get into detail with. We are using correlation as a stepping stool to Linear Regression."
  },
  {
    "objectID": "slides/lec07e-correlation.html#example-body-mass-and-bill-length-of-penguins",
    "href": "slides/lec07e-correlation.html#example-body-mass-and-bill-length-of-penguins",
    "title": "Correlation Analysis",
    "section": "Example: Body mass and bill length of penguins",
    "text": "Example: Body mass and bill length of penguins\n1. Identify response and explanatory variables\n\nThe quantitative explanatory variable is body mass (g)\nThe quantitative response variable is bill length (mm)"
  },
  {
    "objectID": "slides/lec07e-correlation.html#visualize-and-summarise",
    "href": "slides/lec07e-correlation.html#visualize-and-summarise",
    "title": "Correlation Analysis",
    "section": "2. Visualize and summarise",
    "text": "2. Visualize and summarise\n\n\n\n\nShow the code\nggplot(pen, aes(x=body_mass_g, y=bill_length_mm)) + \n  geom_point() + geom_smooth(col = \"red\")\n\n\n\n\n\n\n\n\n\nShow the code\ncor(pen$body_mass_g, pen$bill_length_mm, use = \"pairwise.complete.obs\")\n\n\n[1] 0.5951098\n\n\n\nThere is a strong, positive, mostly linear relationship between the body mass (g) of penguins and their bill length (mm) (r=.595)."
  },
  {
    "objectID": "slides/lec07e-correlation.html#write-the-null-and-research-hypothesis-in-words-and-symbols.",
    "href": "slides/lec07e-correlation.html#write-the-null-and-research-hypothesis-in-words-and-symbols.",
    "title": "Correlation Analysis",
    "section": "3. Write the null and research hypothesis in words and symbols.",
    "text": "3. Write the null and research hypothesis in words and symbols.\n\nNull Hypothesis: There is no correlation between the body mass and bill length of penguins.\nAlternate Hypothesis: There is a correlation between the body mass and bill length of penguins.\n\nLet \\(\\rho\\) be the true correlation between body mass and bill length of penguins.\n\\(H_{0}: \\rho=0 \\qquad \\qquad H_{A}: \\rho \\neq 0\\)"
  },
  {
    "objectID": "slides/lec07e-correlation.html#state-and-justify-the-analysis-model.-check-assumptions.",
    "href": "slides/lec07e-correlation.html#state-and-justify-the-analysis-model.-check-assumptions.",
    "title": "Correlation Analysis",
    "section": "4. State and justify the analysis model. Check assumptions.",
    "text": "4. State and justify the analysis model. Check assumptions.\n\nPearsons test of correlation will be conducted. This is appropriate because both variables are quantitative.\nThe relationship between variables are reasonably linear\nThe sample size is large."
  },
  {
    "objectID": "slides/lec07e-correlation.html#conduct-the-test",
    "href": "slides/lec07e-correlation.html#conduct-the-test",
    "title": "Correlation Analysis",
    "section": "5. Conduct the test",
    "text": "5. Conduct the test\nAnd make a decision about the plausibility of the alternative hypothesis.\n\n\nShow the code\ncor.test(pen$body_mass_g, pen$bill_length_mm)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  pen$body_mass_g and pen$bill_length_mm\nt = 13.654, df = 340, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5220040 0.6595358\nsample estimates:\n      cor \n0.5951098 \n\n\nThe p-value is very small, there is evidence in favor of a non-zero correlation."
  },
  {
    "objectID": "slides/lec07e-correlation.html#write-a-conclusion-in-context-of-the-problem.",
    "href": "slides/lec07e-correlation.html#write-a-conclusion-in-context-of-the-problem.",
    "title": "Correlation Analysis",
    "section": "6. Write a conclusion in context of the problem.",
    "text": "6. Write a conclusion in context of the problem.\nThere was a statistically significant and strong correlation between the body mass (g) and bill length (mm) of penguins (r = 0.595, 95%CI .5220-.6595, p &lt; .0001). The significant positive correlation shows that as the body mass of a penguin increases so does the bill length. These results suggest that 35% (95% CI: 27.2-43.5) of the variance in bill length can be explained by the body mass of the penguin."
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "All Slides",
    "section": "",
    "text": "Slides will open in full screen. Right click to open in a new tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nLec #\n\n\nTopic\n\n\n\n\n\n\nAug 25, 2024\n\n\nlec00a\n\n\nWelcome to MATH 615\n\n\n\n\nAug 25, 2025\n\n\nlec00b\n\n\nMATH 615 Course Tools\n\n\n\n\nAug 27, 2025\n\n\nlec01\n\n\nData Architecture\n\n\n\n\nSep 3, 2025\n\n\nlec02\n\n\nFormulating research questions\n\n\n\n\nSep 8, 2025\n\n\nlec03a\n\n\nWorkflows for Reproducibility\n\n\n\n\nSep 10, 2025\n\n\nlec03b\n\n\nPreparing your data for analysis\n\n\n\n\nSep 15, 2025\n\n\nlec04\n\n\nDescribing Distributions of Data\n\n\n\n\nSep 17, 2025\n\n\nlec05a\n\n\nDescribing Relationships between variables\n\n\n\n\nSep 24, 2025\n\n\nlec05b\n\n\nBest practices in Data Visualization\n\n\n\n\nOct 1, 2025\n\n\nlec06a\n\n\nStatistical Inference with Randomization\n\n\n\n\nOct 6, 2025\n\n\nlec06b\n\n\nStatistical Inference using Models\n\n\n\n\nOct 8, 2025\n\n\nlec07a\n\n\nChoosing Appropriate Analysis\n\n\n\n\nOct 13, 2025\n\n\nlec07b\n\n\nInference between two means\n\n\n\n\nOct 13, 2025\n\n\nlec07c\n\n\nInference between multiple means\n\n\n\n\nOct 20, 2025\n\n\nlec07d\n\n\nInference on proportions\n\n\n\n\nOct 22, 2025\n\n\nlec07e\n\n\nCorrelation Analysis\n\n\n\n\nOct 22, 2025\n\n\nlec08\n\n\nSimple Linear Regression Modeling\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "topics/t00-welcome.html",
    "href": "topics/t00-welcome.html",
    "title": "Welcome to Math 615",
    "section": "",
    "text": "Summer Break!\n\n\n\nReady to learn\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nGet connected to all the class materials & tools\n\n\nLearn about the class research project"
  },
  {
    "objectID": "topics/t00-welcome.html#learning-path",
    "href": "topics/t00-welcome.html#learning-path",
    "title": "Welcome to Math 615",
    "section": "",
    "text": "Summer Break!\n\n\n\nReady to learn\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nGet connected to all the class materials & tools\n\n\nLearn about the class research project"
  },
  {
    "objectID": "topics/t00-welcome.html#learning-materials",
    "href": "topics/t00-welcome.html#learning-materials",
    "title": "Welcome to Math 615",
    "section": "Learning Materials",
    "text": "Learning Materials\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec00a\n\n\nlec00b\n\n\n\n\n\n\n\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nSyllabus\n\n\nHelp page"
  },
  {
    "objectID": "topics/t00-welcome.html#active-learning",
    "href": "topics/t00-welcome.html#active-learning",
    "title": "Welcome to Math 615",
    "section": "üìù Active Learning",
    "text": "üìù Active Learning\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nHW 0 Checklist (Canvas)"
  },
  {
    "objectID": "topics/t00-welcome.html#assessment",
    "href": "topics/t00-welcome.html#assessment",
    "title": "Welcome to Math 615",
    "section": "Assessment",
    "text": "Assessment\nNone"
  },
  {
    "objectID": "topics/t02-asking_q.html",
    "href": "topics/t02-asking_q.html",
    "title": "Formulating research questions",
    "section": "",
    "text": "Learning how to interact with data\nReviewing the available data and thinking of a topic area of interest\n\n\n\n\nReady to start asking research questions to explore for the rest of the term.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nWrite down several research questions that are answerable with your data"
  },
  {
    "objectID": "topics/t02-asking_q.html#learning-path",
    "href": "topics/t02-asking_q.html#learning-path",
    "title": "Formulating research questions",
    "section": "",
    "text": "Learning how to interact with data\nReviewing the available data and thinking of a topic area of interest\n\n\n\n\nReady to start asking research questions to explore for the rest of the term.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nWrite down several research questions that are answerable with your data"
  },
  {
    "objectID": "topics/t02-asking_q.html#learning-materials",
    "href": "topics/t02-asking_q.html#learning-materials",
    "title": "Formulating research questions",
    "section": "Learning Materials",
    "text": "Learning Materials\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec02\n\n\n\n\n\n\n\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nHow to Write an Effective Research Question"
  },
  {
    "objectID": "topics/t02-asking_q.html#active-learning",
    "href": "topics/t02-asking_q.html#active-learning",
    "title": "Formulating research questions",
    "section": "üìù Active Learning",
    "text": "üìù Active Learning\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nHW02"
  },
  {
    "objectID": "topics/t02-asking_q.html#assessment",
    "href": "topics/t02-asking_q.html#assessment",
    "title": "Formulating research questions",
    "section": "Assessment",
    "text": "Assessment\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nProject Phase 2"
  },
  {
    "objectID": "topics/t04-describing_distributions.html",
    "href": "topics/t04-describing_distributions.html",
    "title": "Describing distributions of data",
    "section": "",
    "text": "Importing & starting to wrangle our data\n\n\n\nReady to visualize and learn characteristics of our data.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nCalculate appropriate summary statistics\n\n\nCreate appropriate data visualizations\n\n\nDescribe the distributions of data in complete sentences with supporting numbers."
  },
  {
    "objectID": "topics/t04-describing_distributions.html#learning-path",
    "href": "topics/t04-describing_distributions.html#learning-path",
    "title": "Describing distributions of data",
    "section": "",
    "text": "Importing & starting to wrangle our data\n\n\n\nReady to visualize and learn characteristics of our data.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nCalculate appropriate summary statistics\n\n\nCreate appropriate data visualizations\n\n\nDescribe the distributions of data in complete sentences with supporting numbers."
  },
  {
    "objectID": "topics/t04-describing_distributions.html#preparation",
    "href": "topics/t04-describing_distributions.html#preparation",
    "title": "Describing distributions of data",
    "section": "Preparation",
    "text": "Preparation\nA basic statistics class is a pre-requisite for this class. Ideally this was within the last 4-5 years, but I recognize not all learning paths are ideal. If you are rusty on descriptive statistics such as mean, median, skewness, standard deviation and variance, how to read boxplots, histograms and the IQR rule then I highly recommend that you review IMS Chapter 5.\nThe quiz for this topic includes topics that are not directly lectured on but are considered critical knowledge and are included in either PMA6 Ch 4 or IMS Ch 5."
  },
  {
    "objectID": "topics/t04-describing_distributions.html#learning-materials",
    "href": "topics/t04-describing_distributions.html#learning-materials",
    "title": "Describing distributions of data",
    "section": "Learning Materials",
    "text": "Learning Materials\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec04\n\n\n\n\n\n\n\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nPMA6 Ch 4\n\n\nASCN Ch 2.3"
  },
  {
    "objectID": "topics/t04-describing_distributions.html#active-learning",
    "href": "topics/t04-describing_distributions.html#active-learning",
    "title": "Describing distributions of data",
    "section": "üìù Active Learning",
    "text": "üìù Active Learning\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nHW04"
  },
  {
    "objectID": "topics/t04-describing_distributions.html#assessment",
    "href": "topics/t04-describing_distributions.html#assessment",
    "title": "Describing distributions of data",
    "section": "Assessment",
    "text": "Assessment\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nQuiz 03"
  },
  {
    "objectID": "topics/t06-foundations_for_inference.html",
    "href": "topics/t06-foundations_for_inference.html",
    "title": "Foundations for Statistical Inference",
    "section": "",
    "text": "Learning how to explore and visualize our data.\nVisually consider patterns, identify potential relationships\n\n\n\n\n\nThink about how data come to be. That is, if the data are to be used to make broad and complete conclusions, then it is important to understand who or what the data represent.\n\nKnowing how the observational units were selected will allow for generalizations back to the population from which the data were selected.\nBy understanding the structure of the study, causal relationships can be separated from those relationships which are only associated.\n\nRevisiting null value hypothesis testing (NVHT) from a randomization perspective\nRevisiting the Normal distribution model, and getting a feel for how probability (and thus p-values) are calculated.\n\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nIdentify and distinguish between a parameter and a statistic\n\n\nDescribe multiple sampling methods\n\n\nIdentify if a causal statement can be made given a data collection method\n\n\nExplain how to test a hypothsis using randomization\n\n\nAssess a research question using a hypothesis test\n\n\nUse the Normal distribution to calculate a probability\n\n\nDescribe the concept of sampling variability\n\n\nCalculate the mean and sd of the sampling distribution based on population parameters\n\n\nExplain the Central Limit Theorem\n\n\nConstruct and Interpret a confidence interval in context of the problem\n\n\nUse a confidence interval to make an inferential hypothesis statement"
  },
  {
    "objectID": "topics/t06-foundations_for_inference.html#learning-path",
    "href": "topics/t06-foundations_for_inference.html#learning-path",
    "title": "Foundations for Statistical Inference",
    "section": "",
    "text": "Learning how to explore and visualize our data.\nVisually consider patterns, identify potential relationships\n\n\n\n\n\nThink about how data come to be. That is, if the data are to be used to make broad and complete conclusions, then it is important to understand who or what the data represent.\n\nKnowing how the observational units were selected will allow for generalizations back to the population from which the data were selected.\nBy understanding the structure of the study, causal relationships can be separated from those relationships which are only associated.\n\nRevisiting null value hypothesis testing (NVHT) from a randomization perspective\nRevisiting the Normal distribution model, and getting a feel for how probability (and thus p-values) are calculated.\n\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nIdentify and distinguish between a parameter and a statistic\n\n\nDescribe multiple sampling methods\n\n\nIdentify if a causal statement can be made given a data collection method\n\n\nExplain how to test a hypothsis using randomization\n\n\nAssess a research question using a hypothesis test\n\n\nUse the Normal distribution to calculate a probability\n\n\nDescribe the concept of sampling variability\n\n\nCalculate the mean and sd of the sampling distribution based on population parameters\n\n\nExplain the Central Limit Theorem\n\n\nConstruct and Interpret a confidence interval in context of the problem\n\n\nUse a confidence interval to make an inferential hypothesis statement"
  },
  {
    "objectID": "topics/t06-foundations_for_inference.html#learning-materials",
    "href": "topics/t06-foundations_for_inference.html#learning-materials",
    "title": "Foundations for Statistical Inference",
    "section": "Learning Materials",
    "text": "Learning Materials\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec06a\n\n\nlec06b\n\n\n\n\n\n\n\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nIMS Chapter 11-11.1\n\n\nIMS - Chapter 13.1-13.3\n\n\nIMS - Chapter 2"
  },
  {
    "objectID": "topics/t06-foundations_for_inference.html#active-learning",
    "href": "topics/t06-foundations_for_inference.html#active-learning",
    "title": "Foundations for Statistical Inference",
    "section": "üìù Active Learning",
    "text": "üìù Active Learning\nWe will be using the Jigsaw technique, which is a method of learning by teaching. You have been assigned to read and summarize one section in the textbook.\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nStudy Design\n\n\nBias in hiring\n\n\nCLT Explorer\n\n\nHW06"
  },
  {
    "objectID": "topics/t06-foundations_for_inference.html#assessment",
    "href": "topics/t06-foundations_for_inference.html#assessment",
    "title": "Foundations for Statistical Inference",
    "section": "Assessment",
    "text": "Assessment\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nQuiz 05\n\n\nQuiz 06"
  },
  {
    "objectID": "topics/t08-regression_modeling.html",
    "href": "topics/t08-regression_modeling.html",
    "title": "Introduction to Regression modeling",
    "section": "",
    "text": "Learning how to statistically assess the relationship between two variables.\n\n\n\nLearning the fundamentals of linear regression, a foundational method of modeling for many types of analyses. We‚Äôll start with simple linear regression, a model that describes the relationship between two quantitative variables as a straight line.\nThen we‚Äôll expand that model to include multiple predictors of varying types.\nAnd then we‚Äôll make it even more generalizable by transforming the response variable \\(y\\) and modeling a log transformed outcome, and a binary outcome using the same regression modeling framework.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nUse the least squares method to calculate an equation for a best fit line that describes the relationship between a continuous explanatory and continuous response variable\n\n\nCalculate and interpret estimates for the intercept and slope of regression models\n\n\nUse the regression equation to predict new values for Y given values of X\n\n\nCalculate and interpret confidence and prediction intervals for the slope value\n\n\nVisually assess assumptions of regression models\n\n\nFit a linear regression model with multiple predictors and interpret the coefficients\n\n\nInterpret the regression coefficient for binary, and categorical predictors\n\n\nFit a model with a log transformed, or binary outcome and interpret the results\n\n\nChoose the best fitting model among several candidates using metrics like R2, AIC, BIC and Accuracy"
  },
  {
    "objectID": "topics/t08-regression_modeling.html#learning-path",
    "href": "topics/t08-regression_modeling.html#learning-path",
    "title": "Introduction to Regression modeling",
    "section": "",
    "text": "Learning how to statistically assess the relationship between two variables.\n\n\n\nLearning the fundamentals of linear regression, a foundational method of modeling for many types of analyses. We‚Äôll start with simple linear regression, a model that describes the relationship between two quantitative variables as a straight line.\nThen we‚Äôll expand that model to include multiple predictors of varying types.\nAnd then we‚Äôll make it even more generalizable by transforming the response variable \\(y\\) and modeling a log transformed outcome, and a binary outcome using the same regression modeling framework.\n\n\n\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nUse the least squares method to calculate an equation for a best fit line that describes the relationship between a continuous explanatory and continuous response variable\n\n\nCalculate and interpret estimates for the intercept and slope of regression models\n\n\nUse the regression equation to predict new values for Y given values of X\n\n\nCalculate and interpret confidence and prediction intervals for the slope value\n\n\nVisually assess assumptions of regression models\n\n\nFit a linear regression model with multiple predictors and interpret the coefficients\n\n\nInterpret the regression coefficient for binary, and categorical predictors\n\n\nFit a model with a log transformed, or binary outcome and interpret the results\n\n\nChoose the best fitting model among several candidates using metrics like R2, AIC, BIC and Accuracy"
  },
  {
    "objectID": "topics/t08-regression_modeling.html#learning-materials",
    "href": "topics/t08-regression_modeling.html#learning-materials",
    "title": "Introduction to Regression modeling",
    "section": "Learning Materials",
    "text": "Learning Materials\nThis section uses the the Lung function dataset and the following packages:\n\nPlotting: ggplot2, ggdist, sjPlot,gridExtra\nPresenting results: broom, gtsummary\nAssumption checking: performance\n\nSee PMA6 Appendix for more details about the Lung data.\n\nNote: Regression is such a big deal, there are MANY functions in MANY packages that help you get out the relevant information out of the model, and display it in many different ways. I will show several in the slides.\n\n Slides (Will open in full screen. Right click to open in a new tab)\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nlec08\n\n\n\n\n\n\n\nüìö Reading\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nTopic Overview\n\n\nPMA6 Ch 7\n\n\nIMS Ch 24"
  },
  {
    "objectID": "topics/t08-regression_modeling.html#assignments",
    "href": "topics/t08-regression_modeling.html#assignments",
    "title": "Introduction to Regression modeling",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nHW08"
  },
  {
    "objectID": "topics/t08-regression_modeling.html#assessment",
    "href": "topics/t08-regression_modeling.html#assessment",
    "title": "Introduction to Regression modeling",
    "section": "Assessment",
    "text": "Assessment\n\n\n\n\n\n\n\n\nItems\n\n\n\n\nQuiz 09\n\n\nProject Phase 4"
  }
]