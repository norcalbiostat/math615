---
title: "Statistical Inference using Models"
date: "2024-10-07"
description: "lec06b"
author: "Robin Donatello"
footer: "[üîó https://math615.netlify.app](https://math615.netlify.app) / Stat Inference via Models"
from: markdown+emoji
format: 
  revealjs:
    theme: sky
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    title-slide-attributes:
      data-background-image: images/paranormal.png
      data-background-size: 25% 
      data-background-position: bottom 50px right 50px
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:
      width: 200
---



## Warm up exercise

With a partner, go play with the Central Limit Theorem interactive explorer for about 15 minutes. Take notes and be prepared to share out what you learned/your take away message.  

[https://mathisawesome.shinyapps.io/central-limit-theorem/](https://mathisawesome.shinyapps.io/central-limit-theorem/)

## Sampling Distributions

Since _point estimates_ are numbers calculated on a sample, they are also _sample statistics_. Recall that sample statistics are used to estimate parameters, the true value of the quantity of interest from the population.

As we just saw through simulation, point estimates are subject to _random variation_ because they are calculated on different random samples from the population. The distribution of repeatedly calculated point estimates based on the same fixed size $n$ from a population is called a _sampling distribution_. 


## Mathematical theory guarantees {.smaller}

* If repeated samples are taken, a point estimate will follow something that **resembles a normal distribution** when certain conditions are met. 
    - _Note: we typically only take one sample, but the mathematical model lets us know what to expect if we had taken repeated samples_

:::{.callout-important}
#### Observations in the sample are independent.
Guaranteed when we take a random sample from a population, or randomly divide individuals into treatment and control groups.
:::
    
:::{.callout-important}
#### The sample is large enough.
What qualifies as ‚Äúlarge enough‚Äù differs from one context to the next. If the population is already normally distributed and the formula to calculate the sample statistic simple, then fewer samples are needed. The "magic" number 30 gets thrown around a lot. 
:::

## The Normal Distribution {.smaller}

:::: {.columns}

::: {.column width="50%"}
The normal distribution is used to describe the variability associated with sample statistics which are taken from either repeated samples or repeated experiments. The normal distribution is quite powerful in that it describes the variability of many different statistics such as the sample mean and sample proportions. 

Distributions of many variables are nearly normal, but none are exactly normal. While not perfect for any single problem, the Normal Distribution is very useful for a variety of problems.
:::

::: {.column width="50%"}
<a href="https://twitter.com/RiddleMeCam/status/1557402268395139077?ref_src=twsrc%5Etfw">![](images/clt_twitter.png)</a>
:::

::::

# The Normal Distribution

> come back and expand here

Board work following [IMS 13.2](https://openintro-ims.netlify.app/foundations-mathematical.html#normalDist)

* Distributional Notation
* Standardizing with Z-scores
* Normal Probabilies (qnorm, pnorm)

# Quantifying variability of a statistic

Follows [IMS 13.3](https://openintro-ims.netlify.app/foundations-mathematical.html#quantifying-the-variability-of-a-statistic)


## 68-95-99.7 rule

![](https://openintro-ims.netlify.app/foundations-mathematical_files/figure-html/fig-er6895997-1.png)

> to here


## Standard Error

:::{.callout-important}
### Definition: Standard Deviation (SD)
Variability of the data values ($x$)
:::

:::{.callout-important}
### Definition: Standard Error (SE)
Variability of the sample statistic (e.g. $\bar{x}$ or $\hat{p}$)
:::


## Margin of Error {.smaller}

:::{.callout-important}
### Definition: Margin of Error (MOE)
The margin of error describes how far away observations are from their mean.
> check this

Often approximated as $2 * SE$
:::

* 95% of the observations are within one margin of error of the mean.
* If the spread of the observations goes from some lower bound to some upper bound, a rough approximation of the $SE$ is to divide the range by 4. 
    - If you notice the sample proportions go from 0.1 to 0.4, the SE can be approximated to be 0.075.

## Summary

* Point estimates from a sample may be used to estimate population parameters. 
* Point estimates are not exact: they vary from one sample to another. 
* The standard error is the uncertainty of the sample statistic, and it gets smaller as you use more data to calculate the point estimate. 
* As your standard error decreases, so does your margin of error

# Case study: Stents

This example and data comes from [IMS 13.6](https://openintro-ims.netlify.app/foundations-mathematical.html#casestent)
```{r}
stent30 <- openintro::stent30
```


## Observed data {.smaller}

Consider an experiment that examined whether implanting a stent in the brain of a patient at risk for a stroke helps reduce the risk of a stroke. The results from the first 30 days of this study are summarized in the following table.
 
::: columns
::: {.column width="50%"}
```{r}
table(stent30$group, stent30$outcome) |> addmargins()
```
:::

::: {.column width="50%"}
```{r}
table(stent30$group, stent30$outcome) |>  prop.table(margin=1) |>round(digits=2)
```
:::
:::

These results are surprising! The point estimate suggests that patients who received stents may have a higher risk of stroke: $p_{trmt}‚àíp_{ctrl}=0.090$.

## Point estimate vs Interval estimate

The point estimate for the difference in proportions $p_{trmt}‚àíp_{ctrl}=0.090$ is a single point estimate, based on this single sample.

\

A *point estimate* is our best guess for the value of the parameter, so it makes sense to build the confidence interval around that value.

## Constructing a 95% confidence interval (CI)

When the sampling distribution of a point estimate can _reasonably be modeled as having a normal distribution_, the point estimate we observe will be within 1.96 standard errors of the true value of interest about 95% of the time. Thus, a 95% confidence interval for such a point estimate can be constructed:

$$\mbox{point estimate} \pm 1.96 √ó SE$$

We can be 95% confident this interval captures the true value.

## Construct a 95% CI for the stent example {.smaller}

The conditions necessary to ensure the point estimate $p_{trmt}‚àíp_{ctrl}$ is nearly normal have been verified for you, and the estimate's standard error is $SE = 0.028$.

-   Construct a 95% confidence interval for the change in 30-day stroke rates from usage of the stent.
-   Interpret this interval in context of the problem.

. . . 

$$0.090 \pm 1.96√ó0.028 = (0.035,0.145)$$

We are 95% confident that implanting a stent in a stroke patient's brain increased the risk of stroke within 30 days by a rate of 0.035 to 0.145.

## Important note

:warning: it's incorrect to say that we can be 95% confident that the true value is inside the mean.

![Figure 13.11: Twenty-five samples of size n=300 were collected from a population with p=0.30. For each sample, a confidence interval was created to try to capture the true proportion p. However, 1 of these 25 intervals did not capture p=0.30.](https://openintro-ims.netlify.app/foundations-mathematical_files/figure-html/fig-95PercentConfidenceInterval-1.png)

## 

-   This is one of the most common errors: while it might be useful to think of it as a probability, the confidence level only quantifies how plausible it is that the parameter is in the interval.
-   Our intervals say nothing about the confidence of capturing individual observations, a proportion of the observations, or about capturing point estimates.
-   Confidence intervals provide an interval estimate for and attempt to capture population parameters.

## Hypothesis test

::: {.callout-note icon="false"}
## First draft 
Let's setup a hypothesis to test if stents work to reduce the risk of a stroke.  
:::

\

$H_{0}$: Stents don't work

$H_{A}$: Stents reduce the risk of a stroke

## Hypothesis test

::: {.callout-note icon="false"}
### Revision 1: 
Making it a statement about two groups 
:::


$H_{0}$: Patients who have a stent have the same risk of a stroke as patients who don't have a stent

$H_{A}$: Patients who have a stent have lower risk of a stroke as patients who don't have a stent

## Hypothesis test

::: {.callout-note icon="false"}
### Revision 2: 
Make it a statement using summary statistics and removing the directionality of the hypothesis
:::

\ 

$H_{0}$: The proportion of patients with a stent who have a stroke is the same as the proportion of patients without a stent who have a stroke. 

$H_{A}$: The proportion of patients with a stent who have a stroke is different than the proportion of patients without a stent who have a stroke. 

## Hypothesis test

::: {.callout-note icon="false"}
### Revision 3: 
Writing it in symbols
:::

Let $p_{trmt}$ be the proportion of patients with a stent who have a stroke, and $p_{ctrl}$ be the proportion of patients without a stent who have a stroke 

\

$H_{0}: p_{trmt} = p_{ctrl}$

$H_{A}: p_{trmt} \neq p_{ctrl}$

## Hypothesis test

::: {.callout-note icon="false"}
### Revision 3.5: 

Rewriting as a difference in parameters
:::

Let $p_{1}$ be the proportion of patients with a stent who have a stroke, and $p_{ctrl}$ be the proportion of patients without a stent who have a stroke 

\

$H_{0}: p_{trmt} - p_{ctrl} = 0$

$H_{A}: p_{trmt} - p_{ctrl} \neq 0$

## Using the Normal model

* Now we have a statistic (difference in proportions $p_{trmt} - p_{ctrl}$) and a null value of 0 to compare it to. 

* The conditions necessary to ensure the point estimate is nearly normal have been verified for you. 

* The estimate‚Äôs standard error is $SE = 0.028$ has been calculated for you as well.  

## Calculating a test statistic 

$$ Z = \frac{\mbox{point estimate - null value}}{SE}$$

. . . 

$$ Z = \frac{(p_{trmt} - p_{ctrl}) - 0}{SE_{p_{trmt} - p_{ctrl}}} = \frac{.090}{.028} = 3.21 $$

. . . 

$$ P(Z > 3.2) = .00068 \qquad \mbox{ (the p-value)}$$ 

. . . 

If the true difference in proportions was 0, then the probability of observing a difference of 0.09 due to random chance is 0.00068. 

## 

![https://xkcd.com/1478/](https://imgs.xkcd.com/comics/p_values.png)


## Using Confidence Intervals to test a hypothesis

> We are 95% confident that implanting a stent in a stroke patient's brain increased the risk of stroke within 30 days by a rate of 0.035 to 0.145.

Since the interval does not contain the null hypothesized value of 0 (is completely above 0), it means the data provide convincing evidence that the stent used in the study changed the risk of stroke within 30 days
