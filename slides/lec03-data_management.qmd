---
title: "Preparing your data for analysis"
date: "2023-08-30"
description: "3, 4"
author: "Robin Donatello"
footer: "[ðŸ”— https://math615.netlify.app](https://math615.netlify.app) / Preparing your data for analysis"
from: markdown+emoji
format: 
  revealjs:
    theme: sky
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:
      width: 200
---

# Workflow and Data Cleaning

## Workflows

Once the data are available from a study there are still a number of steps that must be undertaken to get them into shape for analysis.

One of the most misunderstood parts of the analysis process is the data preparation stage. To say that 70% of any analysis is spent on the data management stage is not an understatement.

## 

![Example workflow](images/Afifi_Fig3_1.png)

## Generating a reproducible workflows

Reproducibility is the ability for any researcher to take the same data set and run the same set of software program instructions as another researcher and achieve the same results.

*Not the same as **replicability** where you re-run an experiment and achieve the same outcomes.*

The goal is to create an exact record of what was done to a data set to produce a specific result.

## Three steps to achieve reproducibility

1.  The un-processed data are connected directly to software code file(s) that perform data preparation techniques.
2.  The processed data are connected directly to other software code file(s) that perform the analyses.
3.  All data and code files are self-contained such that they could be given to another researcher to execute the code commands on a separate computer and achieve the same results as the original author.

## Literate programming

-   Explain the logic of the program or analysis process in a natural language,
-   Small code snippets included at each step act as a full set of instructions that can be executed to reproduce the result/analysis being discussed.
-   Literate programming tools such as Markdown, Quarto and $\LaTeX$ are integrated into all common statistical packages except SPSS.

## Reproducible Research + Literate Programming {.smaller}

-   Practicing reproducible research techniques using literate programming tools allows such major updates to be a simple matter of re-compiling all coded instructions using the updated data set.
-   The effort then is reduced to a careful review and update of any written results.
-   Using literate programming tools create formatted documents in a streamlined manner that is fully synchronized with the code itself.
-   The author writes the text explanations, interpretations, and code in the statistical software program itself, and the program will execute all commands and combine the text, code and output all together into a final dynamic document.

## Why all the fuss? {.smaller}

-   You are your own collaborator 6 months from now. Be nice to your future self
-   Explain your steps (what and why)
    -   How did you get from point A to B?
    -   Why did you recode this variable in this manner?
-   Found an error in your analysis code? Need to add an analysis to your presentation?
-   Reproduce your steps in a few clicks using a script file (`.R`, `.Rmd`, `.sas`, `.sps`, `.do`, `.ipynb`)

![Figure Credits: [Roger Peng](http://www.biostat.jhsph.edu/~rpeng/)](images/pipeline.png)

# Data Analysis Pipeline

![](https://d33wubrfki0l68.cloudfront.net/571b056757d68e6df81a3e3853f54d3c76ad6efc/32d37/diagrams/data-science.png)

This week is all about importing, tidying and transforming.

## Project Structure / Follow along for R users

1.  Start a new R project and connect it to your Math 615 folder. This will help keep all your files for this class self-contained.
2.  Install the following packages by copying the following code and pasting it into the console. 

```{r, eval=FALSE}
install.packages("here")
install.packages("tidyverse")
install.packages("palmerpenguins")
install.packages("rmarkdown")
```

Outside of class you will also need to install the following packages: `knitr, kableExtra, scales, sjPlot, ggpubr, RcolorBrewer, janitor`, but we won't use some of these until Hw4. 

## Using Projects

Great, you made a project but how do you use it? 

Instead of opening a single script file, you will open the project itself. It has the same cube like icon that you see in the top right of Rstudio. 

![](images/rproj.png)

Then from your bottom left pane, in the `files` tab you can open all of your script files. 

## Hello Quarto

<https://quarto.org/docs/get-started/hello/rstudio.html>

## Creating a PDF

Great! You rendered your first literate document to an HTML format. Great for viewing, not so great for printing or emailing. We need to do one more thing before we can render this document to a pdf. Install a typesetting program called \LaTeX (lah-tek or lay-tek). 

\

**Step 1: Copy the code below to install the `tinytex` package:**

```{r, eval=FALSE}
install.packages("tinytex")
```

## Install LaTeX

Once that is fully complete and you see the R console windows showing a `>` waiting for you, copy the following code to have tinytex install \LaTeX for you. 

```{r, eval=FALSE}
tinytex::install_tinytex()
```

This will take some time. Be patient, and wait for R to display a `>` in the console. 

## Test your installation. 

Change the output format of your quarto file to `pdf` in the YAML header (At the very top of your code file, line 2 or 3). 

```verbatim
---
format: pdf
---
```

Now click `render` and see if it creates a PDF. 

The PDF should automatically pop up, otherwise check your `Math615` folder _in the same location as your script file is saved_ and see if a PDF is located there. 


## Data Import

1. Create a new Quarto file named `dm_dataset.qmd` where `dataset` is YOUR dataset  name. E.g. `dm_addhealth.qmd`. 
2. Save this file in your `Math615/scripts` folder. 
3. Copy this code into a new code chunk. 

``` verbatim
library(here)
library(tidyverse)

raw <- read_csv(here("data", "data.csv"))
```

4. Replace the `data.csv` with YOUR data set name exactly as it shows in your files window (bottom right). 
5. Run this code chunk only (not render)

## Peek at your data

Okay, did it work? 

1. Look in the top right Environment pane. Do you see a dataset named `raw`? Does it have an expected number of rows and columns? 
2. Use the `glimpse()` function from the `tidyverse` package to get a snapshot of what the data looks like. (# of rows, columns, data types). Type the following code in the console to see a summary of what R sees as your variable names and data types.

```{r, eval=FALSE}
glimpse(raw)
```

Don't worry much more about interpreting this now. We'll start exploring data next week. 7

## Initial Data Screening

Use functions like `str()`, `typeof()` to see what data type R thinks your variables are.

Use `table()` or `summary()` to see the range of values present.

## Data Prep questions {.smaller}

Questions to ask yourself (and the data) while reviewing the codebook to choose variables to be used in an analysis.

-   Do you need to code out missing data? (`N/A`, `MISSING` ,`-99`)
-   Do you need to make response codes more logical?
    -   Some systems will record 1=YES and 2=NO. This should be changed so 0=NO.
-   Do you need to recode numerical variables to categorical?
    -   Sometimes categorical data will be recorded as 1, 2, 3 etc when those numbers represent named categories.
-   Do you need to create secondary variables?
    -   Such as an average across measures to create a score.

::: aside
Some of these answers will come only after you look at your data. This can be looking at the raw data itself but also looking at tables and charts generated from the data. Often when you try to create a plot or table you will encounter an error or something odd looking that will be the notification that something has to be adjusted.
:::

## How do I actually do this?

-   After you identify what you need to do, you have to find an example of how to code the task you want.
-   The [Applied Stats Course notes](https://norcalbiostat.github.io/AppliedStatistics_notes/data-management.html) has specific examples on how to handle certain/common circumstances.
-   Take it one variable at a time.
- Write your successes/code in the [Collaborative R Notes](https://hackmd.io/@norcalbiostat/R) as a quick reference for you, and others. You can see how the [SPSS](https://hackmd.io/@norcalbiostat/SPSS) students did it in years prior. 

## Closing thoughts

-   Do not underestimate the importance of this step
-   It will take you far, far longer than you anticipate to 'clean' your data
-   Writing code (in any language) will be challenging, but will pay off in the long run
